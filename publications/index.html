<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Marius Staring </title> <meta name="author" content="Marius Staring"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>" > <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mstaring.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Marius</span> Staring </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>My Google Scholar profile can be found <a href="http://scholar.google.nl/citations?user=pKFkfq4AAAAJ">here</a>.</p> <div class="publications"> <h2 class="bibliography">Journal Articles</h2> <ol class="bibliography"><li><div class="row"> <div id="Chaves-de-Plaza:2024" class="col-sm-10"> <span class="title">Depth for Multi-Modal Contour Ensembles</span> <span class="author"> N.F. Chaves-de-Plaza,&nbsp;M. Molenaar,&nbsp;P. Mody , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'M. Staring, R. Egmond, E. Eisemann, A. Vilanova, K. Hildebrandt' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </span> <span class="periodical"> <em>Computer Graphics Forum</em>, 2024 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1111/cgf.15083" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2024_j_CGF.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/chadepl/paper-multimodal-contour-depth"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p>The contour depth methodology enables non-parametric summarization of contour ensembles by extracting their representatives, confidence bands, and outliers for visualization (via contour boxplots) and robust downstream procedures. We address two shortcomings of these methods. Firstly, we significantly expedite the computation and recomputation of Inclusion Depth (ID), introducing a linear-time algorithm for epsilon ID, a variant used for handling ensembles with contours with multiple intersections. We also present the inclusion matrix, which contains the pairwise inclusion relationships between contours, and leverage it to accelerate the recomputation of ID. Secondly, extending beyond the single distribution assumption, we present the Relative Depth (ReD), a generalization of contour depth for ensembles with multiple modes. Building upon the linear-time eID, we introduce CDclust, a clustering algorithm that untangles ensemble modes of variation by optimizing ReD. Synthetic and real datasets from medical image segmentation and meteorological forecasting showcase the speed advantages, illustrate the use case of progressive depth computation and enable non-parametric multimodal analysis. To promote research and adoption, we offer the contour-depth Python package.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Chaves-de-Plaza:2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Depth for Multi-Modal Contour Ensembles}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chaves-de-Plaza, N.F. and Molenaar, M. and Mody, P. and Staring, M. and van Egmond, R. and Eisemann, E. and Vilanova, A. and Hildebrandt, K.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{43}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e15083}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Mody:2024" class="col-sm-10"> <span class="title">Large-scale dose evaluation of deep learning organ contours in head-and-neck radiotherapy by leveraging existing plans</span> <span class="author"> Prerak Mody,&nbsp;Merle Huiskes,&nbsp;Nicolas Chaves-de-Plaza , and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Alice Onderwater, Rense Lamsma, Klaus Hildebrandt, Nienke Hoekstra, Eleftheria Astreinidou, Marius Staring, Frank Dankers' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </span> <span class="periodical"> <em>Physics and Imaging in Radiation Oncology</em>, Apr 2024 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.phro.2024.100572" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2024_j_PHIRO.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/prerakmody/dose-eval-via-existing-plan-parameters"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Background and Purpose:</b> Retrospective dose evaluation for organ-at-risk auto-contours has previously used small cohorts due to additional manual effort required for treatment planning on auto-contours. We aimed to do this at large scale, by a) proposing and assessing an automated plan optimization workflow that used existing clinical plan parameters and b) using it for head-and-neck auto-contour dose evaluation.<br/><b>Materials and Methods:</b> Our automated workflow emulated our clinic’s treatment planning protocol and reused existing clinical plan optimization parameters. This workflow recreated the original clinical plan (P<sub>OG</sub>) with manual contours (P<sub>MC</sub>) and evaluated the dose effect (P<sub>OG</sub> - P<sub>MC</sub>) on 70 photon and 30 proton plans of head-and-neck patients. As a use-case, the same workflow (and parameters) created a plan using auto-contours (P<sub>AC</sub>) of eight head-and-neck organs-at-risk from a commercial tool and evaluated their dose effect (P<sub>MC</sub> - P<sub>AC</sub>).<br/><b>Results:</b> For plan recreation (P<sub>OG</sub> - P<sub>MC</sub>), our workflow had a median impact of 1.0% and 1.5% across dose metrics of auto-contours, for photon and proton respectively. Computer time of automated planning was 25% (photon) and 42% (proton) of manual planning time. For auto-contour evaluation (P<sub>MC</sub> - P<sub>AC</sub>), we noticed an impact of 2.0% and 2.6% for photon and proton radiotherapy. All evaluations had a median &Delta;NTCP (Normal Tissue Complication Probability) less than 0.3%.<br/><b>Conclusions:</b> The plan replication capability of our automated program provides a blueprint for other clinics to perform auto-contour dose evaluation with large patient cohorts. Finally, despite geometric differences, auto-contours had a minimal median dose impact, hence inspiring confidence in their utility and facilitating their clinical adoption.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Mody:2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Large-scale dose evaluation of deep learning organ contours in head-and-neck radiotherapy by leveraging existing plans}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mody, Prerak and Huiskes, Merle and Chaves-de-Plaza, Nicolas and Onderwater, Alice and Lamsma, Rense and Hildebrandt, Klaus and Hoekstra, Nienke and Astreinidou, Eleftheria and Staring, Marius and Dankers, Frank}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Physics and Imaging in Radiation Oncology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100572}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Stoel:2024" class="col-sm-10"> <span class="title">Deep Learning in Rheumatologic Image Interpretation</span> <span class="author"> Berend C. Stoel,&nbsp;<em>Marius Staring</em>,&nbsp;Monique Reijnierse , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Annette H.M. Helm-van Mil' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>Nature Reviews Rheumatology</em>, Mar 2024 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/s41584-023-01074-5" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2024_j_NRR.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Artificial intelligence techniques, specifically deep learning, have already affected daily life in a wide range of areas. Likewise, initial applications have been explored in rheumatology. Deep learning might not easily surpass the accuracy of classic techniques when performing classification or regression on low-dimensional numerical data. With images as input, however, deep learning has become so successful that it has already outperformed the majority of conventional image-processing techniques developed during the past 50 years. As with any new imaging technology, rheumatologists and radiologists need to consider adapting their arsenal of diagnostic, prognostic and monitoring tools, and even their clinical role and collaborations. This adaptation requires a basic understanding of the technical background of deep learning, to efficiently utilize its benefits but also to recognize its drawbacks and pitfalls, as blindly relying on deep learning might be at odds with its capabilities. To facilitate such an understanding, it is necessary to provide an overview of deep-learning techniques for automatic image analysis in detecting, quantifying, predicting and monitoring rheumatic diseases, and of currently published deep-learning applications in radiological imaging for rheumatology, with critical assessment of possible limitations, errors and confounders, and conceivable consequences for rheumatologists and radiologists in clinical practice.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Stoel:2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Learning in Rheumatologic Image Interpretation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Stoel, Berend C. and Staring, Marius and Reijnierse, Monique and van der Helm-van Mil, Annette H.M.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Reviews Rheumatology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{182 -- 195}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Chen:2024" class="col-sm-10"> <span class="title">CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation</span> <span class="author"> Yunjie Chen,&nbsp;<em>Marius Staring</em>,&nbsp;Olaf M. Neve , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Stephan R. Romeijn, Erik F. Hensen, Berit M. Verbist, Jelmer M. Wolterink, Qian Tao' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </span> <span class="periodical"> <em>The Journal of Machine Learning for Biomedical Imaging</em>, Mar 2024 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2309.03320" class="btn btn-sm z-depth-0" role="button">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.59275/j.melba.2024-d61g" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2024_j_MELBA.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/cyjdswx/CoNeS.git"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p>Multi-sequence magnetic resonance imaging (MRI) has found wide applications in both modern clinical studies and deep learning research. However, in clinical practice, it frequently occurs that one or more of the MRI sequences are missing due to different image acquisition protocols or contrast agent contraindications of patients, limiting the utilization of deep learning models trained on multi-sequence data. One promising approach is to leverage generative models to synthesize the missing sequences, which can serve as a surrogate acquisition. State-of-the-art methods tackling this problem are based on convolutional neural networks (CNN) which usually suffer from spectral biases, resulting in poor reconstruction of high-frequency fine details. In this paper, we propose Conditional Neural fields with Shift modulation (CoNeS), a model that takes voxel coordinates as input and learns a representation of the target images for multi-sequence MRI translation. The proposed model uses a multi-layer perceptron (MLP) instead of a CNN as the decoder for pixel-to-pixel mapping. Hence, each target image is represented as a neural field that is conditioned on the source image via shift modulation with a learned latent code. Experiments on BraTS 2018 and an in-house clinical dataset of vestibular schwannoma patients showed that the proposed method outperformed state-of-the-art methods for multi-sequence MRI translation both visually and quantitatively. Moreover, we conducted spectral analysis, showing that CoNeS was able to overcome the spectral bias issue common in conventional CNN models. To further evaluate the usage of synthesized images in clinical downstream tasks, we tested a segmentation network using the synthesized images at inference. The results showed that CoNeS improved the segmentation performance when some MRI sequences were missing and outperformed other synthesis models. We concluded that neural fields are a promising technique for multi-sequence MRI translation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Chen:2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yunjie and Staring, Marius and Neve, Olaf M. and Romeijn, Stephan R. and Hensen, Erik F. and Verbist, Berit M. and Wolterink, Jelmer M. and Tao, Qian}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Journal of Machine Learning for Biomedical Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{657 -- 685}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Chaves-de-Plaza:2025" class="col-sm-10"> <span class="title">Inclusion Depth for Contour Ensembles</span> <span class="author"> Nicolas Chaves-de-Plaza,&nbsp;Prerak P. Mody,&nbsp;<em>Marius Staring</em> , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'René; Egmond, Anna Vilanova, Klaus Hildebrandt' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Mar 2024 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/TVCG.2024.3350076" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2024_j_TVCG.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Ensembles of contours arise in various applications like simulation, computer-aided design, and semantic segmentation. Uncovering ensemble patterns and analyzing individual members is a challenging task that suffers from clutter. Ensemble statistical summarization can alleviate this issue by permitting analyzing ensembles’ distributional components like the mean and median, confidence intervals, and outliers. Contour boxplots, powered by Contour Band Depth (CBD), are a popular nonparametric ensemble summarization method that benefits from CBD’s generality, robustness, and theoretical properties. In this work, we introduce Inclusion Depth (ID), a new notion of contour depth with three defining characteristics. First, ID is a generalization of functional Half-Region Depth, which offers several theoretical guarantees. Second, ID relies on a simple principle: the inside/outside relationships between contours. This facilitates implementing ID and understanding its results. Third, the computational complexity of ID scales quadratically in the number of members of the ensemble, improving CBD’s cubic complexity. This also in practice speeds up the computation enabling the use of ID for exploring large contour ensembles or in contexts requiring multiple depth evaluations like clustering. In a series of experiments on synthetic data and case studies with meteorological and segmentation data, we evaluate ID’s performance and demonstrate its capabilities for the visual analysis of contour ensembles.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Chaves-de-Plaza:2025</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chaves-de-Plaza, Nicolas and Mody, Prerak P. and Staring, Marius and van Egmond, Ren{\'e}; and Vilanova, Anna and Hildebrandt, Klaus}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inclusion Depth for Contour Ensembles}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Visualization and Computer Graphics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Beljaards:2024" class="col-sm-10"> <span class="title">AI-Based Motion Artifact Severity Estimation in Undersampled MRI Allowing for Selection of Appropriate Reconstruction Models</span> <span class="author"> Laurens Beljaards,&nbsp;Nicola Pezzotti,&nbsp;Chinmay Rao , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Mariya Doneva, Matthias J.P. Osch, Marius Staring' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>Medical Physics</em>, Mar 2024 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/mp.16918" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2024_j_MP.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Background:</b> MR acquisition is a time consuming process, making it susceptible to patient motion during scanning. Even motion in the order of a millimeter can introduce severe blurring and ghosting artifacts, potentially necessitating re-acquisition. MRI can be accelerated by acquiring only a fraction of k-space, combined with advanced reconstruction techniques leveraging coil sensitivity profiles and prior knowledge. AI-based reconstruction techniques have recently been popularized, but generally assume an ideal setting without intra-scan motion.<br/><b>Purpose:</b> To retrospectively detect and quantify the severity of motion artifacts in undersampled MRI data. This may prove valuable as a safety mechanism for AI-based approaches, provide useful information to the reconstruction method, or prompt for re-acquisition while the patient is still in the scanner.<br/><b>Methods:</b> We developed a deep learning approach that detects and quantifies motion artifacts in undersampled brain MRI. We demonstrate that synthetically motion-corrupted data can be leveraged to train the CNN-based motion artifact estimator, generalizing well to real-world data. Additionally, we leverage the motion artifact estimator by using it as a selector for a motion-robust reconstruction model in case a considerable amount of motion was detected, and a high data consistency model otherwise.<br/><b>Results:</b> Training and validation were performed on 4387 and 1304 synthetically motion-corrupted images and their uncorrupted counterparts, respectively. Testing was performed on undersampled in vivo motion-corrupted data from 28 volunteers, where our model distinguished head motion from motion-free scans with 91% and 96% accuracy when trained on synthetic and on real data, respectively. It predicted a manually defined quality label (‘Good’, ‘Medium’ or ‘Bad’ quality) correctly in 76% and 85% of the time when trained on synthetic and real data, respectively. When used as a selector it selected the appropriate reconstruction network 93% of the time, achieving near optimal SSIM values.<br/><b>Conclusions:</b> The proposed method quantified motion artifact severity in undersampled MRI data with high accuracy, enabling real-time motion artifact detection that can help improve the safety and quality of AI-based reconstructions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Beljaards:2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Beljaards, Laurens and Pezzotti, Nicola and Rao, Chinmay and Doneva, Mariya and van Osch, Matthias J.P. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AI-Based Motion Artifact Severity Estimation in Undersampled MRI Allowing for Selection of Appropriate Reconstruction Models}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{51}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3555 -- 3565}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Jia:2023" class="col-sm-10"> <span class="title">Automatic pulmonary function estimation from chest CT scans using deep regression neural networks: the relation between structure and function in systemic sclerosis</span> <span class="author"> Jingnan Jia,&nbsp;Emiel R. Marges,&nbsp;Maarten K. Ninaber , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Lucia J.M. Kroft, Anne A. Schouffoer, Marius Staring, Berend C. Stoel' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>IEEE Access</em>, Nov 2023 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ACCESS.2023.3337639" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2023_j_Access.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Pulmonary function test (PFT) plays an important role in screening and following-up pulmonary involvement in systemic sclerosis (SSc). However, some patients are not able to perform PFT due to contraindications. In addition, it is unclear how lung function is affected by changes in lung structure in SSc. Therefore, this study aims to explore the potential of automatically estimating PFT results from chest CT scans of SSc patients and how different regions influence the estimation of PFT values. Deep regression networks were developed with transfer learning to estimate PFT from 316 SSc patients. Segmented lungs and vessels were used to mask the CT images to train the network with different inputs: from entire CT scan, lungs-only to vessels-only. The network trained by entire CT scans with transfer learning achieved an ICC of 0.71, 0.76, 0.80, and 0.81 for the estimation of DLCO, FEV1, FVC and TLC, respectively. The performance of the networks gradually decreased when trained on data from lungs-only and vessels-only. Regression attention maps showed that regions close to large vessels are highlighted more than other regions, and occasionally regions outside the lungs are highlighted. These experiments mean that apart from lungs and large vessels, other regions contribute to the estimation of PFTs. In addition, adding manually designed biomarkers increased the correlation (R) from 0.75, 0.74, 0.82, and 0.83 to 0.81, 0.83, 0.88, and 0.90, respectively. It means that that manually designed imaging biomarkers can still contribute to explaining the relation between lung function and structure.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Jia:2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jia, Jingnan and Marges, Emiel R. and Ninaber, Maarten K. and Kroft, Lucia J.M. and Schouffoer, Anne A. and Staring, Marius and Stoel, Berend C.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic pulmonary function estimation from chest CT scans using deep regression neural networks: the relation between structure and function in systemic sclerosis}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{135272 -- 135282}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Neve:2023" class="col-sm-10"> <span class="title">Automated 2-dimensional measurement of vestibular schwannoma: validity and accuracy of an artificial intelligence algorithm</span> <span class="author"> Olaf M. Neve,&nbsp;Stephan R. Romeijn,&nbsp;Yunjie Chen , and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Larissa Nagtegaal, Willem Grootjans, Jeroen C. Jansen, Marius Staring, Berit M. Verbist, Erik F. Hensen' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </span> <span class="periodical"> <em>Otolaryngology - Head and Neck Surgery</em>, Dec 2023 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/ohn.470" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2023_j_OHNS.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Objective.</b> Validation of automated 2-dimensional (2D) diameter measurements of vestibular schwannomas on magnetic resonance imaging (MRI).<br/><b>Study Design.</b>Retrospective validation study using 2 data sets containing MRIs of vestibular schwannoma patients.<br/><b>Setting.</b> University Hospital in The Netherlands.<br/><b>Methods.</b>Two data sets were used, 1 containing 1 scan per patient (n = 134) and the other containing at least 3 consecutive MRIs of 51 patients, all with contrast-enhanced T1 or high-resolution T2 sequences. 2D measurements of the maximal extrameatal diameters in the axial plane were automatically derived from a 3D-convolutional neural network compared to manual measurements by 2 human observers. Intra- and interobserver variabilities were calculated using the intraclass correlation coefficient (ICC), agreement on tumor progression using Cohen’s kappa.<br/><b>Results.</b> The human intra- and interobserver variability showed a high correlation (ICC: 0.98-0.99) and limits of agreement of 1.7 to 2.1 mm. Comparing the automated to human measurements resulted in ICC of 0.98 (95% confidence interval [CI]: 0.974; 0.987) and 0.97 (95% CI: 0.968; 0.984), with limits of agreement of 2.2 and 2.1 mm for diameters parallel and perpendicular to the posterior side of the temporal bone, respectively. There was satisfactory agreement on tumor progression between automated measurements and human observers (Cohen’s &kappa; = 0.77), better than the agreement between the human observers (Cohen’s &kappa; = 0.74).<br/><b>Conclusion.</b> Automated 2D diameter measurements and growth detection of vestibular schwannomas are at least as accurate as human 2D measurements. In clinical practice, measurements of the maximal extrameatal tumor (2D) diameters of vestibular schwannomas provide important complementary information to total tumor volume (3D) measurements. Combining both in an automated measurement algorithm facilitates clinical adoption.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Neve:2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Neve, Olaf M. and Romeijn, Stephan R. and Chen, Yunjie and Nagtegaal, Larissa and Grootjans, Willem and Jansen, Jeroen C. and Staring, Marius and Verbist, Berit M. and Hensen, Erik F.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated 2-dimensional measurement of vestibular schwannoma: validity and accuracy of an artificial intelligence algorithm}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Otolaryngology - Head and Neck Surgery}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{169}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1582 -- 1589}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Zhai:2023" class="col-sm-10"> <span class="title">Automated Quantification of the Pulmonary Vasculature in Pulmonary Embolism and Chronic Thromboembolic Pulmonary Hypertension</span> <span class="author"> Zhiwei Zhai,&nbsp;Gudula J.A.M. Boon,&nbsp;<em>Marius Staring</em> , and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Lisette F. Dam, Lucia J.M. Kroft, Irene Hernandez Giron, Maarten K. Ninaber, Harm Jan Bogaard, Lilian J. Meijboom, Anton Vonk Noordegraaf, Menno V. Huisman, Frederikus A. Klok, Berend C. Stoel' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">10 more authors</span> </span> <span class="periodical"> <em>Pulmonary Circulation</em>, Dec 2023 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/pul2.12223" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2023_j_PC.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>The particular mechanical obstruction of pulmonary embolism (PE) and chronic thromboembolic pulmonary hypertension (CTEPH) may affect pulmonary arteries and veins differently. Therefore, we evaluated whether pulmonary vascular morphology and densitometry using CT pulmonary angiography (CTPA) in arteries and veins could distinguish PE from CTEPH.<br/>We analyzed CTPA images from a convenience cohort of 16 PE patients, 6 CTEPH patients and 15 controls without PE or CTEPH. Pulmonary vessels were extracted with a graph-cuts method, and separated into arteries and veins using a deep-learning classification method. By analyzing the distribution of vessel radii, vascular morphology was quantified into a slope (&alpha;) and intercept (&beta;) for the entire pulmonary vascular tree, and for arteries and veins, separately. To quantify lung perfusion, the median pulmonary vascular density was calculated. As a reference, lung perfusion was also quantified by the contrast enhancement in the parenchymal areas, pulmonary trunk and descending aorta. All quantifications were compared between the three groups.<br/>Vascular morphology did not differ between groups, in contrast to vascular density values (both arterial and venous; p-values 0.006 - 0.014). The median vascular density (interquartile range) was -452 (95), -567 (113) and -470 (323) HU, for the PE, control and CTEPH group, respectively. The perfusion curves from all measurements showed different patterns between groups.<br/>In this proof of concept study, not vasculature morphology but vascular densities differentiated between normal and thrombotic obstructed vasculature. For distinction on an individual patient level, further technical improvements are needed both in terms of image acquisition/reconstruction and post-processing.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhai:2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhai, Zhiwei and Boon, Gudula J.A.M. and Staring, Marius and van Dam, Lisette F. and Kroft, Lucia J.M. and Giron, Irene Hernandez and Ninaber, Maarten K. and Bogaard, Harm Jan and Meijboom, Lilian J. and Vonk Noordegraaf, Anton and Huisman, Menno V. and Klok, Frederikus A. and Stoel, Berend C.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated Quantification of the Pulmonary Vasculature in Pulmonary Embolism and Chronic Thromboembolic Pulmonary Hypertension}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Pulmonary Circulation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e12223}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Goedmakers:2022" class="col-sm-10"> <span class="title">Machine learning for image analysis in the cervical spine: Systematic review of the available models and methods</span> <span class="author"> C.M.W Goedmakers,&nbsp;L.M. Pereboom,&nbsp;J.W. Schoones , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'M.L. Bouter, R.F. Remis, M. Staring, C.L.A. Vleggeert-Lankamp' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>Brain and Spine</em>, Dec 2022 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.bas.2022.101666" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2022_j_BandS.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><ul><li>Neural network approaches show the most potential for automated image analysis of thecervical spine.</li><li>Fully automatic convolutional neural network (CNN) models are promising Deep Learning methods for segmentation.</li><li>In cervical spine analysis, the biomechanical features are most often studied using finiteelement models.</li><li>The application of artificial neural networks and support vector machine models looks promising for classification purposes.</li><li>This article provides an overview of the methods for research on computer aided imaging diagnostics of the cervical spine.</li></ul></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Goedmakers:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Goedmakers, C.M.W and Pereboom, L.M. and Schoones, J.W. and de Leeuw den Bouter, M.L. and Remis, R.F. and Staring, M. and Vleggeert-Lankamp, C.L.A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine learning for image analysis in the cervical spine: Systematic review of the available models and methods}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Brain and Spine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{101666}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Neve:2022" class="col-sm-10"> <span class="title">Fully Automated 3D Vestibular Schwannoma Segmentation with and without Gadolinium Contrast: a multi-center, multi-vendor study</span> <span class="author"> Olaf Neve,&nbsp;Yunjie Chen,&nbsp;Qian Tao , and <span class="more-authors" title="click to view 9 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '9 more authors' ? 'Stephan Romeijn, Nick Boer, Willem Grootjans, Mark Kruit, Boudewijn Lelieveldt, Jeroen Jansen, Erik Hensen, Berit Verbist, Marius Staring' : '9 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">9 more authors</span> </span> <span class="periodical"> <em>Radiology: Artificial Intelligence</em>, Dec 2022 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1148/ryai.210300" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2022_j_RadAI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> To develop automated vestibular schwannoma measurements on contrast-enhanced T1- and T2-weighted MRI.<br/><b>Material and methods:</b> MRI data from 214 patients in 37 different centers was retrospectively analyzed between 2020-2021. Patients with hearing loss (134 vestibular schwannoma positive [mean age ± SD, 54 ± 12 years; 64 men], 80 negative) were randomized to a training and validation set and an independent test set. A convolutional neural network (CNN) was trained using five-fold cross-validation for two models (T1 and T2). Quantitative analysis including Dice index, Hausdorff distance, surface-to-surface distance (S2S), and relative volume error were used to compare the computer and the human delineations. Furthermore, an observer study was performed in which two experienced physicians evaluated both delineations.<br/><b>Results:</b> The T1-weighted model showed state-of-the-art performance with a mean S2S distance of less than 0.6 mm for the whole tumor and the intrameatal and extrameatal tumor parts. The whole tumor Dice index and Hausdorff distance were 0.92 and 2.1 mm in the independent test set. T2-weighted images had a mean S2S distance less than 0.6 mm for the whole tumor and the intrameatal and extrameatal tumor parts. Whole tumor Dice index and Hausdorff distance were 0.87 and 1.5 mm in the independent test set. The observer study indicated that the tool was comparable to human delineations in 85-92% of cases.<br/><b>Conclusion:</b> The CNN model detected and delineated vestibular schwannomas accurately on contrast-enhanced T1 and T2-weighted MRI and distinguished the clinically relevant difference between intrameatal and extrameatal tumor parts.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Neve:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Neve, Olaf and Chen, Yunjie and Tao, Qian and Romeijn, Stephan and de Boer, Nick and Grootjans, Willem and Kruit, Mark and Lelieveldt, Boudewijn and Jansen, Jeroen and Hensen, Erik and Verbist, Berit and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fully Automated 3D Vestibular Schwannoma Segmentation with and without Gadolinium Contrast: a multi-center, multi-vendor study}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Radiology: Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e210300}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Koolstra:2022" class="col-sm-10"> <span class="title">Subject-specific optimization of background suppression for arterial spin labeling MRI using a feedback loop on the scanner</span> <span class="author"> Kirsten Koolstra,&nbsp;<em>Marius Staring</em>,&nbsp;Paul Bruin , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Mathias J.P. Osch' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>NMR in Biomedicine</em>, Sep 2022 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/nbm.4746" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2022_j_NMR.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Background suppression (BGS) in arterial spin labeling (ASL) MRI leads to a higher temporal SNR (tSNR) of the perfusion images compared to ASL without BGS. The performance of the BGS, however, depends on the tissue relaxation times and on inhomogeneities of the scanner’s magnetic fields, which differ between subjects and are unknown at the moment of scanning. Therefore, we developed a feedback loop (FBL) mechanism that optimizes the BGS for each subject in the scanner during acquisition. We implemented the FBL for 2D pseudo-continuous ASL (PCASL) scans with an echo-planar imaging (EPI) readout. After each dynamic scan, acquired ASL images were automatically sent to an external computer and processed with a Python processing tool. Inversion times were optimized on-the-fly using 80 iterations of the Nelder-Mead method, by minimizing the signal intensity in the label image while maximizing the signal intensity in the perfusion image. The performance of this method was first tested in a 4-component phantom. The regularization parameter was then tuned in 6 healthy subjects (3 male, 3 female, age 24-62 years) and set as &lambda;=4 for all other experiments. Resulting ASL images, perfusion images and tSNR maps obtained from the last 20 iterations of the FBL scan were compared to those obtained without BGS and to standard BGS in 12 healthy volunteers (5 male, 7 female, age 24-62 years) (including the 6 volunteers used for tuning of &lambda;). The FBL resulted in perfusion images with a statistically significantly higher tSNR (2.20) compared to standard BGS (1.96) (P &lt; 5 10<sup>-3</sup>, two-sided paired t-test). Minimizing signal in the label image furthermore resulted in control images from which approximate changes in perfusion signal can directly be appreciated. This could be relevant to ASL applications that require a high temporal resolution. Future work is needed to minimize the number of initial acquisitions during which the performance of BGS is reduced compared to standard BGS and to extend the technique to 3D ASL.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Koolstra:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koolstra, Kirsten and Staring, Marius and de Bruin, Paul and van Osch, Mathias J.P.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subject-specific optimization of background suppression for arterial spin labeling MRI using a feedback loop on the scanner}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NMR in Biomedicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e4746}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Brink:2022" class="col-sm-10"> <span class="title">Personalised Local SAR Prediction for Parallel Transmit Neuroimaging at 7T from a Single T1-weighted Dataset</span> <span class="author"> Wyger M. Brink,&nbsp;Sahar Yousefi,&nbsp;Prerna Bhatnagar , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Rob F. Remis, Marius Staring, Andrew G. Webb' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>Magnetic Resonance in Medicine</em>, Jul 2022 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/mrm.29215" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2022_j_MRM.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/wygerbrink/PersonalizedDosimetry"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose.</b> Parallel RF transmission (PTx) is one of the key technologies enabling high quality imaging at ultrahigh field strengths (&ge;7T). Compliance with regulatory limits on the local specific absorption rate (SAR) typically involves over-conservative safety margins to account for intersubject variability, which negatively affect the utilization of ultra-high field MR. In this work, we present a method to generate a subject-specific body model from a single T1-weighted dataset for personalized local SAR prediction in PTx neuroimaging at 7T.<br/><b>Methods.</b> Multi-contrast data were acquired at 7T (N=10) to establish ground truth segmentations in eight tissue types. A 2.5D convolutional neural network was trained using the T1-weighted data as input in a leave-one-out cross-validation study. The segmentation accuracy was evaluated through local SAR simulations in a quadrature birdcage as well as a PTx coil model.<br/><b>Results.</b> The network-generated segmentations reached overall Dice coefficients of 86.7% &plusmn; 6.7% (mean &plusmn; standard deviation) and showed to successfully address the severe intensity bias and contrast variations typical to 7T. Errors in peak local SAR obtained were below 3.0% in the quadrature birdcage. Results obtained in the PTx configuration indicated that a safety margin of 6.3% ensures conservative local SAR estimates in 95% of the random RF shims, compared to an average overestimation of 34% in the generic "one-size-fits-all" approach.<br/><b>Conclusion.</b> A subject-specific body model can be automatically generated from a single T1-weighted dataset by means of deep learning, providing the necessary inputs for accurate and personalized local SAR predictions in PTx neuroimaging at 7T.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Brink:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brink, Wyger M. and Yousefi, Sahar and Bhatnagar, Prerna and Remis, Rob F. and Staring, Marius and Webb, Andrew G.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Personalised Local SAR Prediction for Parallel Transmit Neuroimaging at 7T from a Single T1-weighted Dataset}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Magnetic Resonance in Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{88}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{464 - 475}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Malimban:2022" class="col-sm-10"> <span class="title">Deep learning-based segmentation of the thorax in mouse micro-CT scans</span> <span class="author"> Justin Malimban,&nbsp;Danny Lathouwers,&nbsp;Haibin Qian , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Frank Verhaegen, Julia Wiedemann, Sytze Brandenburg, Marius Staring' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>Scientific Reports</em>, Jul 2022 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/s41598-022-05868-7" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2022_j_SR.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>For image-guided small animal irradiations, the whole workflow of imaging, organ contouring, irradiation planning, and delivery is typically performed in a single session requiring continuous administration of anesthetic agents. Automating contouring leads to a faster workflow, which limits exposure to anesthesia and thereby, reducing its impact on experimental results and on animal wellbeing. Here, we trained the 2D and 3D U-Net architectures of no-new-Net (nnU-Net) for autocontouring of the thorax in mouse micro-CT images. We trained the models only on native CTs and evaluated their performance using an independent testing dataset (i.e., native CTs not included in the training and validation). Unlike previous studies, we also tested the model performance on an external dataset (i.e., contrast-enhanced CTs) to see how well they predict on CTs completely different from what they were trained on. We also assessed the interobserver variability using the generalized conformity index (CIgen) among three observers, providing a stronger human baseline for evaluating automated contours than previous studies. Lastly, we showed the benefit on the contouring time compared to manual contouring. The results show that 3D models of nnU-Net achieve superior segmentation accuracy and are more robust to unseen data than 2D models. For all target organs, the mean surface distance (MSD) and the Hausdorff distance (95p HD) of the best performing model for this task (nnU-Net 3d_fullres) are within 0.16 mm and 0.60 mm, respectively. These values are below the minimum required contouring accuracy of 1 mm for small animal irradiations, and improve significantly upon state-of-the-art 2D U-Net-based AIMOS method. Moreover, the conformity indices of the 3d_fullres model also compare favourably to the interobserver variability for all target organs, whereas the 2D models perform poorly in this regard. Importantly, the 3d_fullres model offers 98% reduction in contouring time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Malimban:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep learning-based segmentation of the thorax in mouse micro-CT scans}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1822}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Elmahdy:2021" class="col-sm-10"> <span class="title">Joint Registration and Segmentation via Multi-Task Learning for Adaptive Radiotherapy of Prostate Cancer</span> <span class="author"> Mohamed S. Elmahdy,&nbsp;Laurens Beljaards,&nbsp;Sahar Yousefi , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Hessam Sokooti, Fons Verbeek, U.A. Heide, Marius Staring' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>IEEE Access</em>, Jun 2021 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2105.01844" class="btn btn-sm z-depth-0" role="button">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ACCESS.2021.3091011" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2021_j_Accessc.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/moelmahdy/JRS-MTL"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p>Medical image registration and segmentation are two of the most frequent tasks in medical image analysis. As these tasks are complementary and correlated, it would be beneficial to apply them simultaneously in a joint manner. In this paper, we formulate registration and segmentation as a joint problem via a Multi-Task Learning (MTL) setting, allowing these tasks to leverage their strengths and mitigate their weaknesses through the sharing of beneficial information. We propose to merge these tasks not only on the loss level, but on the architectural level as well. We studied this approach in the context of adaptive image-guided radiotherapy for prostate cancer, where planning and follow-up CT images as well as their corresponding contours are available for training. At testing time the contours of the follow-up scans are not available, which is a common scenario in adaptive radiotherapy. The study involves two datasets from different manufacturers and institutes. The first dataset was divided into training (12 patients) and validation (6 patients), and was used to optimize and validate the methodology, while the second dataset (14 patients) was used as an independent test set. We carried out an extensive quantitative comparison between the quality of the automatically generated contours from different network architectures as well as loss weighting methods. Moreover, we evaluated the quality of the generated deformation vector field (DVF). We show that MTL algorithms outperform their Single-Task Learning (STL) counterparts and achieve better generalization on the independent test set. The best algorithm achieved a mean surface distance of 1.06&pm;0.3 mm, 1.27&pm;0.4 mm, 0.91&pm;0.4 mm, and 1.76&pm;0.8 mm on the validation set for the prostate, seminal vesicles, bladder, and rectum, respectively. The high accuracy of the proposed method combined with the fast inference speed, makes it a promising method for automatic re-contouring of follow-up scans for adaptive radiotherapy, potentially reducing treatment related complications and therefore improving patients quality-of-life after treatment. The source code is available at <a href="https://github.com/moelmahdy/JRS-MTL">https://github.com/moelmahdy/JRS-MTL</a>.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Elmahdy:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Elmahdy, Mohamed S. and Beljaards, Laurens and Yousefi, Sahar and Sokooti, Hessam and Verbeek, Fons and van der Heide, U.A. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Joint Registration and Segmentation via Multi-Task Learning for Adaptive Radiotherapy of Prostate Cancer}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{95551 -- 95568}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Yousefi:2021" class="col-sm-10"> <span class="title">Esophageal Tumor Segmentation in CT Images using a Dilated Dense Attention Unet (DDAUnet)</span> <span class="author"> Sahar Yousefi,&nbsp;Hessam Sokooti,&nbsp;Mohamed S. Elmahdy , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Irene M. Lips, Mohammad T. Manzuri Shalmani, Roel T. Zinkstok, Frank J.W.M. Dankers, Marius Staring' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </span> <span class="periodical"> <em>IEEE Access</em>, Jul 2021 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2012.03242" class="btn btn-sm z-depth-0" role="button">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ACCESS.2021.3096270" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2021_j_Accessb.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/yousefis/DenseUnet_Esophagus_Segmentation"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p>Manual or automatic delineation of the esophageal tumor in CT images is known to be very challenging. This is due to the low contrast between the tumor and adjacent tissues, the anatomical variation of the esophagus, as well as the occasional presence of foreign bodies (e.g. feeding tubes). Physicians therefore usually exploit additional knowledge such as endoscopic findings, clinical history, additional imaging modalities like PET scans. Achieving his additional information is time-consuming, while the results are error-prone and might lead to non-deterministic results. In this paper we aim to investigate if and to what extent a simplified clinical workflow based on CT alone, allows one to automatically segment the esophageal tumor with sufficient quality. For this purpose, we present a fully automatic end-to-end esophageal tumor segmentation method based on convolutional neural networks (CNNs). The proposed network, called Dilated Dense Attention Unet (DDAUnet), leverages spatial and channel attention gates in each dense block to selectively concentrate on determinant feature maps and regions. Dilated convolutional layers are used to manage GPU memory and increase the network receptive field. We collected a dataset of 792 scans from 288 distinct patients including varying anatomies with air pockets, feeding tubes and proximal tumors. Repeatability and reproducibility studies were conducted for three distinct splits of training and validation sets. The proposed network achieved a DSC value of 0.79 &plusmn; 0.20, a mean surface distance of 5.4 &plusmn; 20.2mm and 95% Hausdorff distance of 14.7 &plusmn; 25.0mm for 287 test scans, demonstrating promising results with a simplified clinical workflow based on CT alone. Our code is publicly available via <a href="https://github.com/yousefis/DenseUnet_Esophagus_Segmentation">https://github.com/yousefis/DenseUnet_Esophagus_Segmentation</a>.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Yousefi:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yousefi, Sahar and Sokooti, Hessam and Elmahdy, Mohamed S. and Lips, Irene M. and Manzuri Shalmani, Mohammad T. and Zinkstok, Roel T. and Dankers, Frank J.W.M. and and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Esophageal Tumor Segmentation in CT Images using a Dilated Dense Attention Unet (DDAUnet)}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{99235 -- 99248}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Sokooti:2021" class="col-sm-10"> <span class="title">Hierarchical Prediction of Registration Misalignment using a Convolutional LSTM: Application to Chest CT Scans</span> <span class="author"> Hessam Sokooti,&nbsp;Sahar Yousefi,&nbsp;Mohamed S. Elmahdy , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Boudewijn P.F. Lelieveldt, Marius Staring' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </span> <span class="periodical"> <em>IEEE Access</em>, Apr 2021 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ACCESS.2021.3074124" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2021_j_Accessa.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>In this paper we propose a supervised method to predict registration misalignment using convolutional neural networks (CNNs). This task is casted to a classification problem with multiple classes of misalignment: "correct" 0-3 mm, "poor" 3-6 mm and "wrong" over 6 mm. Rather than a direct prediction, we propose a hierarchical approach, where the prediction is gradually refined from coarse to fine. Our solution is based on a convolutional Long Short-Term Memory (LSTM), using hierarchical misalignment predictions on three resolutions of the image pair, leveraging the intrinsic strengths of an LSTM for this problem. The convolutional LSTM is trained on a set of artificially generated image pairs obtained from artificial displacement vector fields (DVFs). Results on chest CT scans show that incorporating multi-resolution information, and the hierarchical use via an LSTM for this, leads to overall better F1 scores, with fewer misclassifications in a well-tuned registration setup. The final system yields an accuracy of 87.1%, and an average F1 score of 66.4% aggregated in two independent chest CT scan studies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Sokooti:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sokooti, Hessam and Yousefi, Sahar and Elmahdy, Mohamed S. and Lelieveldt, Boudewijn P.F. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Prediction of Registration Misalignment using a Convolutional LSTM: Application to Chest CT Scans}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{62008 -- 62020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Luu:2021" class="col-sm-10"> <span class="title">Efficiently Compressing 3D Medical Images for Teleinterventions via CNNs and Anisotropic Diffusion</span> <span class="author"> Ha Manh Luu,&nbsp;Theo Walsum,&nbsp;Daniel Franklin , and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Phuong Cam Pham, Luu Dang Vu, Adriaan Moelker, Marius Staring, Xiem Van Hoang, Wiro Niessen, Nguyen Linh Trung' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </span> <span class="periodical"> <em>Medical Physics</em>, Jun 2021 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/mp.14814" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2021_j_MP.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> Efficient compression of images while preserving image quality has the potential to be a major enabler of effective remote clinical diagnosis and treatment, since poor Internet connection conditions are often the primary constraint in such services. This paper presents a framework for organ-specific image compression for teleinterventions based on a deep learning approach and anisotropic diffusion filter.<br/><b>Methods:</b> The proposed method, DLAD, uses a CNN architecture to extract a probability map for the organ of interest; this probability map guides an anisotropic diffusion filter that smooths the image except at the location of the organ of interest. Subsequently, a compression method, such as BZ2 and HEVC-visually lossless, is applied to compress the image. We demonstrate the proposed method on 3D CT images acquired for radio frequency ablation (RFA) of liver lesions. We quantitatively evaluate the proposed method on 151 CT images using peak-signal-to-noise ratio (PSNR), structural similarity (SSIM) and compression ratio (CR) metrics. Finally, we compare the assessments of two radiologists on the liver lesion detection and the liver lesion center annotation using 33 sets of the original images and the compressed images.<br/><b>Results:</b> The results show that the method can significantly improve CR of most well-known compression methods. DLAD combined with HEVC-visually lossless achieves the highest average CR of 6.45, which is 36% higher than that of the original HEVC and outperforms other state-of-the-art lossless medical image compression methods. The means of PSNR and SSIM are 70 dB and 0.95, respectively. In addition, the compression effects do not statistically significantly affect the assessments of the radiologists on the liver lesion detection and the lesion center annotation.<br/><b>Conclusions:</b> We thus conclude that the method has a high potential to be applied in teleintervention applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Luu:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Luu, Ha Manh and van Walsum, Theo and Franklin, Daniel and Pham, Phuong Cam and Vu, Luu Dang and Moelker, Adriaan and Staring, Marius and Van Hoang, Xiem and Niessen, Wiro and Trung, Nguyen Linh}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficiently Compressing 3D Medical Images for Teleinterventions via CNNs and Anisotropic Diffusion}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{48}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2877 -- 2890}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Pezzotti:2020" class="col-sm-10"> <span class="title">An Adaptive Intelligence Algorithm for Undersampled Knee MRI Reconstruction</span> <span class="author"> Nicola Pezzotti,&nbsp;Sahar Yousefi,&nbsp;Mohamed S. Elmahdy , and <span class="more-authors" title="click to view 9 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '9 more authors' ? 'Jeroen Gemert, Christophe Schülke, Mariya Doneva, Tim Nielsen, Sergey Kastryulin, Boudewijn P.F. Lelieveldt, Matthias J.P. Osch, Elwin Weerdt, Marius Staring' : '9 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">9 more authors</span> </span> <span class="periodical"> <em>IEEE Access</em>, Jun 2020 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2004.07339" class="btn btn-sm z-depth-0" role="button">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ACCESS.2020.3034287" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2020_j_Access.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Adaptive intelligence aims at empowering machine learning techniques with the additional use of domain knowledge. In this work, we present the application of adaptive intelligence to accelerate MR acquisition. Starting from undersampled k-space data, an iterative learning-based reconstruction scheme inspired by compressed sensing theory is used to reconstruct the images. We developed a novel deep neural network to refine and correct prior reconstruction assumptions given the training data. The network was trained and tested on a knee MRI dataset from the 2019 fastMRI challenge organized by Facebook AI Research and NYU Langone Health. All submissions to the challenge were initially ranked based on similarity with a known groundtruth, after which the top 4 submissions were evaluated radiologically. Our method was evaluated by the fastMRI organizers on an independent challenge dataset. It ranked #1, shared #1, and #3 on respectively the 8x accelerated multi-coil, the 4x multi-coil, and the 4x single-coil tracks. This demonstrates the superior performance and wide applicability of the method.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pezzotti:2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pezzotti, Nicola and Yousefi, Sahar and Elmahdy, Mohamed S. and van Gemert, Jeroen and Sch{\"u}lke, Christophe and Doneva, Mariya and Nielsen, Tim and Kastryulin, Sergey and Lelieveldt, Boudewijn P.F. and van Osch, Matthias J.P. and de Weerdt, Elwin and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Adaptive Intelligence Algorithm for Undersampled Knee MRI Reconstruction}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{204825 -- 204838}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Zhao:2020" class="col-sm-10"> <span class="title">A framework for pulmonary fissure segmentation in 3D CT images using a directional derivative of plate filter</span> <span class="author"> Hong Zhao,&nbsp;Berend C. Stoel,&nbsp;<em>Marius Staring</em> , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'M. Els Bakker, Jan Stolk, Ping Zhou, Changyan Xiao' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>Signal Processing</em>, Aug 2020 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.sigpro.2020.107602" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2020_j_SP.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Imaging pulmonary fissures by CT provides useful information on diagnosis of pulmonary diseases. Automatic segmentation of fissures is a challenging task due to the variable appearance of fissures, such as inhomogeneous intensities, pathological deformation and imaging noise. To overcome these challenges, we propose an anisotropic differential operator called directional derivative of plate (DDoP) filter to probe the presence of fissure objects in 3D space by modeling the profile of a fissure patch with three parallel plates. To reduce the huge computation burden of dense matching with rotated DDoP kernels, a family of spherical harmonics are particularly utilized for acceleration. Additionally, a two-stage post-processing scheme is introduced to segment fissures. The performance of our method was verified in experiments using 55 scans from the publicly available LOLA11 dataset and 50 low-dose CT scans of lung cancer patients from the VIA-ELCAP database. Our method showed superior performance compared to the derivative of sticks (DoS) method and the Hessian-based method in terms of median and mean F1-score. The median F1-score for DDoP, DoS-based and Hessian-based methods on the LOLA11 dataset was 0.899, 0.848 and 0.843, respectively, and the mean F1-score was 0.858 &pm; 0.103, 0.781 &pm; 0.165 and 0.747 &pm; 0.239, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhao:2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhao, Hong and Stoel, Berend C. and Staring, Marius and Bakker, M. Els and Stolk, Jan and Zhou, Ping and Xiao, Changyan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A framework for pulmonary fissure segmentation in 3D CT images using a directional derivative of plate filter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Signal Processing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{173}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107602}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Yousefi:2019" class="col-sm-10"> <span class="title">A Novel Motion Detection Method Using 3D Discrete Wavelet Transform</span> <span class="author"> Sahar Yousefi,&nbsp;M. T. Manzuri Shalmani,&nbsp;Jeremy Lin , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marius Staring' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, Dec 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/TCSVT.2018.2885211" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_CSVT.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>The problem of motion detection has received considerable attention due to the explosive growth of its applications in video analysis and surveillance systems. While the previous approaches can produce good results, the accurate detection of motion remains a challenging task due to the difficulties raised by illumination variations, occlusion, camouflage, sudden motions appearing in burst, dynamic texture, and environmental changes such as those on weather conditions, sunlight changes during a day, etc. In this study, a novel per-pixel motion descriptor is proposed for motion detection in video sequences which outperforms the current methods in the literature particularly in severe scenarios. The proposed descriptor is based on two complementary three-dimensional discrete wavelet transforms (3D-DWT) and a three-dimensional wavelet leader. In this approach, a feature vector is extracted for each pixel by applying a novel three-dimensional wavelet-based motion descriptor. Then, the extracted features are clustered by the well-known K-means algorithm. The experimental results demonstrate the effectiveness of the proposed method compared to state-of-the-art approaches in several public benchmark datasets. The application of the proposed method and additional experimental results for several challenging datasets are available online.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Yousefi:2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yousefi, Sahar and Manzuri Shalmani, M. T. and Lin, Jeremy and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Novel Motion Detection Method Using 3D Discrete Wavelet Transform}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Circuits and Systems for Video Technology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3487 -- 3500}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="vandenEnde:2019a" class="col-sm-10"> <span class="title">Feasibility of gold fiducial markers as a surrogate for GTV position in image-guided radiotherapy of rectal cancer</span> <span class="author"> R.P.J. Ende,&nbsp;E.M. Kerkhof,&nbsp;L.S. Rigter , and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'M.E. Leerdam, F.P. Peters, B. Triest, M. Staring, C.A.M. Marijnen, U.A. Heide' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </span> <span class="periodical"> <em>International Journal of Radiation Oncology, Biology, Physics</em>, Dec 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.ijrobp.2019.08.052" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_IJROBP.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> To evaluate the feasibility of fiducial markers as a surrogate for GTV position in image-guided radiotherapy of rectal cancer.<br/><b>Methods and Materials:</b> We analyzed 35 fiducials in 19 rectal cancer patients who received short course radiotherapy or long-course chemoradiotherapy. A MRI exam was acquired before and after the first week of radiotherapy and daily pre- and post-irradiation CBCT scans were acquired in the first week of radiotherapy. Between the two MRI exams, the fiducial displacement relative to the center of gravity of the GTV (COGGTV) and the COGGTV displacement relative to bony anatomy was determined. Using the CBCT scans, inter- and intrafraction fiducial displacement relative to bony anatomy was determined.<br/><b>Results:</b> The systematic error of the fiducial displacement relative to the COG<sub>GTV</sub> was 2.8, 2.4 and 4.2 mm in the left-right (LR), anterior-posterior (AP) and craniocaudal (CC) direction. Large interfraction systematic errors of up to 8.0 and random errors up to 4.7 mm were found for COG<sub>GTV</sub> and fiducial displacements relative to bony anatomy, mostly in the AP and CC directions. For tumors located in the mid- and upper rectum these errors were up to 9.4 (systematic) and 5.6 mm (random) compared to 4.9 and 2.9 mm for tumors in the lower rectum. Systematic and random errors of the intrafraction fiducial displacement relative to bony anatomy were &le; 2.1 mm in all directions.<br/><b>Conclusions:</b> Large interfraction errors of the COG<sub>GTV</sub> and the fiducials relative to bony anatomy were found. Therefore, despite the observed fiducial displacement relative to the COG<sub>GTV</sub>, the use of fiducials as a surrogate for GTV position reduces the required margins in the AP and CC direction for a GTV boost using image-guided radiotherapy of rectal cancer. This reduction may be larger in patients with tumors located in the mid- and upper rectum compared to the lower rectum.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vandenEnde:2019a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{van den Ende, R.P.J. and Kerkhof, E.M. and Rigter, L.S. and van Leerdam, M.E. and Peters, F.P. and van Triest, B. and Staring, M. and Marijnen, C.A.M. and van der Heide, U.A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Feasibility of gold fiducial markers as a surrogate for GTV position in image-guided radiotherapy of rectal cancer}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Radiation Oncology, Biology, Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{105}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1151 -- 1159}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Qiao:2019a" class="col-sm-10"> <span class="title">Evaluation of an open source registration package for automatic contour propagation in online adaptive intensity-modulated proton therapy of prostate cancer</span> <span class="author"> Yuchuan Qiao,&nbsp;Thyrza Jagt,&nbsp;Mischa Hoogeman , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Boudewijn P.F. Lelieveldt, Marius Staring' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </span> <span class="periodical"> <em>Frontiers in Oncology</em>, Nov 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.3389/fonc.2019.01297" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_FiO.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/SuperElastix/elastix"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Objective:</b> Our goal was to investigate the performance of an open source deformable image registration package, elastix, for fast and robust contour propagation in the context of online adaptive intensity-modulated proton therapy (IMPT) for prostate cancer.<br/><b>Methods:</b> A planning and 7-10 repeat CT scans were available of 18 prostate cancer patients. Automatic contour propagation of repeat CT scans was performed using elastix and compared with manual delineations in terms of geometric accuracy and runtime. Dosimetric accuracy was quantified by generating IMPT plans using the propagated contours expanded with a 2 mm (prostate) and 3.5 mm margin (seminal vesicles and lymph nodes) and calculating dosimetric coverage based on the manual delineation. A coverage of V95% &geq; 98% (at least 98% of the target volumes receive at least 95% of the prescribed dose) was considered clinically acceptable.<br/><b>Results:</b> Contour propagation runtime varied between 3 and 30 seconds for different registration settings. For the fastest setting, 83 in 93 (89.2%), 73 in 93 (78.5%), and 91 in 93 (97.9%) registrations yielded clinically acceptable dosimetric coverage of the prostate, seminal vesicles, and lymph nodes, respectively. For the prostate, seminal vesicles, and lymph nodes the Dice Similarity Coefficient (DSC) was 0:87 &plusmn; 0:05, 0:63 &plusmn; 0:18 and 0:89 &plusmn; 0:03 and the mean surface distance (MSD) was 1:4 &plusmn; 0:5 mm, 2:0 &plusmn; 1:2 mm and 1:5 &plusmn; 0:4 mm, respectively.<br/><b>Conclusion:</b> With a dosimetric success rate of 78.5% to 97.9%, this software may facilitate online adaptive IMPT of prostate cancer using a fast, free and open implementation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Qiao:2019a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qiao, Yuchuan and Jagt, Thyrza and Hoogeman, Mischa and Lelieveldt, Boudewijn P.F. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Evaluation of an open source registration package for automatic contour propagation in online adaptive intensity-modulated proton therapy of prostate cancer}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Oncology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1297}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Zhai:2019a" class="col-sm-10"> <span class="title">Pulmonary Vascular Morphology Associated with Gas Exchange in Systemic Sclerosis without Lung Fibrosis</span> <span class="author"> Zhiwei Zhai,&nbsp;<em>Marius Staring</em>,&nbsp;Maarten K. Ninaber , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Jeska Vries-Bouwstra, Anne A. Schouffoer, Lucia J. Kroft, Jan Stolk, Berend C. Stoel' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </span> <span class="periodical"> <em>Journal of Thoracic Imaging</em>, Nov 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1097/RTI.0000000000000395" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_JTI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> Gas exchange in systemic sclerosis (SSc) is known to be affected by fibrotic changes in the pulmonary parenchyma. However, SSc patients without detectable fibrosis can still have impaired gas transfer. We aim to investigate whether pulmonary vascular changes could partly explain a reduction in gas transfer of systemic sclerosis (SSc) patients without fibrosis.<br/><b>Materials and Methods:</b> We selected 77 patients, whose visual CT scoring showed no fibrosis. Pulmonary vessels were detected automatically in CT images and their local radii were calculated. The frequency of occurrence for each radius was calculated, and from this radius histogram two imaging biomarkers (&alpha; and &beta;) were extracted, where &alpha; reflects the relative contribution of small vessels compared to large vessels and &beta; represents the vessel tree capacity. Correlations between imaging biomarkers and gas transfer (DLCOc %predicted) were evaluated with Spearman’s correlation. Multivariable stepwise linear regression was performed with DLCOc %predicted as dependent variable and age, BMI, sPAP, FEV1 %predicted, TLC %predicted, FVC %predicted, &alpha;, &beta;, voxel size and CT-derived lung volume as independent variables.<br/><b>Results:</b> Both &alpha; and &beta; were significantly correlated with gas transfer (R=-0.29, p-value=0.011 and R=0.32, p-value=0.004, respectively). The multivariable step-wise linear regression analysis selected sPAP (coefficient=-0.78, 95%CI=[-1.07, -0.49], p-value&lt;0.001), &beta; (coefficient=8.6, 95%CI=[4.07, 13.1], p-value&lt;0.001) and FEV1 %predicted (coefficient=0.3, 95%CI=[0.12, 0.48], p-value=0.001) as significant independent predictors of DLCOc %predicted (R=0.71, p-value&lt;0.001).<br/><b>Conclusions:</b>In SSc patients without detectable pulmonary fibrosis, pulmonary vascular morphology is associated with gas transfer, indicating that impaired gas exchange is associated with vascular changes.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhai:2019a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhai, Zhiwei and Staring, Marius and Ninaber, Maarten K. and de Vries-Bouwstra, Jeska and Schouffoer, Anne A. and Kroft, Lucia J. and Stolk, Jan and Stoel, Berend C.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pulmonary Vascular Morphology Associated with Gas Exchange in Systemic Sclerosis without Lung Fibrosis}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Thoracic Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{373 -- 379}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Qiao:2019b" class="col-sm-10"> <span class="title">An efficient preconditioner for stochastic gradient descent optimization of image registration</span> <span class="author"> Yuchuan Qiao,&nbsp;Boudewijn P.F Lelieveldt,&nbsp;and&nbsp;<em>Marius Staring</em> </span> <span class="periodical"> <em>IEEE Transactions on Medical Imaging</em>, Oct 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/TMI.2019.2897943" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_TMI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/SuperElastix/elastix"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p>Stochastic gradient descent (SGD) is commonly used to solve (parametric) image registration problems. In case of badly scaled problems, SGD however only exhibits sublinear convergence properties. In this paper we propose an efficient preconditioner estimation method to improve the convergence rate of SGD. Based on the observed distribution of voxel displacements in the registration, we estimate the diagonal entries of a preconditioning matrix, thus rescaling the optimization cost function. The preconditioner is efficient to compute and employ, and can be used for mono-modal as well as multi-modal cost functions, in combination with different transformation models like the rigid, affine and B-spline model. Experiments on different clinical data sets show that the proposed method indeed improves the convergence rate compared to SGD with speedups around 2-5 in all tested settings, while retaining the same level of registration accuracy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Qiao:2019b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qiao, Yuchuan and Lelieveldt, Boudewijn P.F and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An efficient preconditioner for stochastic gradient descent optimization of image registration}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2314 -- 2325}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Bayer:2019" class="col-sm-10"> <span class="title">Registration of vascular structures using a hybrid mixture model</span> <span class="author"> Siming Bayer,&nbsp;Zhiwei Zhai,&nbsp;Maddalena Strumia , and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Xiaoguang Tong, Ying Gao, Marius Staring, Berend Stoel, Rebecca Fahrig, Arya Nabavi, Andreas Maier, Nishant Ravikumar' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </span> <span class="periodical"> <em>International Journal of Computer Assisted Radiology and Surgery</em>, Sep 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/s11548-019-02007-y" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_IJCARS.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> Morphological changes to anatomy resulting from invasive surgical procedures or pathology, typically alter the surrounding vasculature. This makes it useful as a descriptor for feature-driven image registration in various clinical applications. However, registration of vasculature remains challenging, as vessels often differ in size and shape, and may even miss branches, due to surgical interventions or pathological changes. Furthermore, existing vessel registration methods are typically designed for a specific application. To address this limitation, we propose a generic vessel registration approach useful for a variety of clinical applications, involving different anatomical regions.<br/><b>Methods:</b> A probabilistic registration framework based on a hybrid mixture model, with a refinement mechanism to identify missing branches (denoted as HdMM+) during vasculature matching, is introduced. Vascular structures are represented as 6-dimensional hybrid point sets comprising spatial positions and centerline orientations, using Student’s t-distributions to model the former and Watson distributions for the latter.<br/><b>Results:</b> The proposed framework is evaluated for intraoperative brain shift compensation, and monitoring changes in pulmonary vasculature resulting from chronic lung disease. Registration accuracy is validated using both synthetic and patient data. Our results demonstrate, HdMM+ is able to reduce more than 85% of the initial error for both applications, and outperforms the state-of-the-art point-based registration methods such as coherent point drift (CPD) and Student’s t-Distribution mixture model (TMM), in terms of mean surface distance, modified hausdorff distance, Dice and Jaccard scores.<br/><b>Conclusion:</b> The proposed registration framework models complex vascular structures using a hybrid representation of vessel centerlines, and accommodates intricate variations in vascular morphology. Furthermore, it is generic and flexible in its design, enabling its use in a variety of clinical applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Bayer:2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bayer, Siming and Zhai, Zhiwei and Strumia, Maddalena and Tong, Xiaoguang and Gao, Ying and Staring, Marius and Stoel, Berend and Fahrig, Rebecca and Nabavi, Arya and Maier, Andreas and Ravikumar, Nishant}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Registration of vascular structures using a hybrid mixture model}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Computer Assisted Radiology and Surgery}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1507 -- 1516}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Zhai:2019b" class="col-sm-10"> <span class="title">Automatic quantitative analysis of pulmonary vascular morphology in CT images</span> <span class="author"> Zhiwei Zhai,&nbsp;<em>Marius Staring</em>,&nbsp;Irene Hernandez Giron , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Wouter J.H. Veldkamp, Lucia J. Kroft, Maarten K. Ninaber, Berend C. Stoel' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>Medical Physics</em>, Sep 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/mp.13659" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_MPb.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> Vascular remodeling is a significant pathological feature of various pulmonary diseases, which may be assessed by quantitative CT imaging. The purpose of this study was therefore to develop and validate an automatic method for quantifying pulmonary vascular morphology in CT images.<br/><b>Methods:</b> The proposed method consists of pulmonary vessel extraction and quantification. For extracting pulmonary vessels, a graph-cuts based method is proposed which considers appearance (CT intensity) and shape (vesselness from a Hessian-based filter) features, and incorporates distance to the airways into the cost function to prevent false detection of airway walls. For quantifying the extracted pulmonary vessels, a radius histogram is generated by counting the occurrence of vessel radii, calculated from a distance transform based method. Subsequently, two biomarkers, slope &alpha; and intercept &beta;, are calculated by linear regression on the radius histogram. A public data set from the VESSEL12 challenge was used to independently evaluate the vessel extraction. The quantitative analysis method was validated using images of a 3D printed vessel phantom, scanned by a clinical CT scanner and a micro-CT scanner (to obtain a gold standard). To confirm the association between imaging biomarkers and pulmonary function, 77 scleroderma patients were investigated with the proposed method.<br/><b>Results:</b> In the independent evaluation with the public data set, our vessel segmentation method obtained an area under the ROC curve of 0.976. The median radius difference between clinical and micro-CT scans of a 3D printed vessel phantom was 0.062 &plusmn; 0.020 mm, with interquartile range of 0.199 &plusmn; 0.050 mm. In the studied patient group, a significant correlation between diffusion capacity for carbon monoxide and the biomarkers, &alpha; (R=-0.27, p-value=0.018) and &beta; (R=0.321, p-value=0.004), was obtained.<br/><b>Conclusions:</b> In conclusion, the proposed method was highly accurate, validated with a public data set and a 3D printed vessel phantom data set. The correlation between imaging biomarkers and diffusion capacity in a clinical data set confirmed an association between lung structure and function. This quantification of pulmonary vascular morphology may be helpful in understanding the pathophysiology of pulmonary vascular diseases.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhai:2019b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhai, Zhiwei and Staring, Marius and Giron, Irene Hernandez and Veldkamp, Wouter J.H. and Kroft, Lucia J. and Ninaber, Maarten K. and Stoel, Berend C.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic quantitative analysis of pulmonary vascular morphology in CT images}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3985 -- 3997}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Elmahdy:2019" class="col-sm-10"> <span class="title">Robust contour propagation using deep learning and image registration for online adaptive proton therapy of prostate cancer</span> <span class="author"> Mohamed S. Elmahdy,&nbsp;Thyrza Jagt,&nbsp;Roel Th. Zinkstok , and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Yuchuan Qiao, Rahil Shazad, Hessam Sokooti, Sahar Yousefi, Luca Incrocci, Corrie A.M. Marijnen, Mischa Hoogeman, Marius Staring' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </span> <span class="periodical"> <em>Medical Physics</em>, Aug 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/mp.13620" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_MPa.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose:</b> To develop and validate a robust and accurate registration pipeline for automatic contour propagation for online adaptive Intensity-Modulated Proton Therapy (IMPT) of prostate cancer using elastix software and deep learning.<br/><b>Methods:</b> A 3D Convolutional Neural Network was trained for automatic bladder segmentation of the CT scans. The automatic bladder segmentation alongside the CT scan are jointly optimized to add explicit knowledge about the underlying anatomy to the registration algorithm. We included three datasets from different institutes and CT manufacturers. The first was used for training and testing the ConvNet, where the second and the third were used for evaluation of the proposed pipeline. The system performance was quantified geometrically using the Dice Similarity Coefficient (DSC), the Mean Surface Distance (MSD), and the 95% Hausdorff Distance (HD). The propagated contours were validated clinically through generating the associated IMPT plans and compare it with the IMPT plans based on the manual delineations. Propagated contours were considered clinically acceptable if their treatment plans met the dosimetric coverage constraints on the manual contours.<br/><b>Results:</b> The bladder segmentation network achieved a DSC of 88% and 82% on the test datasets. The proposed registration pipeline achieved a MSD of 1.29 &plusmn; 0.39, 1.48 &plusmn; 1.16, and 1.49 &plusmn; 0.44 mm for the prostate, seminal vesicles, and lymph nodes, respectively on the second dataset and a MSD of 2.31 &plusmn; 1.92 and 1.76 &plusmn; 1.39 mm for the prostate and seminal vesicles on the third dataset. The automatically propagated contours met the dose coverage constraints in 86%, 91%, and 99% of the cases for the prostate, seminal vesicles, and lymph nodes, respectively. A Conservative Success Rate (CSR) of 80% was obtained, compared to 65% when only using intensity-based registration.<br/><b>Conclusions:</b> The proposed registration pipeline obtained highly promising results for generating treatment plans adapted to the daily anatomy. With 80% of the automatically generated treatment plans directly usable without manual correction, a substantial improvement in system robustness was reached compared to a previous approach. The proposed method therefore facilitates more precise proton therapy of prostate cancer, potentially leading to fewer treatment related adverse side effects.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Elmahdy:2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Elmahdy, Mohamed S. and Jagt, Thyrza and Zinkstok, Roel Th. and Qiao, Yuchuan and Shazad, Rahil and Sokooti, Hessam and Yousefi, Sahar and Incrocci, Luca and Marijnen, Corrie A.M. and Hoogeman, Mischa and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust contour propagation using deep learning and image registration for online adaptive proton therapy of prostate cancer}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3329 -- 3343}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Sokooti:2019" class="col-sm-10"> <span class="title">Quantitative Error Prediction of Medical Image Registration using Regression Forests</span> <span class="author"> Hessam Sokooti,&nbsp;Gorkem Saygili,&nbsp;Ben Glocker , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Boudewijn P.F. Lelieveldt, Marius Staring' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </span> <span class="periodical"> <em>Medical Image Analysis</em>, Aug 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.media.2019.05.005" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_MedIAb.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Predicting registration error can be useful for evaluation of registration procedures, which is important for the adoption of registration techniques in the clinic. In addition, quantitative error prediction can be helpful in improving the registration quality. The task of predicting registration error is demanding due to the lack of a ground truth in medical images. This paper proposes a new automatic method to predict the registration error in a quantitative manner, and is applied to chest CT scans. A random regression forest is utilized to predict the registration error locally. The forest is built with features related to the transformation model and features related to the dissimilarity after registration. The forest is trained and tested using manually annotated corresponding points between pairs of chest CT scans in two experiments: SPREAD (trained and tested on SPREAD) and inter-database (including three databases SPREAD, DIR-Lab-4DCT and DIR-Lab-COPDgene). The results show that the mean absolute errors of regression are 1.07 &plusmn; 1.86 and 1.76 &plusmn; 2.59 mm for the SPREAD and inter-database experiment, respectively. The overall accuracy of classification in three classes (correct, poor and wrong registration) is 90.7% and 75.4%, for SPREAD and inter-database respectively. The good performance of the proposed method enables important applications such as automatic quality control in large-scale image analysis.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Sokooti:2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sokooti, Hessam and Saygili, Gorkem and Glocker, Ben and Lelieveldt, Boudewijn P.F. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Quantitative Error Prediction of Medical Image Registration using Regression Forests}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{56}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{110 -- 121}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="vandenEnde:2019b" class="col-sm-10"> <span class="title">MRI visibility of gold fiducial markers for image-guided radiotherapy of rectal cancer</span> <span class="author"> R.P.J. Ende,&nbsp;L.S. Rigter,&nbsp;E.M. Kerkhof , and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'E.L. Meerten, E.C. Rijkmans, D.M.J. Lambregts, B. Triest, M.E. Leerdam, M. Staring, C.A.M. Marijnen, U.A. Heide' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </span> <span class="periodical"> <em>Radiotherapy &amp; Oncology</em>, Mar 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.radonc.2018.11.016" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_RO.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Background and purpose:</b> A GTV boost is suggested to result in higher complete response rates in rectal cancer patients, which is attractive for organ preservation. Fiducials may offer GTV position verification on (CB)CT, if the fiducial-GTV spatial relationship can be accurately defined on MRI. The study aim was to evaluate the MRI visibility of fiducials inserted in the rectum.<br/><b>Materials and methods:</b> We tested four fiducial types (two Visicoil types, Cook and Gold Anchor), inserted in five patients each. Four observers identified fiducial locations on two MRI exams per patient in two scenarios: without (scenario A) and with (scenario B) (CB)CT available. A fiducial was defined to be consistently identified if 3 out of 4 observers labeled that fiducial at the same position on MRI. Fiducial visibility was scored on an axial and sagittal T2-TSE sequence and a T1 3D GRE sequence.<br/><b>Results:</b> Fiducial identification was poor in scenario A for all fiducial types. The Visicoil 0.75 and Gold Anchor were the most consistently identified fiducials in scenario B with 7 out of 9 and 8 out of 11 consistently identified fiducials in the first MRI exam and 2 out of 7 and 5 out of 10 in the second MRI exam, respectively. The consistently identified Visicoil 0.75 and Gold Anchor fiducials were best visible on the T1 3D GRE sequence.<br/><b>Conclusion:</b> The Visicoil 0.75 and Gold Anchor fiducials were the most visible fiducials on MRI as they were most consistently identified. The use of a registered (CB)CT and a T1 3D GRE MRI sequence is recommended.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vandenEnde:2019b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{van den Ende, R.P.J. and Rigter, L.S. and Kerkhof, E.M. and van Persijn van Meerten, E.L. and Rijkmans, E.C. and Lambregts, D.M.J. and van Triest, B. and van Leerdam, M.E. and Staring, M. and Marijnen, C.A.M. and van der Heide, U.A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MRI visibility of gold fiducial markers for image-guided radiotherapy of rectal cancer}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Radiotherapy &amp; Oncology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{132}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{93 -- 99}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="DeVos:2019" class="col-sm-10"> <span class="title">A Deep Learning Framework for Unsupervised Affine and Deformable Image Registration</span> <span class="author"> Bob De Vos,&nbsp;Floris F. Berendsen,&nbsp;Max A. Viergever , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Hessam Sokooti, Marius Staring, Ivana Išgum' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>Medical Image Analysis</em>, Feb 2019 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.media.2018.11.010" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2019_j_MedIAa.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Image registration, the process of aligning two or more images, is the core technique of many (semi-)automatic medical image analysis tasks. Recent studies have shown that deep learning methods, notably convolutional neural networks (ConvNets), can be used for image registration. Thus far training of ConvNets for registration was supervised using predefined example registrations. However, obtaining example registrations is not trivial. To circumvent the need for predefined examples, and thereby to increase convenience of training ConvNets for image registration, we propose the Deep Learning Image Registration (DLIR) framework for unsupervised affine and deformable image registration. In the DLIR framework ConvNets are trained for image registration by exploiting image similarity analogous to conventional intensity-based image registration. After a ConvNet has been trained with the DLIR framework, it can be used to register pairs of unseen images in one shot. We propose flexible ConvNets designs for affine image registration and for deformable image registration. By stacking multiple of these ConvNets into a larger architecture, we are able to perform coarse-to-fine image registration. We show for registration of cardiac cine MRI and registration of chest CT that performance of the DLIR framework is comparable to conventional image registration while being several orders of magnitude faster.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DeVos:2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{De Vos, Bob and Berendsen, Floris F. and Viergever, Max A. and Sokooti, Hessam and Staring, Marius and I{\v{s}}gum, Ivana}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Deep Learning Framework for Unsupervised Affine and Deformable Image Registration}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{52}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{128 -- 143}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Sun:2018" class="col-sm-10"> <span class="title">Integrating Spatial-Anatomical Regularization and Structure Sparsity into SVM: Improving Interpretation of Alzheimer’s Disease Classification</span> <span class="author"> Zhuo Sun,&nbsp;Yuchuan Qiao,&nbsp;Boudewijn P.F. Lelieveldt , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marius Staring' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>NeuroImage</em>, Sep 2018 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.neuroimage.2018.05.051" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2018_j_NI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>In recent years, machine learning approaches have been successfully applied to the field of neuroimaging for classification and regression tasks. However, many approaches do not give an intuitive relation between the raw features and the diagnosis. Therefore, they are difficult for clinicians to interpret. Moreover, most approaches treat the features extracted from the brain (for example, voxelwise gray matter concentration maps from brain MRI) as independent variables and ignore their spatial and anatomical relations. In this paper, we present a new Support Vector Machine (SVM)-based learning method for the classification of Alzheimer’s disease (AD), which integrates spatial-anatomical information. In this way, spatial-neighbor features in the same anatomical region are encouraged to have similar weights in the SVM model. Secondly, to make the learned model more interpretable, we introduce a group lasso penalty to induce structure sparsity, which may help clinicians to assess the key regions involved in the disease. For solving this learning problem, we use an accelerated proximal gradient descent approach. We tested our method on the subset of ADNI data selected by Cuingnet et al. (2011) for Alzheimer’s disease classification, as well as on an independent larger dataset from ADNI. Good classification performance is obtained for distinguishing cognitive normals (CN) vs. AD, as well as on distinguishing between various sub-types (e.g. CN vs. Mild Cognitive Impairment). The model trained on Cuignet’s dataset for AD vs. CN classification was directly used without re-training to the independent larger dataset. Good performance was achieved, demonstrating the generalizability of the proposed methods. For all experiments, the classification results are comparable or better than the state-of-the-art, while the weight map more clearly indicates the key regions related to Alzheimer’s disease.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Sun:2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Zhuo and Qiao, Yuchuan and Lelieveldt, Boudewijn P.F. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Integrating Spatial-Anatomical Regularization and Structure Sparsity into SVM: Improving Interpretation of Alzheimer's Disease Classification}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NeuroImage}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{178}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{445 -- 460}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Zhai:2018" class="col-sm-10"> <span class="title">Treatment Effect of Balloon Pulmonary Angioplasty in Chronic Thromboembolic Pulmonary Hypertension Quantified by Automatic Comparative Imaging in Computed Tomography Pulmonary Angiography</span> <span class="author"> Zhiwei Zhai,&nbsp;Hideki Ota,&nbsp;<em>Marius Staring</em> , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Jan Stolk, Koichiro Sugimura, Kei Takase, Berend C. Stoel' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </span> <span class="periodical"> <em>Investigative Radiology</em>, May 2018 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1097/RLI.0000000000000441" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2018_j_IR.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Objectives:</b> Balloon pulmonary angioplasty (BPA) in patients with inoperable chronic thromboembolic pulmonary hypertension (CTEPH) can have variable outcomes. To gain more insight into this variation, we designed a method for visualizing and quantifying changes in pulmonary perfusion by automatically comparing computed tomography (CT) pulmonary angiography before and after BPA treatment. We validated these quantifications of perfusion changes against hemodynamic changes measured with right-sided heart catheterization.<br/><b>Materials and Methods:</b> We studied 14 consecutive CTEPH patients (12 women; age, 70.5 \pm 24), who underwent CT pulmonary angiography and right-sided heart catheterization, before and after BPA. Posttreatment images were registered to pretreatment CT scans (using the Elastix toolbox) to obtain corresponding locations. Pulmonary vascular trees and their centerlines were detected using a graph cuts method and a distance transform method, respectively. Areas distal from vessels were defined as pulmonary parenchyma. Subsequently, the density changes within the vascular centerlines and parenchymal areas were calculated and corrected for inspiration level differences. For visualization, the densitometric changes were displayed in color-coded overlays. For quantification, the median and interquartile range of the density changes in the vascular and parenchymal areas (&Delta;VD and &Delta;PD) were calculated. The recorded changes in hemodynamic parameters, including changes in systolic, diastolic, mean pulmonary artery pressure (&Delta;sPAP, &Delta;dPAP and &Delta;mPAP, respectively) and vascular resistance (&Delta;PVR), were used as reference assessments of the treatment effect. Spearman correlation coefficients were employed to investigate the correlations between changes in perfusion and hemodynamic changes.<br/><b>Results:</b> Comparative imaging maps showed distinct patterns in perfusion changes among patients. Within pulmonary vessels, the interquartile range of &Delta;VD correlated significantly with &Delta;sPAP (R= 0.58, p=0.03), &Delta;dPAP (R= 0.71, p=0.005), &Delta;mPAP (R= 0.71, p=0.005), and &Delta;PVR (R= 0.77, p=0.001). In the parenchyma, the median of &Delta;PD had significant correlations with &Delta;dPAP (R= 0.58, p=0.030) and &Delta;mPAP (R= 0.59, p=0.025).<br/><b>Conclusions:</b> Comparative imaging analysis in CTEPH patients offers insight into differences in BPA treatment effect. Quantification of perfusion changes provides noninvasive measures that reflect hemodynamic changes.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhai:2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhai, Zhiwei and Ota, Hideki and Staring, Marius and Stolk, Jan and Sugimura, Koichiro and Takase, Kei and Stoel, Berend C.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Treatment Effect of Balloon Pulmonary Angioplasty in Chronic Thromboembolic Pulmonary Hypertension Quantified by Automatic Comparative Imaging in Computed Tomography Pulmonary Angiography}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Investigative Radiology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{53}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{286 -- 292}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Shahzad:2017" class="col-sm-10"> <span class="title">Fully-Automatic Left Ventricular Segmentation from Long-Axis Cardiac Cine MR Scans</span> <span class="author"> Rahil Shahzad,&nbsp;Qian Tao,&nbsp;Oleh Dzyubachyk , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Marius Staring, Boudewijn P.F. Lelieveldt, Rob J. Geest' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>Medical Image Analysis</em>, Jul 2017 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://doi.org/10.1016/j.media.2017.04.004" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2017_j_MedIA.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>With an increasing number of large-scale population-based cardiac magnetic resonance (CMR) imaging studies being conducted nowadays, there comes the mammoth task of image annotation and image analysis. Such population-based studies would greatly benefit from automated pipelines, with an efficient CMR image analysis workflow. The purpose of this work is to investigate the feasibility of using a fully-automatic pipeline to segment the left ventricular endocardium and epicardium simultaneously on two orthogonal (vertical and horizontal) long-axis cardiac cine MRI scans. The pipeline is based on a multi-atlas-based segmentation approach and a spatio-temporal registration approach. The performance of the method was assessed by: (i) comparing the automatic segmentations to those obtained manually at both the end-diastolic and end-systolic phase, (ii) comparing the automatically obtained clinical parameters, including end-diastolic volume, end-systolic volume, stroke volume and ejection fraction, with those defined manually and (iii) by the accuracy of classifying subjects to the appropriate risk category based on the estimated ejection fraction. Automatic segmentation of the left ventricular endocardium was achieved with a Dice similarity coefficient (DSC) of 0.93 on the end-diastolic phase for both the vertical and horizontal long-axis scan; on the end-systolic phase the DSC was 0.88 and 0.85, respectively. For the epicardium, a DSC of 0.94 and 0.95 was obtained on the end-diastolic vertical and horizontal long-axis scans; on the end-systolic phase the DSC was 0.90 and 0.88, respectively. With respect to the clinical volumetric parameters, Pearson correlation coefficient (R) of 0.97 was obtained for the end-diastolic volume, 0.95 for end-systolic volume, 0.87 for stroke volume and 0.84 for ejection fraction. Risk category classification based on ejection fraction showed that 80% of the subjects were assigned to the correct risk category and only one subject (\lt 1%) was more than one risk category off. We conclude that the proposed automatic pipeline presents a viable and cost-effective alternative for manual annotation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Shahzad:2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shahzad, Rahil and Tao, Qian and Dzyubachyk, Oleh and Staring, Marius and Lelieveldt, Boudewijn P.F. and van der Geest, Rob J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fully-Automatic Left Ventricular Segmentation from Long-Axis Cardiac Cine MR Scans}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{39}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{44 -- 55}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Sun:2017" class="col-sm-10"> <span class="title">Detection of conversion from mild cognitive impairment to Alzheimer’s disease using longitudinal brain MRI</span> <span class="author"> Zhuo Sun,&nbsp;Martijn Giessen,&nbsp;Boudewijn P.F. Lelieveldt , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marius Staring' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>Frontiers in Neuroinformatics</em>, Feb 2017 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.3389/fninf.2017.00016" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2017_j_FNI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Mild Cognitive Impairment (MCI) is an intermediate stage between healthy and Alzheimer’s disease (AD). To enable early intervention it is important to identify the MCI subjects that will convert to AD in an early stage. In this paper, we provide a new method to distinguish between MCI patients that either convert to Alzheimer’s Disease (MCIc) or remain stable (MCIs), using only longitudinal T1-weighted MRI. Currently, most longitudinal studies focus on volumetric comparison of a few anatomical structures, thereby ignoring more detailed development inside and outside those structures. In this study we propose to exploit the anatomical development within the entire brain, as found by a non-rigid registration approach. Specifically, this anatomical development is represented by the stationary velocity field (SVF) from registration between the baseline and follow-up images. To make the SVFs comparable among subjects, we use the parallel transport method to align them in a common space. The normalized SVF together with derived features are then used to distinguish between MCIc and MCIs subjects. This novel feature space is reduced using a Kernel Principal Component Analysis method, and a linear support vector machine is used as a classifier. Extensive comparative experiments are performed to inspect the influence of several aspects of our method on classification performance, specifically the feature choice, the smoothing parameter in the registration and the use of dimensionality reduction. The optimal result from a 10-fold cross-validation using 36 month follow-up data shows competitive results: accuracy 92%, sensitivity 95%, specificity 90%, and AUC 94%. Based on the same dataset, the proposed approach outperforms two alternative ones that either depends on the baseline image only, or uses longitudinal information from larger brain areas. Good results were also obtained when scans at 6, 12 or 24 months were used for training the classifier. Besides the classification power, the proposed method can quantitatively compare brain regions that have a significant difference in development between the MCIc and MCIs groups.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Sun:2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Zhuo and van der Giessen, Martijn and Lelieveldt, Boudewijn P.F. and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Detection of conversion from mild cognitive impairment to Alzheimer's disease using longitudinal brain MRI}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroinformatics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Dzyubachyk:2017" class="col-sm-10"> <span class="title">Inter-Station Intensity Standardization for Whole-Body MR Data</span> <span class="author"> Oleh Dzyubachyk,&nbsp;<em>Marius Staring</em>,&nbsp;Monique Reijnierse , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Boudewijn P.F. Lelieveldt, Rob J. Geest' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </span> <span class="periodical"> <em>Magnetic Resonance in Medicine</em>, Jan 2017 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1002/mrm.26098" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2017_j_MRM.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p><b>Purpose.</b> To develop and validate a method for performing inter-station intensity standardization in multi-spectral whole-body MR data.<br/><b>Methods.</b> Different approaches for mapping the intensity of each acquired image stack into the reference intensity space were developed and validated. The registration strategies included: "direct" registration to the reference station (Strategy 1), "progressive" registration to the neighbouring stations without (Strategy 2) and with (Strategy 3) using information from the overlap regions of the neighbouring stations. For Strategy 3, two regularized modifications were proposed and validated. All methods were tested on two multi-spectral whole-body MR data sets: a multiple myeloma patients data set (48 subjects) and a whole-body MR angiography data set (33 subjects).<br/><b>Results.</b> For both data sets, all strategies showed significant improvement of intensity homogeneity with respect to vast majority of the validation measures (p \lt 0.005). Strategy 1 exhibited the best performance, closely followed by Strategy 2. Strategy 3 and its modifications were performing worse, in majority of the cases significantly (p \lt 0.05).<br/><b>Conclusions.</b> We propose several strategies for performing inter-station intensity standardization in multi-spectral whole-body MR data. All the strategies were successfully applied to two types of whole-body MR data, and the "direct" registration strategy was concluded to perform the best.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Dzyubachyk:2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dzyubachyk, Oleh and Staring, Marius and Reijnierse, Monique and Lelieveldt, Boudewijn P.F. and van der Geest, Rob J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inter-Station Intensity Standardization for Whole-Body MR Data}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Magnetic Resonance in Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{77}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{422 -- 433}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Viergever:2016" class="col-sm-10"> <span class="title">A survey of medical image registration - under review</span> <span class="author"> Max A. Viergever,&nbsp;J.B. Antoine Maintz,&nbsp;Stefan Klein , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Keelin Murphy, Marius Staring, Josien P.W. Pluim' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>Medical Image Analysis</em>, Oct 2016 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1016/j.media.2016.06.030" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2016_j_MedIA.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>A retrospective view on the past two decades of the field of medical image registration is presented, guided by the article "A survey of medical image registration" (Maintz and Viergever, 1998). It shows that the classification of the field introduced in that article is still usable, although some modifications to do justice to advances in the field would be due. The main changes over the last twenty years are the shift from extrinsic to intrinsic registration, the primacy of intensity-based registration, the breakthrough of nonlinear registration, the progress of inter-subject registration, and the availability of generic image registration software packages. Two problems that were called urgent already 20 years ago, are even more urgent nowadays: Validation of registration methods, and translation of results of image registration research to clinical practice. It may be concluded that the field of medical image registration has evolved, but still is in need of further development in various aspects.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Viergever:2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Viergever, Max A. and Maintz, J.B. Antoine and Klein, Stefan and Murphy, Keelin and Staring, Marius and Pluim, Josien P.W.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A survey of medical image registration - under review}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{140 -- 144}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Xiao:2016" class="col-sm-10"> <span class="title">Pulmonary Fissure Detection in CT Images Using a Derivative of Stick Filter</span> <span class="author"> Changyan Xiao,&nbsp;Berend C. Stoel,&nbsp;M. Els Bakker , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Yuanyuan Peng, Jan Stolk, Marius Staring' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </span> <span class="periodical"> <em>IEEE Transactions on Medical Imaging</em>, Jun 2016 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1109/TMI.2016.2517680" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2016_j_TMIc.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Pulmonary fissures are important landmarks for recognition of lung anatomy. In CT images, automatic detection of fissures is complicated by factors like intensity variability, pathological deformation and imaging noise. To circumvent this problem, we propose a derivative of stick (DoS) filter for fissure enhancement and a post-processing pipeline for subsequent segmentation. Considering a typical thin curvilinear shape of fissure profiles inside 2D cross-sections, the DoS filter is presented by first defining nonlinear derivatives along a triple stick kernel in varying directions. Then, to accommodate pathological abnormality and orientational deviation, a max-min cascading and multiple plane integration scheme is adopted to form a shape-tuned likelihood for 3D surface patches discrimination. During the post-processing stage, our main contribution is to isolate the fissure patches from adhering clutters by introducing a branch-point removal algorithm, and a multi-threshold merging framework is employed to compensate for local intensity inhomogeneity. The performance of our method was validated in experiments with two clinical CT data sets including 55 publicly available LOLA11 scans as well as separate left and right lung images from 23 GLUCOLD scans of COPD patients. Compared with manually delineating interlobar boundary references, our method obtained a high segmentation accuracy with median F1-scores of 0.833, 0.885, and 0.856 for the LOLA11, left and right lung images respectively, whereas the corresponding indices for a conventional Wiemker filtering method were 0.687, 0.853, and 0.841. The good performance of our proposed method was also verified by visual inspection and demonstration on abnormal and pathological cases, where typical deformations were robustly detected together with normal fissures.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Xiao:2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xiao, Changyan and Stoel, Berend C. and Bakker, M. Els and Peng, Yuanyuan and Stolk, Jan and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pulmonary Fissure Detection in CT Images Using a Derivative of Stick Filter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1488 -- 1500}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Saygili:2016" class="col-sm-10"> <span class="title">Confidence Estimation for Medical Image Registration Based On Stereo Confidences</span> <span class="author"> Gorkem Saygili,&nbsp;<em>Marius Staring</em>,&nbsp;and&nbsp;Emile A. Hendriks </span> <span class="periodical"> <em>IEEE Transactions on Medical Imaging</em>, Feb 2016 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1109/TMI.2015.2481609" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2016_j_TMIb.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>In this paper, we propose a novel method to estimate the confidence of a registration that does not require any ground truth, is independent from the registration algorithm and the resulting confidence is correlated with the amount of registration error. We first apply a local search to match patterns between the registered image pairs. Local search induces a cost space per voxel which we explore further to estimate the confidence of the registration similar to confidence estimation algorithms for stereo matching. We test our method on both synthetically generated registration errors and on real registrations with ground truth. The experimental results show that our confidence measure can estimate registration errors and it is correlated with local errors.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Saygili:2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Saygili, Gorkem and Staring, Marius and Hendriks, Emile A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Confidence Estimation for Medical Image Registration Based On Stereo Confidences}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{539 -- 549}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Qiao:2016" class="col-sm-10"> <span class="title">Fast Automatic Step Size Estimation for Gradient Descent Optimization of Image Registration</span> <span class="author"> Yuchuan Qiao,&nbsp;Baldur Lew,&nbsp;Boudewijn P.F Lelieveldt , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marius Staring' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>IEEE Transactions on Medical Imaging</em>, Feb 2016 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1109/TMI.2015.2476354" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2016_j_TMIa.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> <a href="https://github.com/SuperElastix/elastix"><img src="/assets/img/github-mark.svg" height="20"/></a> </div> <div class="abstract hidden"> <p>Fast automatic image registration is an important prerequisite for image guided clinical procedures. However, due to the large number of voxels in an image and the complexity of registration algorithms, this process is often very slow. Among many classical optimization strategies, stochastic gradient descent is a powerful method to iteratively solve the registration problem. This procedure relies on a proper selection of the optimization step size, which is important for the optimization procedure to converge. This step size selection is difficult to perform manually, since it depends on the input data, similarity measure and transformation model. The Adaptive Stochastic Gradient Descent (ASGD) method has been proposed to automatically choose the step size, but it comes at a high computational cost, dependent on the number of transformation parameters.<br/>In this paper, we propose a new computationally efficient method (fast ASGD) to automatically determine the step size for gradient descent methods, by considering the observed distribution of the voxel displacements between iterations. A relation between the step size and the expectation and variance of the observed distribution is derived. While ASGD has quadratic complexity with respect to the transformation parameters, the fast ASGD method only has linear complexity. Extensive validation has been performed on different datasets with different modalities, inter/intra subjects, different similarity measures and transformation models. To perform a large scale experiment on 3D MR brain data, we have developed efficient and reusable tools to exploit an international high performance computing facility. For all experiments, we obtained similar accuracy as ASGD. Moreover, the estimation time of the fast ASGD method is reduced to a very small value, from 40 seconds to less than 1 second when the number of parameters is 10<sup>5</sup>, almost 40 times faster. Depending on the registration settings, the total registration time is reduced by a factor of 2.5-7x for the experiments in this paper.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Qiao:2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qiao, Yuchuan and van Lew, Baldur and Lelieveldt, Boudewijn P.F and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast Automatic Step Size Estimation for Gradient Descent Optimization of Image Registration}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{391 -- 403}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Hammelrath:2016" class="col-sm-10"> <span class="title">Morphological maturation of the mouse brain: An in vivo MRI and histology investigation</span> <span class="author"> Luam Hammelrath,&nbsp;Siniša Škokić,&nbsp;Artem Khmelinskii , and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Andreas Hess, Noortje Knaap, Marius Staring, Boudewijn P.F. Lelieveldt, Dirk Wiedermann, Mathias Hoehn' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </span> <span class="periodical"> <em>NeuroImage</em>, Jan 2016 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1016/j.neuroimage.2015.10.009" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2016_j_NI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>With the wide access to studies of selected gene expressions in transgenic animals, mice have become the dominant species as cerebral disease models.Many of these studies are performed on animals of not more than eight weeks, declared as adult animals. Based on the earlier reports that full brain maturation requires at least three months in rats, there is a clear need to discern the corresponding minimal animal age to provide an "adult brain" in mice in order to avoid modulation of disease progression/therapy studies by ongoing developmental changes. For this purpose, we have studied anatomical brain alterations of mice during their first six months of age. Using T2-weighted and diffusion-weighted MRI, structural and volume changes of the brain were identified and compared with histological analysis of myelination. Mouse brain volume was found to be almost stable already at three weeks, but cortex thickness kept decreasing continuously with maximal changes during the first three months. Myelination is still increasing between three and six months, although most dramatic changes are over by three months. While our results emphasize that mice should be at least three months old when adult animals are needed for brain studies, preferred choice of one particular metric for future investigation goals will result in somewhat varying age windows of stabilization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Hammelrath:2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hammelrath, Luam and {\v{S}}koki{\'c}, Sini{\v{s}}a and Khmelinskii, Artem and Hess, Andreas and van der Knaap, Noortje and Staring, Marius and Lelieveldt, Boudewijn P.F. and Wiedermann, Dirk and Hoehn, Mathias}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Morphological maturation of the mouse brain: An in vivo MRI and histology investigation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NeuroImage}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{125}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{144 -- 152}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="Shahzad:2015" class="col-sm-10"> <span class="title">Automated Extraction and Labelling of the Arterial Tree from Whole-Body MRA Data</span> <span class="author"> Rahil Shahzad,&nbsp;Oleh Dzyubachyk,&nbsp;<em>Marius Staring</em> , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Joel Kullberg, Lars Johansson, Håkan Ahlström, Boudewijn P. F. Lelieveldt, Rob J. Geest' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </span> <span class="periodical"> <em>Medical Image Analysis</em>, Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1016/j.media.2015.05.008" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2015_j_MedIA.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>In this work, we present a fully automated algorithm for extraction of the 3D arterial tree and labelling the tree segments from whole-body magnetic resonance angiography (WB-MRA) sequences. The algorithm developed consists of two core parts (i) 3D volume reconstruction from different stations with simultaneous correction of different types of intensity inhomogeneity, and (ii) Extraction of the arterial tree and subsequent labelling of the pruned extracted tree. Extraction of the arterial tree is performed using the probability map of the "contrast" class, which is obtained as one of the results of the inhomogeneity correction scheme. We demonstrate that such approach is more robust than using the difference between the pre- and post-contrast channels traditionally used for this purpose. Labelling the extracted tree is performed by using a combination of graph-based and atlas-based approaches. Validation of our method with respect to the extracted tree was performed on the arterial tree subdivided into 32 segments, 82.4% of which were completely detected, 11.7% partially detected, and 5.9% were missed on a cohort of 35 subjects. With respect to automated labelling accuracy of the 32 segments, various registration strategies were investigated on a training set consisting of 10 scans. Further analysis on the test set consisting of 25 data sets indicates that 69% of the vessel centerline tree in the head and neck region, 80% in the thorax and abdomen region, and 84% in the legs was accurately labelled to the correct vessel segment. These results indicate clinical potential of our approach in enabling fully automated and accurate analysis of the entire arterial tree. This is the first study that not only automatically extracts the WB-MRA arterial tree, but also labels the vessel tree segments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Shahzad:2015</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shahzad, Rahil and Dzyubachyk, Oleh and Staring, Marius and Kullberg, Joel and Johansson, Lars and Ahlstr{\"o}m, H{\r{a}}kan and Lelieveldt, Boudewijn P. F. and van der Geest, Rob J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated Extraction and Labelling of the Arterial Tree from Whole-Body MRA Data}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{28 -- 40}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXXX" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXXX</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXXY" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXXY</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXXZ" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXXZ</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYA" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYA</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYB" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYB</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYC" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYC</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYD" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYD</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYE" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYE</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYF" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYF</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li><div class="row"> <div id="XXYG" class="col-sm-10"> <span class="title"></span> <span class="author"> </span> <span class="periodical"> <em></em> Aug 2015 </span> <span class="periodical"> </span> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XXYG</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">Conference Articles</h2> <ol class="bibliography"><li><div class="row"> <div id="vanderValk:2023" class="col-sm-10"> <span class="title">Joint optimization of a β-VAE for ECG task-specific feature extraction</span> <span class="author"> Viktor Valk,&nbsp;Douwe Atsma,&nbsp;Roderick Scherptong , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marius Staring' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </span> <span class="periodical"> <em>In Medical Image Computing and Computer-Assisted Intervention</em> , Oct 2023 </span> <span class="periodical"> </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.06476" class="btn btn-sm z-depth-0" role="button">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/978-3-031-43895-0_52" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="/assets/pdf/2023_c_MICCAI.pdf"><img src="/assets/img/PDF_32.png" height="20"/></a> </div> <div class="abstract hidden"> <p>Electrocardiography is the most common method to investigate the condition of the heart through the observation of cardiac rhythm and electrical activity, for both diagnosis and monitoring purposes. Analysis of electrocardiograms (ECGs) is commonly performed through the investigation of specific patterns, which are visually recognizable by trained physicians and are known to reflect cardiac (dis)function. In this work we study the use of β-variational autoencoders (VAEs) as an explainable feature extractor, and improve on its predictive capacities by jointly optimizing signal reconstruction and cardiac function prediction. The extracted features are then used for cardiac function prediction using logistic regression. The method is trained and tested on data from 7255 patients, who were treated for acute coronary syndrome at the Leiden University Medical Center between 2010 and 2021. The results show that our method significantly improved prediction and explainability compared to a vanilla β-VAE, while still yielding similar reconstruction performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">vanderValk:2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{van der Valk, Viktor and Atsma, Douwe and Scherptong, Roderick and Staring, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Joint optimization of a β-VAE for ECG task-specific feature extraction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Medical Image Computing and Computer-Assisted Intervention}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vancouver, Canada}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14221}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{554 -- 563}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> &copy; Copyright 2024 Marius Staring. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with the <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Last updated: July 11, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hideBreadcrumbs noAutoLoadMdIcons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"news-we-received-funding-from-the-wellcome-trust-as-part-of-the-czi-essential-open-source-software-for-science-program-for-the-further-development-of-our-image-registration-software-lt-a-href-quot-https-elastix-dev-quot-gt-elastix-lt-a-gt",title:"We received funding from the Wellcome Trust as part of the \u201cCZI Essential Open Source Software for Science\u201d program for the further development of our image registration software &lt;a href=&quot;https://elastix.dev/&quot;&gt;elastix&lt;/a&gt;.",description:"",section:"News"},{id:"news-i-held-my-inaugural-lecture-entitled-images-and-physicians-in-transition-the-era-of-the-learning-machine",title:"I held my inaugural lecture entitled \u201cImages and Physicians in transition: the era of the learning machine\u201d.",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6D.%73%74%61%72%69%6E%67@%6C%75%6D%63.%6E%6C","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-2885-5812","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=pKFkfq4AAAAJ","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/2602873","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Marius-Staring-47869146/","_blank")}},{id:"socials-ieee-xplore",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/38294698000/","_blank")}},{id:"socials-scopus",title:"Scopus",section:"Socials",handler:()=>{window.open("https://www.scopus.com/authid/detail.uri?authorId=55886447500","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/mstaring","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/mariusstaring","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/35/6426.html","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>