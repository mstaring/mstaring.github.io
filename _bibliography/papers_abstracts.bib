

@inproceedings{Rao:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Beljaards, Laurens and van Osch, Matthias and Doneva, Mariya and Meineke, Jakob and Sch{\"u}lke, Christophe and Pezzotti, Nicola and de Weerdt, Elwin and Staring, Marius},
title 	= {Guided Multicontrast Reconstruction based on the Decomposition of Content and Style},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2024},
  pdf =       {2024_a_ISMRM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Motivation: </b>Scans within an MR exam share redundant information due to the same underlying structures. One contrast can hence be used to guide the reconstruction of another, thereby requiring less measurements.<br><b>Goals: </b>Multimodal guided reconstruction to reduce scanning times.<br><b>Approach: </b>Our method exploits AI-based content/style decomposition in an iterative reconstruction algorithm. We explored this concept via numerical simulation and subsequently validated it on in vivo data.<br><b>Results: </b>Compared to a conventional compressed sensing baseline, our method showed consistent improvement in simulations and produced sharper reconstructions from undersampled in vivo data. By enforcing data consistency, it was also more reliable than blind image translation.<br><b>Impact: </b>In the clinic, this can potentially enable a reduced MR exam time for a given image quality or improve image quality given a scan time budget. The former can reduce strain on the patient, whereas the latter can improve diagnosis.},
}

@inproceedings{Mody:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Mody, Prerak and Huiskes, Merle and Chaves de Plaza, Nicolas and Onderwater, Alice and Lamsma, Rense and Hildebrandt, Klaus and Hoekstra, Nienke and Astreinidou, Eleftheria and Staring, Marius and Dankers, Frank},
title 	= {Dose evaluation using existing plan parameters of auto-contouring in head-and-neck radiotherapy},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2024},
  pdf =       {2024_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Previous work on auto-contour dose evaluation has used both manual [1] and automated [2,3] techniques, however with small (~20) test patient cohorts. This is due to extensive manual effort required for additional contour refinement and treatment planning on the auto-contours. Moreover, automated planning techniques, if not already clinically implemented, are difficult to adopt. Our primary goal is to investigate the dosimetric effect of auto-contouring for proton radiotherapy using a large-scale cohort of patients. A secondary goal is to develop and evaluate a workflow that is both automated and uses existing plan parameters, hence enabling evaluation for a large patient cohort.},
}

@inproceedings{Goedmakers:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Goedmakers, C.M.W and Pereboom, L.M. and de Leeuw den Bouter, M.L. and Remis, R.F. and Staring, M. and Vleggeert-Lankamp, C.L.A.},
title 	= {Deep Learning on Preoperative Radiographs for Clinical Success Prediction after Surgery for Cervical Degenerative Disease},
journal 	= {Brain and Spine},
volume 	= {3},
pages 	= {101842},
year 	= {2023},
  pdf =       {2023_a_BandS.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {As populations age and the prevalence of cervical spine degeneration rises, the demand for computer-aided diagnostics and prognostics in neurosurgery rises. Not all patients benefit from surgical treatment and predicting who will remains challenging. Automating parts of the radiological image analysis process using Machine Learning could provide more accurate, consistent assessment with increased time efficiency, and potentially gain new disease insights. The purpose of this study was to identify which image features on cervical radiographs are important for the prediction of clinical success one year after surgery for cervical disc disease, by developing and validating a deep learning algorithm that predicts clinical success solely based on the radiograph.},
}

@inproceedings{Malimban:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Ludwig, Felix and Lathouwers, Danny and Staring, Marius and Verhaegen, Frank and Brandenburg, Sytze},
title 	= {A simulation framework of the preclinical proton irradiation workflow},
booktitle 	= {Particle Therapy Co-operative Group},
address 	= {Madrid, Spain},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_PTCOG.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {The size of orthotopic tumors in small animals (typically a few mm) presents some challenges in preclinical proton dose delivery. For tumors situated deeper in the animal close to critical organs, determination of the actual dose distribution and conformity is challenging especially for Bragg peak irradiations. Therefore, it is important to optimize beam properties, verify CT HU-RSP calibration, and ensure the quality of dose distributions.<br>In this work, we present a simulation framework that (1) allows generation of realistic X-ray {\mu}-CBCT images, (2) facilitates CT HU calibration, and (3) performs proton dose calculations.<br>A {\mu}-CBCT model was developed using the fastCAT toolkit. Monte Carlo simulations were performed to generate the primary and scatter kernels and imaging dose calibration appropriate for {\mu}-CBCT scans. CTs were then generated for a mini Gammex phantom and the MOBY/ROBY digital rodent phantoms. The HU - SPR conversion is performed with the mini Gammex phantom. The resulting calibration parameters are then used to convert the CTs of the MOBY/ROBY phantoms to SPR maps. These are then used to calculate dose distributions in TOPAS for treatment plans created in matRad using realistic beams based on measured emittances and simulations of the beam transport with BDSIM. Since the composition of the MOBY/ROBY phantoms is known, a ground truth exists against which the accuracy of the calibration and dose distributions can be verified.<br>This framework is used to optimize the irradiation setup and assess the quality of small animal irradiations.},
}

@inproceedings{Rao:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Meineke, Jakob and Pezzotti, Nicola and Staring, Marius and van Osch, Matthias and Doneva, Mariya},
title 	= {Analysis of the Discretization Error vs. Estimation Time Tradeoff of MRF Dictionary Matching and the Advantage of the Neural Net-based Approach},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Traditional MR fingerprinting involves matching the acquired signal evolutions against a dictionary of expected tissue fingerprints to obtain thecorresponding tissue parameters. Since this dictionary is essentially a discrete representation of a physical model and the matching processamounts to brute-force search in a discretized parameter space, there arises a tradeoff between discretization error and parameter estimationtime. In this work, we investigate this tradeoff and show via numerical simulation how a neural net-based approach solves it. We additionallyconduct a phantom study using 1.5T and 3T data to demonstrate the consistency of neural net-based estimation with dictionary matching.},
}

@inproceedings{Dong:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Dong, Yiming and Koolstra, Kirsten and Beljaards, Laurens and Staring, Marius and van Osch, Matthias J.P. and B{\"o}rnert, Peter},
title 	= {Deep Learning Based Self-Navigated Diffusion Weighted Multi-Shot EPI with Supervised Denoising},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Advanced diffusion weighted self-navigated multi-shot MRI can run at high scan efficiencies resulting in good image quality. However, the model-based image reconstruction used is rather time consuming. Deep learning-based reconstruction approaches could function as a faster alternative. Tailored network architectures with appropriately set physical model constraints can help to shorten reconstruction times, resulting in good image quality with reduced noise propagation.},
}

@inproceedings{Lu:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Lu, Huangling and Juffermans, Joe F. and Pezzotti, Nicola and Staring, Marius and Lamb, Hildo J.},
title 	= {Deep learning-based acceleration of Compressed SENSE Cardiac MR imaging - accelerating total scan-times and reducing the number of breath holds},
journal 	= {Society for Cardiovascular Magnetic Resonance},
month 	= {January},
year 	= {2023},
  pdf =       {2023_a_SCMR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {With compressed sensing (CS) undersampled data points are used for MR image reconstruction to reduce acquisition times with preservation of SNR, but CS tends to simplify image content with higher levels of acceleration. Deep learning (DL) reconstruction methods could accelerate the acquisition process with preservation of high image quality by learning from high complexity images. In cardiac MR imaging high levels of acceleration allows multi-slice imaging during one breath-hold (BH) which could reduce scan-times significantly. We investigate the feasibility of a prospectively assessed DL-based reconstruction technique combined with different levels of acceleration using Compressed Sensing artificial intelligence framework in cardiac MR imaging.},
}

@inproceedings{Beljaards:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Beljaards, Laurens and Pezzotti, Nicola and Sch{\"u}lke, Christophe and van Osch, Matthias J.P. and Staring, Marius},
title 	= {The effect of intra-scan motion on AI reconstructions in MRI},
journal 	= {Medical Imaging with Deep Learning},
month 	= {July},
year 	= {2022},
  pdf =       {2022_a_MIDL.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {MRI can be accelerated via (AI-based) reconstruction by undersampling k-space. Current methods typically ignore intra-scan motion, although even a few millimeters of motion can introduce severe blurring and ghosting artifacts that necessitate reacquisition. In this short paper we investigate the effects of rigid-body motion on AI-based reconstructions. Leveraging the Bloch equations we simulate motion corrupted MRI acquisitions with a linear interleaved scanning protocol including spin history effects, and investigate i) the effect on reconstruction quality, and ii) if this corruption can be mitigated by introducing motion-corrupted data during training. We observe an improvement from 0.787 to 0.844 in terms of SSIM when motion-corrupted brain data is included during training, demonstrating that training with motion-corrupted data can partially compensate for motion corruption. Inclusion of spin-history effects did not influence the results.},
}

@inproceedings{Malimban:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius},
title 	= {External validation of deep learning models for mouse thorax autocontouring},
journal 	= {5th Conference on Small Animal Precision Image-guided Radiotherapy},
month 	= {March},
year 	= {2022},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Introduction: </b>Organ contouring is one of the most laborious and time-consuming stages in the preclinical irradiation workflow. Since deep learning algorithms have shown excellent performance on human organ segmentation, their application for animals have also been recently explored. However, previously developed deep learning-based animal autocontouring models were mostly trained on one type of dataset, and their predictive performance was also evaluated on the same distribution as the training data. In a preclinical facility wherein studies involving various strains of animals and image acquisition protocols are performed, it is important to demonstrate the robustness of these tools across different populations and settings. Therefore, in this work, we externally validated two deep learning pipelines for mouse thorax segmentation to assess their usability and portability when implemented on a larger scale.|<b>Materials & Methods: </b>We trained the 2D and 3D models of nnU-Net (i.e., one of the best performing algorithms for clinical segmentation) and compared them with the state-of-the-art AIMOS pipeline for segmentation of the mouse thorax. We allotted 105 native micro-CT scans of mice for the training and initially performed internal validation using 35 native micro-CT scans not included in the model development to determine the best nnU-Net model. Then, the proposed nnU-Net model and AIMOS were externally validated using 35 contrast-enhanced micro-CTs, which comprise of scans with a different mouse strain and imaging parameters than the training data. The predictive performance was evaluated in terms of the Dice score (DSC), mean surface distance (MSD), and 95% Hausdorff distance (95% HD).|<b>Results: </b>When tested against native micro-CTs, all models of nnU-Net (3d_fullres, 3d_cascade, 3d_lowres, 2d) and AIMOS generated accurate contours, achieving average DSC greater than 0.94, 0.90, 0.97 and 0.95 for the heart, spinal cord, right and left lungs, respectively. The average MSD was less than the in-plane voxel size of 0.14 mm while the average 95% HD was below 0.60 mm except for the right lung results of nnU-Net 2d. Among the nnU-Net models, 3d_fullres was considered the superior model, producing the most accurate contours at a reasonable speed. The nnU-Net 3d_fullres model and AIMOS were then evaluated against the external dataset. The nnU-Net 3d_fullres model achieved average DSC of 0.92, 0.85, 0.96 and 0.95 whereas AIMOS showed inferior results: 0.83, 0.82, 0.87 and 0.77. Consistent for all organs, AIMOS recorded unacceptably large 95% HD > 1 mm and produced incomplete contours. Moreover, AIMOS failed to distinguish the right lung from left lung. These entail that AIMOS requires more labor-intensive corrections than nnU-Net 3d_fullres for data on which the model was not trained on.|<b>Conclusion: </b>We have shown that the nnU-Net 3d_fullres model is more robust and generalizable than the current best performing algorithm for mouse segmentation (AIMOS). Our findings also demonstrate the importance of thoroughly evaluating the performance of autocontouring tools before implementation in routine preclinical practice.},
}

@inproceedings{Koolstra:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Koolstra, Kirsten and Staring, Marius and de Bruin, Paul and van Osch, Matthias J.P.},
title 	= {Subject-specific optimization of background suppression for arterial spin labeling MRI using a real-time feedback loop on the scanner},
booktitle 	= {International Society for Magnetic Resonance in Medicine},
address 	= {London, UK},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Background suppression (BGS) in arterial spin labeling (ASL) leads to perfusion images with a higher temporal signal-to-noise ratio (tSNR) compared to ASL without BGS. The optimal inversion times (TIs), and therefore the quality of the BGS, depend on the T1 relaxation times of the underlying tissue and on inhomogeneities of the scanner's magnetic fields (B0, B1+). In this work, we designed and implemented a feedback mechanism that optimized the quality of background suppression in real time on the scanner. The results show an increased tSNR for the subject-specific optimization of BGS compared to standard BGS in 12 healthy volunteers.},
}

@inproceedings{Brink:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Brink, Wyger and Staring, Marius and Remis, Rob and Webb, Andrew},
title 	= {Fast Subject-Specific SAR and B1+ Prediction for PTx at 7T using only an Initial Localizer Scan},
booktitle 	= {ISMRM},
address 	= {London, UK},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Ultra-high field (UHF) MRI (B<sub>0</sub> > 7T) shows great promise to yield higher resolution structural and physiological information than available at 3T, particularly in the brain. Parallel RF transmission (PTx) is a key technology for UHF-MRI to address the increased spatial variations in the radiofrequency (RF) field distribution. However, currently it has failed to reach widespread clinical adoption. The main factors include the intersubject variability in local specific absorption rate (SAR) leading to large safety margins to ensure compliance to regulatory limits, and time-consuming B1<sup>+</sup> calibration procedures required for tailored RF pulse design. Together, these technological challenges limit the clinical impact of PTx and the utilization of UHF-MRI.|In this work, we demonstrate a fast subject-specific method based on deep learning and a fast EM solver for predicting both SAR and B1<sup>+</sup> fields using only a 9 second long localizer scan.},
}

@inproceedings{Malimban:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius},
title 	= {Autocontouring of the mouse thorax using deep learning},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Image-guided small animal irradiations are typically performed in a single session, requiring continuous administration of anesthesia. Prolonged exposure to anesthesia can potentially affect experimental outcomes and thus, a fast preclinical irradiation workflow is desired. Similar to the clinic, delineation of organs remains one of the most time-consuming and labor-intensive stages in the preclinical workflow, and this is amplified by the fact that hundreds of animals are involved in a single study. In this work, we evaluated the accuracy and efficiency of deep learning pipelines for automated contouring of organs in the mouse thorax.},
}

@inproceedings{Koolstra:2021,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Koolstra, Kirsten and Staring, Marius and de Bruin, Paul and van Osch, Matthias J.P.},
title 	= {Individually optimized ASL background suppression using a real-time feedback loop on the scanner},
booktitle 	= {ESMRMB},
address 	= {online},
month 	= {October},
year 	= {2021},
  pdf =       {2021_a_ESMRMB.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Suppression of background signal in ASL leads to perfusion images with higher signal-to-noise ratio (SNR) compared to ASL without background suppression (BGS)1. BGS is obtained by applying multiple inversion pulses before and during the post-label delay (PLD). The optimal inversion times, and therefore the quality of the BGS, depends on the relaxation times of the underlying tissue (T1, T2) and on imperfections of the scanner's magnetic fields (B0, B1+). Although this results in inter-subject differences, current ASL protocols make use of one set of predefined inversion times for all subjects, primarily because these inter-scan variations are not known at the moment of scanning. This means that the quality of the resulting perfusion images is not optimal for all subjects. In this work, we develop and implement a feedback loop that optimizes the timings of ASL BGS pulses real-time on the scanner, generating individually optimized perfusion images for each subject.},
}

@inproceedings{Neve:2021,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Neve, Olaf and Tao, Qian and Romeijn, Stephan and Chen, Yunjie and de Boer, Nick P. and Grootjans, Willem and Kruit, Mark C. and Lelieveldt, Boudewijn P.F. and Jansen, Jeroen and Hensen, Erik and Staring, Marius and Verbist, Berit},
title 	= {Fully Automated 3D Vestibular Schwannoma Segmentation: A multicentre multi-vendor study},
booktitle 	= {European Society of Head and Neck Radiology (ESHNR)},
address 	= {online},
month 	= {September},
year 	= {2021},
  pdf =       {2021_a_ESHNR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Short summary:</b> For the evaluation of vestibular schwannoma (VS) progression and treatment planning, accurate measurement from MRI is important. In clinical practice, manual linear measurements are performed from MRI. Manual 3D measurement is time-consuming and 2D measurement is subjective and reflects highly variable tumour volume poorly. We developed an AI model to detect and segment VS from MRI automatically.|<b>Purpose/Objectives:</b> We present a model for the detection and segmentation of VS, based on deep learning and suited to process multi-centre, multi-vendor MR images. The model's performance is evaluated and compared to humans in an observer study.|<b>Methods & materials:</b> In total 214 cases (134 VS positive and 80 negative) with gadolinium-enhanced T1 and native T2 weighted MR images were acquired from 37 centres and 12 different MRI scanners. The intra- and extra meatal parts of the tumour were manually delineated by two observers under supervision of an experienced head and neck radiologist. Cases were divided into three non-overlapping sets (training, validation, and testing). A model was trained using 3D no-new-Unet deep learning segmentation method. In addition, an observer study was performed, in which the radiologist blinded to case information and delineation method compared model and human delineations.|<b>Results:</b> The model correctly detected VS in all positive cases and excluded the negative. Evaluation of the T1 model compared to the human delineation resulted in a Dice index 90.4&plusmn;13.0, Hausdorff distance 2.12&plusmn;9.32 mm, and mean surface-to-surface distance 0.49&plusmn;1.52 mm. Intra and extra meatal tumour parts had Dice indices of 77.5&plusmn;21.3 and 82.2&plusmn;28.0, respectively. The observer study showed that in 103 out of 111 cases (93%) the model was comparable to or better than human delineation.|<b>Conclusion:</b> The proposed model can accurately detect and delineate VS from MRI in a multi-centre, multi-vendor setting. As such, it is a robust tool well suited to the reality of clinical practise. The model performed comparably to human delineations in the observer study.},
}

@inproceedings{Brink:2021,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Brink, Wyger and Yousefi, Sahar and Bhatnagar, Prernna and Staring, Marius and Remis, Rob and Webb, Andrew},
title 	= {Numerical Body Model Inference for Personalized RF Exposure Prediction in Neuroimaging at 7T},
booktitle 	= {ISMRM},
address 	= {Vancouver, BC, Canada},
month 	= {May},
year 	= {2021},
  pdf =       {2021_a_ISMRM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Compliance with RF exposure limits in ultra-high field MRI is typically based on "one-size-fits-all" safety margins to account for the intersubject variability of local SAR. In this work we have developed a semantic segmentation method based on deep learning, which is able to generate a subject-specific bodymodel for personalized RF exposure prediction at 7T.},
}

@inproceedings{Tao:2020,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Tao, Qian and Romeijn, Stephan and Neve, Olaf and de Boer, Nick and Grootjans, Willem and Kruit, Mark C. and Lelieveldt, Boudewijn P.F. and Jansen, Jeroen and Hensen, Erik and Verbist, Berit and Staring, Marius},
title 	= {Deep-Learning-based Detection and Segmentation of Vestibular Schwannoma: A Multi-Center and Multi-Vendor MRI Study},
booktitle 	= {RSNA},
address 	= {Chicago, USA},
month 	= {November},
year 	= {2020},
  pdf =       {2020_a_RSNA.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>PURPOSE:</b> Accurate measurement of vestibular schwannoma (VS) is important for evaluation of VS progression and treatment planning. In clinical practice, linear measurements are manually performed from MRI. Manual measurement is time-consuming, subjective, and restricted to 2D planes. In this study, we aim to develop a deep learning convolutional neural network (CNN) model to automatically detect and segment VS in 3D from Gadolinium (Gd)-enhanced MRI.|<b>METHOD AND MATERIALS:</b> In total 124 patients with unilateral hearing loss referred to MRI exam were enrolled, including 84 VS-positive and 40 VS-negative cases. MRI data were acquired from 37 centers, by 12 different MRI scanners from 3 vendors. Typical image resolution was 0.35x0.35x1 mm, and field of view ranged from 130x130x24 mm to 270x270x188 mm. In 84 positive cases, VS was manually delineated by two observers, supervised by a senior radiologist. The 124 subjects were randomly divided into three non-overlapping sets: training set (N=72), validation set (N=18), and test set (N=34). We trained a 3D no-new-Unet CNN for both VS detection and segmentation. Training was performed on a NVIDIA Tesla V100 graphics processing unit with 16GB memory.|<b>RESULTS:</b>Applied to the test set, the CNN correctly detected VS in 24 subjects and excluded VS in 10 (sensitivity 100%, specificity 100%). We evaluated the Dice index, Hausdorff distance, and surface to surface (S2S) distance in two scenarios, namely, CNN vs. observer 1, and observer 1 vs. observer 2. No significant differences were found: Dice 0.91&plusmn;0.06 vs 0.92&plusmn;0.05 (p=0.5 by paired Wilcoxon test), Hausdorff 1.3&plusmn;1.5mm vs. 1.2&plusmn;1.0 mm (p=0.6), S2S 0.4&plusmn;0.3 mm vs. 0.4&plusmn;0.2 mm (p=0.9). The annotation time was 6.0&plusmn;3.3 min for the observer and 2.5&plusmn;2.8 min for the CNN model.|<b>CONCLUSION:</b> In a multi-center and multi-vendor setting, a CNN model can accurately detect and delineate VS in 3D from Gd-enhanced MRI, to faciliate diagnosis and measurement of VS in clinical practice.},
}

@inproceedings{Zhai:2020,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Zhai, Zhiwei and Ota, Hideki and Staring, Marius and Stolk, Jan and Sugimura, Koichiro and Takase, Kei and Stoel, Berend C.},
title 	= {Response to balloon pulmonary angioplasty in treated versus untreated pulmonary arteries in CTEPH patients},
booktitle 	= {European Congress of Radiology},
address 	= {Vienna, Austria},
month 	= {March},
year 	= {2020},
  pdf =       {2020_a_ECR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Purpose:</b> Balloon pulmonary angioplasty (BPA) is a treatment of obstructed pulmonary arteries (PAs), for patients with inoperable chronic thromboembolic pulmonary hypertension (CTEPH). Since the effect of BPA in untreated (i.e. unobstructed) PAs is unknown, we investigated the treatment response in treated and untreated PAs, by analyzing CT Pulmonary Angiography (CTPA).|<b>Methods and Materials:</b> We studied 22 consecutive CTEPH patients (20 female; age: 67 &plusmn; 14), who underwent CTPA and right-heart catheterization (RHC), pre- and post-BPA. In consensus, three experts selected treated artery segments based on the BPA locations and approximately 5 untreated artery segments at a similar level. Post-BPA CTPA scans were registered to pre-BPA scans, and local intravascular density changes were measured. The median density change in treated (MDC<sub>T</sub>) and untreated segments (MDC<sub>U</sub>) was calculated, based on manual selections. The difference between MDC<sub>U</sub> and MDC<sub>T</sub> was tested by paired T-test. The difference in density changes (&Delta;MDC) between treated and untreated PAs was calculated (MDC<sub>T</sub>-MDC<sub>U</sub>). Changes in RHC parameters included systolic, diastolic and mean pulmonary artery pressure (&Delta;sPAP, &Delta;dPAP and &Delta;mPAP) and in pulmonary vascular resistance (&Delta;PVR). The relation between hemodynamic changes and &Delta;MDC was studied with Spearman’s correlation.|<b>Results:</b> MDC<sub>T</sub> (51 &plusmn; 85 HU) and MDC<sub>U</sub> (-23 &plusmn; 103 HU) were significantly different and in opposite direction (p=0.001). &Delta;MDC was significantly correlated with &Delta;dPAP (R=-0.55, p=0.008) and &Delta;PVR (R=-0.47, p=0.026), and marginally correlated with &Delta;mPAP (R=-0.4, p=0.068).|<b>Conclusion:</b> Perfusion in treated PAs increased, whereas perfusion in untreated PAs decreased. Not only improved perfusion in treated arteries, but also normalization in untreated arteries may play a significant role in improving hemodynamics by BPA.},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}


