

@inproceedings{Rao:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Beljaards, Laurens and van Osch, Matthias and Doneva, Mariya and Meineke, Jakob and Sch{\"u}lke, Christophe and Pezzotti, Nicola and de Weerdt, Elwin and Staring, Marius},
title 	= {Guided Multicontrast Reconstruction based on the Decomposition of Content and Style},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2024},
  pdf =       {2024_a_ISMRM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Motivation: </b>Scans within an MR exam share redundant information due to the same underlying structures. One contrast can hence be used to guide the reconstruction of another, thereby requiring less measurements.<br><b>Goals: </b>Multimodal guided reconstruction to reduce scanning times.<br><b>Approach: </b>Our method exploits AI-based content/style decomposition in an iterative reconstruction algorithm. We explored this concept via numerical simulation and subsequently validated it on in vivo data.<br><b>Results: </b>Compared to a conventional compressed sensing baseline, our method showed consistent improvement in simulations and produced sharper reconstructions from undersampled in vivo data. By enforcing data consistency, it was also more reliable than blind image translation.<br><b>Impact: </b>In the clinic, this can potentially enable a reduced MR exam time for a given image quality or improve image quality given a scan time budget. The former can reduce strain on the patient, whereas the latter can improve diagnosis.},
}

@inproceedings{Mody:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Mody, Prerak and Huiskes, Merle and Chaves de Plaza, Nicolas and Onderwater, Alice and Lamsma, Rense and Hildebrandt, Klaus and Hoekstra, Nienke and Astreinidou, Eleftheria and Staring, Marius and Dankers, Frank},
title 	= {Dose evaluation using existing plan parameters of auto-contouring in head-and-neck radiotherapy},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2024},
  pdf =       {2024_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Previous work on auto-contour dose evaluation has used both manual [1] and automated [2,3] techniques, however with small (~20) test patient cohorts. This is due to extensive manual effort required for additional contour refinement and treatment planning on the auto-contours. Moreover, automated planning techniques, if not already clinically implemented, are difficult to adopt. Our primary goal is to investigate the dosimetric effect of auto-contouring for proton radiotherapy using a large-scale cohort of patients. A secondary goal is to develop and evaluate a workflow that is both automated and uses existing plan parameters, hence enabling evaluation for a large patient cohort.},
}

@inproceedings{Goedmakers:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Goedmakers, C.M.W and Pereboom, L.M. and de Leeuw den Bouter, M.L. and Remis, R.F. and Staring, M. and Vleggeert-Lankamp, C.L.A.},
title 	= {Deep Learning on Preoperative Radiographs for Clinical Success Prediction after Surgery for Cervical Degenerative Disease},
journal 	= {Brain and Spine},
volume 	= {3},
pages 	= {101842},
year 	= {2023},
  pdf =       {2023_a_BandS.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {As populations age and the prevalence of cervical spine degeneration rises, the demand for computer-aided diagnostics and prognostics in neurosurgery rises. Not all patients benefit from surgical treatment and predicting who will remains challenging. Automating parts of the radiological image analysis process using Machine Learning could provide more accurate, consistent assessment with increased time efficiency, and potentially gain new disease insights. The purpose of this study was to identify which image features on cervical radiographs are important for the prediction of clinical success one year after surgery for cervical disc disease, by developing and validating a deep learning algorithm that predicts clinical success solely based on the radiograph.},
}

@inproceedings{Malimban:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Ludwig, Felix and Lathouwers, Danny and Staring, Marius and Verhaegen, Frank and Brandenburg, Sytze},
title 	= {A simulation framework of the preclinical proton irradiation workflow},
booktitle 	= {Particle Therapy Co-operative Group},
address 	= {Madrid, Spain},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_PTCOG.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {The size of orthotopic tumors in small animals (typically a few mm) presents some challenges in preclinical proton dose delivery. For tumors situated deeper in the animal close to critical organs, determination of the actual dose distribution and conformity is challenging especially for Bragg peak irradiations. Therefore, it is important to optimize beam properties, verify CT HU-RSP calibration, and ensure the quality of dose distributions.<br>In this work, we present a simulation framework that (1) allows generation of realistic X-ray {\mu}-CBCT images, (2) facilitates CT HU calibration, and (3) performs proton dose calculations.<br>A {\mu}-CBCT model was developed using the fastCAT toolkit. Monte Carlo simulations were performed to generate the primary and scatter kernels and imaging dose calibration appropriate for {\mu}-CBCT scans. CTs were then generated for a mini Gammex phantom and the MOBY/ROBY digital rodent phantoms. The HU - SPR conversion is performed with the mini Gammex phantom. The resulting calibration parameters are then used to convert the CTs of the MOBY/ROBY phantoms to SPR maps. These are then used to calculate dose distributions in TOPAS for treatment plans created in matRad using realistic beams based on measured emittances and simulations of the beam transport with BDSIM. Since the composition of the MOBY/ROBY phantoms is known, a ground truth exists against which the accuracy of the calibration and dose distributions can be verified.<br>This framework is used to optimize the irradiation setup and assess the quality of small animal irradiations.},
}

@inproceedings{Rao:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Meineke, Jakob and Pezzotti, Nicola and Staring, Marius and van Osch, Matthias and Doneva, Mariya},
title 	= {Analysis of the Discretization Error vs. Estimation Time Tradeoff of MRF Dictionary Matching and the Advantage of the Neural Net-based Approach},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Traditional MR fingerprinting involves matching the acquired signal evolutions against a dictionary of expected tissue fingerprints to obtain thecorresponding tissue parameters. Since this dictionary is essentially a discrete representation of a physical model and the matching processamounts to brute-force search in a discretized parameter space, there arises a tradeoff between discretization error and parameter estimationtime. In this work, we investigate this tradeoff and show via numerical simulation how a neural net-based approach solves it. We additionallyconduct a phantom study using 1.5T and 3T data to demonstrate the consistency of neural net-based estimation with dictionary matching.},
}

@inproceedings{Dong:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Dong, Yiming and Koolstra, Kirsten and Beljaards, Laurens and Staring, Marius and van Osch, Matthias J.P. and B{\"o}rnert, Peter},
title 	= {Deep Learning Based Self-Navigated Diffusion Weighted Multi-Shot EPI with Supervised Denoising},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Advanced diffusion weighted self-navigated multi-shot MRI can run at high scan efficiencies resulting in good image quality. However, the model-based image reconstruction used is rather time consuming. Deep learning-based reconstruction approaches could function as a faster alternative. Tailored network architectures with appropriately set physical model constraints can help to shorten reconstruction times, resulting in good image quality with reduced noise propagation.},
}

@inproceedings{Lu:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Lu, Huangling and Juffermans, Joe F. and Pezzotti, Nicola and Staring, Marius and Lamb, Hildo J.},
title 	= {Deep learning-based acceleration of Compressed SENSE Cardiac MR imaging - accelerating total scan-times and reducing the number of breath holds},
journal 	= {Society for Cardiovascular Magnetic Resonance},
month 	= {January},
year 	= {2023},
  pdf =       {2023_a_SCMR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {With compressed sensing (CS) undersampled data points are used for MR image reconstruction to reduce acquisition times with preservation of SNR, but CS tends to simplify image content with higher levels of acceleration. Deep learning (DL) reconstruction methods could accelerate the acquisition process with preservation of high image quality by learning from high complexity images. In cardiac MR imaging high levels of acceleration allows multi-slice imaging during one breath-hold (BH) which could reduce scan-times significantly. We investigate the feasibility of a prospectively assessed DL-based reconstruction technique combined with different levels of acceleration using Compressed Sensing artificial intelligence framework in cardiac MR imaging.},
}

@inproceedings{Beljaards:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Beljaards, Laurens and Pezzotti, Nicola and Sch{\"u}lke, Christophe and van Osch, Matthias J.P. and Staring, Marius},
title 	= {The effect of intra-scan motion on AI reconstructions in MRI},
journal 	= {Medical Imaging with Deep Learning},
month 	= {July},
year 	= {2022},
  pdf =       {2022_a_MIDL.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {MRI can be accelerated via (AI-based) reconstruction by undersampling k-space. Current methods typically ignore intra-scan motion, although even a few millimeters of motion can introduce severe blurring and ghosting artifacts that necessitate reacquisition. In this short paper we investigate the effects of rigid-body motion on AI-based reconstructions. Leveraging the Bloch equations we simulate motion corrupted MRI acquisitions with a linear interleaved scanning protocol including spin history effects, and investigate i) the effect on reconstruction quality, and ii) if this corruption can be mitigated by introducing motion-corrupted data during training. We observe an improvement from 0.787 to 0.844 in terms of SSIM when motion-corrupted brain data is included during training, demonstrating that training with motion-corrupted data can partially compensate for motion corruption. Inclusion of spin-history effects did not influence the results.},
}

@inproceedings{Malimban:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius},
title 	= {External validation of deep learning models for mouse thorax autocontouring},
journal 	= {5th Conference on Small Animal Precision Image-guided Radiotherapy},
month 	= {March},
year 	= {2022},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Introduction: </b>Organ contouring is one of the most laborious and time-consuming stages in the preclinical irradiation workflow. Since deep learning algorithms have shown excellent performance on human organ segmentation, their application for animals have also been recently explored. However, previously developed deep learning-based animal autocontouring models were mostly trained on one type of dataset, and their predictive performance was also evaluated on the same distribution as the training data. In a preclinical facility wherein studies involving various strains of animals and image acquisition protocols are performed, it is important to demonstrate the robustness of these tools across different populations and settings. Therefore, in this work, we externally validated two deep learning pipelines for mouse thorax segmentation to assess their usability and portability when implemented on a larger scale.|<b>Materials & Methods: </b>We trained the 2D and 3D models of nnU-Net (i.e., one of the best performing algorithms for clinical segmentation) and compared them with the state-of-the-art AIMOS pipeline for segmentation of the mouse thorax. We allotted 105 native micro-CT scans of mice for the training and initially performed internal validation using 35 native micro-CT scans not included in the model development to determine the best nnU-Net model. Then, the proposed nnU-Net model and AIMOS were externally validated using 35 contrast-enhanced micro-CTs, which comprise of scans with a different mouse strain and imaging parameters than the training data. The predictive performance was evaluated in terms of the Dice score (DSC), mean surface distance (MSD), and 95% Hausdorff distance (95% HD).|<b>Results: </b>When tested against native micro-CTs, all models of nnU-Net (3d_fullres, 3d_cascade, 3d_lowres, 2d) and AIMOS generated accurate contours, achieving average DSC greater than 0.94, 0.90, 0.97 and 0.95 for the heart, spinal cord, right and left lungs, respectively. The average MSD was less than the in-plane voxel size of 0.14 mm while the average 95% HD was below 0.60 mm except for the right lung results of nnU-Net 2d. Among the nnU-Net models, 3d_fullres was considered the superior model, producing the most accurate contours at a reasonable speed. The nnU-Net 3d_fullres model and AIMOS were then evaluated against the external dataset. The nnU-Net 3d_fullres model achieved average DSC of 0.92, 0.85, 0.96 and 0.95 whereas AIMOS showed inferior results: 0.83, 0.82, 0.87 and 0.77. Consistent for all organs, AIMOS recorded unacceptably large 95% HD > 1 mm and produced incomplete contours. Moreover, AIMOS failed to distinguish the right lung from left lung. These entail that AIMOS requires more labor-intensive corrections than nnU-Net 3d_fullres for data on which the model was not trained on.|<b>Conclusion: </b>We have shown that the nnU-Net 3d_fullres model is more robust and generalizable than the current best performing algorithm for mouse segmentation (AIMOS). Our findings also demonstrate the importance of thoroughly evaluating the performance of autocontouring tools before implementation in routine preclinical practice.},
}

@inproceedings{Koolstra:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Koolstra, Kirsten and Staring, Marius and de Bruin, Paul and van Osch, Matthias J.P.},
title 	= {Subject-specific optimization of background suppression for arterial spin labeling MRI using a real-time feedback loop on the scanner},
booktitle 	= {International Society for Magnetic Resonance in Medicine},
address 	= {London, UK},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Background suppression (BGS) in arterial spin labeling (ASL) leads to perfusion images with a higher temporal signal-to-noise ratio (tSNR) compared to ASL without BGS. The optimal inversion times (TIs), and therefore the quality of the BGS, depend on the T1 relaxation times of the underlying tissue and on inhomogeneities of the scanner's magnetic fields (B0, B1+). In this work, we designed and implemented a feedback mechanism that optimized the quality of background suppression in real time on the scanner. The results show an increased tSNR for the subject-specific optimization of BGS compared to standard BGS in 12 healthy volunteers.},
}

@inproceedings{Brink:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Brink, Wyger and Staring, Marius and Remis, Rob and Webb, Andrew},
title 	= {Fast Subject-Specific SAR and B1+ Prediction for PTx at 7T using only an Initial Localizer Scan},
booktitle 	= {ISMRM},
address 	= {London, UK},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Ultra-high field (UHF) MRI (B<sub>0</sub> > 7T) shows great promise to yield higher resolution structural and physiological information than available at 3T, particularly in the brain. Parallel RF transmission (PTx) is a key technology for UHF-MRI to address the increased spatial variations in the radiofrequency (RF) field distribution. However, currently it has failed to reach widespread clinical adoption. The main factors include the intersubject variability in local specific absorption rate (SAR) leading to large safety margins to ensure compliance to regulatory limits, and time-consuming B1<sup>+</sup> calibration procedures required for tailored RF pulse design. Together, these technological challenges limit the clinical impact of PTx and the utilization of UHF-MRI.|In this work, we demonstrate a fast subject-specific method based on deep learning and a fast EM solver for predicting both SAR and B1<sup>+</sup> fields using only a 9 second long localizer scan.},
}

@inproceedings{Malimban:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius},
title 	= {Autocontouring of the mouse thorax using deep learning},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Image-guided small animal irradiations are typically performed in a single session, requiring continuous administration of anesthesia. Prolonged exposure to anesthesia can potentially affect experimental outcomes and thus, a fast preclinical irradiation workflow is desired. Similar to the clinic, delineation of organs remains one of the most time-consuming and labor-intensive stages in the preclinical workflow, and this is amplified by the fact that hundreds of animals are involved in a single study. In this work, we evaluated the accuracy and efficiency of deep learning pipelines for automated contouring of organs in the mouse thorax.},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{XXXX,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}


