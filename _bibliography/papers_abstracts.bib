

@inproceedings{Rao:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Beljaards, Laurens and van Osch, Matthias and Doneva, Mariya and Meineke, Jakob and Sch{\"u}lke, Christophe and Pezzotti, Nicola and de Weerdt, Elwin and Staring, Marius},
title 	= {Guided Multicontrast Reconstruction based on the Decomposition of Content and Style},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2024},
  pdf =       {2024_a_ISMRM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Motivation: </b>Scans within an MR exam share redundant information due to the same underlying structures. One contrast can hence be used to guide the reconstruction of another, thereby requiring less measurements.<br><b>Goals: </b>Multimodal guided reconstruction to reduce scanning times.<br><b>Approach: </b>Our method exploits AI-based content/style decomposition in an iterative reconstruction algorithm. We explored this concept via numerical simulation and subsequently validated it on in vivo data.<br><b>Results: </b>Compared to a conventional compressed sensing baseline, our method showed consistent improvement in simulations and produced sharper reconstructions from undersampled in vivo data. By enforcing data consistency, it was also more reliable than blind image translation.<br><b>Impact: </b>In the clinic, this can potentially enable a reduced MR exam time for a given image quality or improve image quality given a scan time budget. The former can reduce strain on the patient, whereas the latter can improve diagnosis.},
}

@inproceedings{Mody:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Mody, Prerak and Huiskes, Merle and Chaves de Plaza, Nicolas and Onderwater, Alice and Lamsma, Rense and Hildebrandt, Klaus and Hoekstra, Nienke and Astreinidou, Eleftheria and Staring, Marius and Dankers, Frank},
title 	= {Dose evaluation using existing plan parameters of auto-contouring in head-and-neck radiotherapy},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2024},
  pdf =       {2024_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Previous work on auto-contour dose evaluation has used both manual [1] and automated [2,3] techniques, however with small (~20) test patient cohorts. This is due to extensive manual effort required for additional contour refinement and treatment planning on the auto-contours. Moreover, automated planning techniques, if not already clinically implemented, are difficult to adopt. Our primary goal is to investigate the dosimetric effect of auto-contouring for proton radiotherapy using a large-scale cohort of patients. A secondary goal is to develop and evaluate a workflow that is both automated and uses existing plan parameters, hence enabling evaluation for a large patient cohort.},
}

@inproceedings{Goedmakers:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Goedmakers, C.M.W and Pereboom, L.M. and de Leeuw den Bouter, M.L. and Remis, R.F. and Staring, M. and Vleggeert-Lankamp, C.L.A.},
title 	= {Deep Learning on Preoperative Radiographs for Clinical Success Prediction after Surgery for Cervical Degenerative Disease},
journal 	= {Brain and Spine},
volume 	= {3},
pages 	= {101842},
year 	= {2023},
  pdf =       {2023_a_BandS.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {As populations age and the prevalence of cervical spine degeneration rises, the demand for computer-aided diagnostics and prognostics in neurosurgery rises. Not all patients benefit from surgical treatment and predicting who will remains challenging. Automating parts of the radiological image analysis process using Machine Learning could provide more accurate, consistent assessment with increased time efficiency, and potentially gain new disease insights. The purpose of this study was to identify which image features on cervical radiographs are important for the prediction of clinical success one year after surgery for cervical disc disease, by developing and validating a deep learning algorithm that predicts clinical success solely based on the radiograph.},
}

@inproceedings{Malimban:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Ludwig, Felix and Lathouwers, Danny and Staring, Marius and Verhaegen, Frank and Brandenburg, Sytze},
title 	= {A simulation framework of the preclinical proton irradiation workflow},
booktitle 	= {Particle Therapy Co-operative Group},
address 	= {Madrid, Spain},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_PTCOG.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {The size of orthotopic tumors in small animals (typically a few mm) presents some challenges in preclinical proton dose delivery. For tumors situated deeper in the animal close to critical organs, determination of the actual dose distribution and conformity is challenging especially for Bragg peak irradiations. Therefore, it is important to optimize beam properties, verify CT HU-RSP calibration, and ensure the quality of dose distributions.<br>In this work, we present a simulation framework that (1) allows generation of realistic X-ray {\mu}-CBCT images, (2) facilitates CT HU calibration, and (3) performs proton dose calculations.<br>A {\mu}-CBCT model was developed using the fastCAT toolkit. Monte Carlo simulations were performed to generate the primary and scatter kernels and imaging dose calibration appropriate for {\mu}-CBCT scans. CTs were then generated for a mini Gammex phantom and the MOBY/ROBY digital rodent phantoms. The HU - SPR conversion is performed with the mini Gammex phantom. The resulting calibration parameters are then used to convert the CTs of the MOBY/ROBY phantoms to SPR maps. These are then used to calculate dose distributions in TOPAS for treatment plans created in matRad using realistic beams based on measured emittances and simulations of the beam transport with BDSIM. Since the composition of the MOBY/ROBY phantoms is known, a ground truth exists against which the accuracy of the calibration and dose distributions can be verified.<br>This framework is used to optimize the irradiation setup and assess the quality of small animal irradiations.},
}

@inproceedings{Rao:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Meineke, Jakob and Pezzotti, Nicola and Staring, Marius and van Osch, Matthias and Doneva, Mariya},
title 	= {Analysis of the Discretization Error vs. Estimation Time Tradeoff of MRF Dictionary Matching and the Advantage of the Neural Net-based Approach},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Traditional MR fingerprinting involves matching the acquired signal evolutions against a dictionary of expected tissue fingerprints to obtain thecorresponding tissue parameters. Since this dictionary is essentially a discrete representation of a physical model and the matching processamounts to brute-force search in a discretized parameter space, there arises a tradeoff between discretization error and parameter estimationtime. In this work, we investigate this tradeoff and show via numerical simulation how a neural net-based approach solves it. We additionallyconduct a phantom study using 1.5T and 3T data to demonstrate the consistency of neural net-based estimation with dictionary matching.},
}

@inproceedings{Dong:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Dong, Yiming and Koolstra, Kirsten and Beljaards, Laurens and Staring, Marius and van Osch, Matthias J.P. and B{\"o}rnert, Peter},
title 	= {Deep Learning Based Self-Navigated Diffusion Weighted Multi-Shot EPI with Supervised Denoising},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Advanced diffusion weighted self-navigated multi-shot MRI can run at high scan efficiencies resulting in good image quality. However, the model-based image reconstruction used is rather time consuming. Deep learning-based reconstruction approaches could function as a faster alternative. Tailored network architectures with appropriately set physical model constraints can help to shorten reconstruction times, resulting in good image quality with reduced noise propagation.},
}

@inproceedings{Lu:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Lu, Huangling and Juffermans, Joe F. and Pezzotti, Nicola and Staring, Marius and Lamb, Hildo J.},
title 	= {Deep learning-based acceleration of Compressed SENSE Cardiac MR imaging - accelerating total scan-times and reducing the number of breath holds},
journal 	= {Society for Cardiovascular Magnetic Resonance},
month 	= {January},
year 	= {2023},
  pdf =       {2023_a_SCMR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {With compressed sensing (CS) undersampled data points are used for MR image reconstruction to reduce acquisition times with preservation of SNR, but CS tends to simplify image content with higher levels of acceleration. Deep learning (DL) reconstruction methods could accelerate the acquisition process with preservation of high image quality by learning from high complexity images. In cardiac MR imaging high levels of acceleration allows multi-slice imaging during one breath-hold (BH) which could reduce scan-times significantly. We investigate the feasibility of a prospectively assessed DL-based reconstruction technique combined with different levels of acceleration using Compressed Sensing artificial intelligence framework in cardiac MR imaging.},
}

@inproceedings{Beljaards:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Beljaards, Laurens and Pezzotti, Nicola and Sch{\"u}lke, Christophe and van Osch, Matthias J.P. and Staring, Marius},
title 	= {The effect of intra-scan motion on AI reconstructions in MRI},
journal 	= {Medical Imaging with Deep Learning},
month 	= {July},
year 	= {2022},
  pdf =       {2022_a_MIDL.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {MRI can be accelerated via (AI-based) reconstruction by undersampling k-space. Current methods typically ignore intra-scan motion, although even a few millimeters of motion can introduce severe blurring and ghosting artifacts that necessitate reacquisition. In this short paper we investigate the effects of rigid-body motion on AI-based reconstructions. Leveraging the Bloch equations we simulate motion corrupted MRI acquisitions with a linear interleaved scanning protocol including spin history effects, and investigate i) the effect on reconstruction quality, and ii) if this corruption can be mitigated by introducing motion-corrupted data during training. We observe an improvement from 0.787 to 0.844 in terms of SSIM when motion-corrupted brain data is included during training, demonstrating that training with motion-corrupted data can partially compensate for motion corruption. Inclusion of spin-history effects did not influence the results.},
}

@inproceedings{Malimban:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius},
title 	= {External validation of deep learning models for mouse thorax autocontouring},
journal 	= {5th Conference on Small Animal Precision Image-guided Radiotherapy},
month 	= {March},
year 	= {2022},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Introduction: </b>Organ contouring is one of the most laborious and time-consuming stages in the preclinical irradiation workflow. Since deep learning algorithms have shown excellent performance on human organ segmentation, their application for animals have also been recently explored. However, previously developed deep learning-based animal autocontouring models were mostly trained on one type of dataset, and their predictive performance was also evaluated on the same distribution as the training data. In a preclinical facility wherein studies involving various strains of animals and image acquisition protocols are performed, it is important to demonstrate the robustness of these tools across different populations and settings. Therefore, in this work, we externally validated two deep learning pipelines for mouse thorax segmentation to assess their usability and portability when implemented on a larger scale.|<b>Materials & Methods: </b>We trained the 2D and 3D models of nnU-Net (i.e., one of the best performing algorithms for clinical segmentation) and compared them with the state-of-the-art AIMOS pipeline for segmentation of the mouse thorax. We allotted 105 native micro-CT scans of mice for the training and initially performed internal validation using 35 native micro-CT scans not included in the model development to determine the best nnU-Net model. Then, the proposed nnU-Net model and AIMOS were externally validated using 35 contrast-enhanced micro-CTs, which comprise of scans with a different mouse strain and imaging parameters than the training data. The predictive performance was evaluated in terms of the Dice score (DSC), mean surface distance (MSD), and 95% Hausdorff distance (95% HD).|<b>Results: </b>When tested against native micro-CTs, all models of nnU-Net (3d_fullres, 3d_cascade, 3d_lowres, 2d) and AIMOS generated accurate contours, achieving average DSC greater than 0.94, 0.90, 0.97 and 0.95 for the heart, spinal cord, right and left lungs, respectively. The average MSD was less than the in-plane voxel size of 0.14 mm while the average 95% HD was below 0.60 mm except for the right lung results of nnU-Net 2d. Among the nnU-Net models, 3d_fullres was considered the superior model, producing the most accurate contours at a reasonable speed. The nnU-Net 3d_fullres model and AIMOS were then evaluated against the external dataset. The nnU-Net 3d_fullres model achieved average DSC of 0.92, 0.85, 0.96 and 0.95 whereas AIMOS showed inferior results: 0.83, 0.82, 0.87 and 0.77. Consistent for all organs, AIMOS recorded unacceptably large 95% HD > 1 mm and produced incomplete contours. Moreover, AIMOS failed to distinguish the right lung from left lung. These entail that AIMOS requires more labor-intensive corrections than nnU-Net 3d_fullres for data on which the model was not trained on.|<b>Conclusion: </b>We have shown that the nnU-Net 3d_fullres model is more robust and generalizable than the current best performing algorithm for mouse segmentation (AIMOS). Our findings also demonstrate the importance of thoroughly evaluating the performance of autocontouring tools before implementation in routine preclinical practice.},
}

@inproceedings{Koolstra:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Koolstra, Kirsten and Staring, Marius and de Bruin, Paul and van Osch, Matthias J.P.},
title 	= {Subject-specific optimization of background suppression for arterial spin labeling MRI using a real-time feedback loop on the scanner},
booktitle 	= {International Society for Magnetic Resonance in Medicine},
address 	= {London, UK},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Background suppression (BGS) in arterial spin labeling (ASL) leads to perfusion images with a higher temporal signal-to-noise ratio (tSNR) compared to ASL without BGS. The optimal inversion times (TIs), and therefore the quality of the BGS, depend on the T1 relaxation times of the underlying tissue and on inhomogeneities of the scanner's magnetic fields (B0, B1+). In this work, we designed and implemented a feedback mechanism that optimized the quality of background suppression in real time on the scanner. The results show an increased tSNR for the subject-specific optimization of BGS compared to standard BGS in 12 healthy volunteers.},
}

@inproceedings{Brink:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Brink, Wyger and Staring, Marius and Remis, Rob and Webb, Andrew},
title 	= {Fast Subject-Specific SAR and B1+ Prediction for PTx at 7T using only an Initial Localizer Scan},
booktitle 	= {ISMRM},
address 	= {London, UK},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Ultra-high field (UHF) MRI (B<sub>0</sub> > 7T) shows great promise to yield higher resolution structural and physiological information than available at 3T, particularly in the brain. Parallel RF transmission (PTx) is a key technology for UHF-MRI to address the increased spatial variations in the radiofrequency (RF) field distribution. However, currently it has failed to reach widespread clinical adoption. The main factors include the intersubject variability in local specific absorption rate (SAR) leading to large safety margins to ensure compliance to regulatory limits, and time-consuming B1<sup>+</sup> calibration procedures required for tailored RF pulse design. Together, these technological challenges limit the clinical impact of PTx and the utilization of UHF-MRI.|In this work, we demonstrate a fast subject-specific method based on deep learning and a fast EM solver for predicting both SAR and B1<sup>+</sup> fields using only a 9 second long localizer scan.},
}

@inproceedings{Malimban:2022,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Lathouwers, Danny and Qian, Haibin and Verhaegen, Frank and Wiedemann, Julia and Brandenburg, Sytze and Staring, Marius},
title 	= {Autocontouring of the mouse thorax using deep learning},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2022},
  pdf =       {2022_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Image-guided small animal irradiations are typically performed in a single session, requiring continuous administration of anesthesia. Prolonged exposure to anesthesia can potentially affect experimental outcomes and thus, a fast preclinical irradiation workflow is desired. Similar to the clinic, delineation of organs remains one of the most time-consuming and labor-intensive stages in the preclinical workflow, and this is amplified by the fact that hundreds of animals are involved in a single study. In this work, we evaluated the accuracy and efficiency of deep learning pipelines for automated contouring of organs in the mouse thorax.},
}

@inproceedings{Koolstra:2021,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Koolstra, Kirsten and Staring, Marius and de Bruin, Paul and van Osch, Matthias J.P.},
title 	= {Individually optimized ASL background suppression using a real-time feedback loop on the scanner},
booktitle 	= {ESMRMB},
address 	= {online},
month 	= {October},
year 	= {2021},
  pdf =       {2021_a_ESMRMB.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Suppression of background signal in ASL leads to perfusion images with higher signal-to-noise ratio (SNR) compared to ASL without background suppression (BGS). BGS is obtained by applying multiple inversion pulses before and during the post-label delay (PLD). The optimal inversion times, and therefore the quality of the BGS, depends on the relaxation times of the underlying tissue (T1, T2) and on imperfections of the scanner's magnetic fields (B0, B1+). Although this results in inter-subject differences, current ASL protocols make use of one set of predefined inversion times for all subjects, primarily because these inter-scan variations are not known at the moment of scanning. This means that the quality of the resulting perfusion images is not optimal for all subjects. In this work, we develop and implement a feedback loop that optimizes the timings of ASL BGS pulses real-time on the scanner, generating individually optimized perfusion images for each subject.},
}

@inproceedings{Neve:2021,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Neve, Olaf and Tao, Qian and Romeijn, Stephan and Chen, Yunjie and de Boer, Nick P. and Grootjans, Willem and Kruit, Mark C. and Lelieveldt, Boudewijn P.F. and Jansen, Jeroen and Hensen, Erik and Staring, Marius and Verbist, Berit},
title 	= {Fully Automated 3D Vestibular Schwannoma Segmentation: A multicentre multi-vendor study},
booktitle 	= {European Society of Head and Neck Radiology (ESHNR)},
address 	= {online},
month 	= {September},
year 	= {2021},
  pdf =       {2021_a_ESHNR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Short summary:</b> For the evaluation of vestibular schwannoma (VS) progression and treatment planning, accurate measurement from MRI is important. In clinical practice, manual linear measurements are performed from MRI. Manual 3D measurement is time-consuming and 2D measurement is subjective and reflects highly variable tumour volume poorly. We developed an AI model to detect and segment VS from MRI automatically.|<b>Purpose/Objectives:</b> We present a model for the detection and segmentation of VS, based on deep learning and suited to process multi-centre, multi-vendor MR images. The model's performance is evaluated and compared to humans in an observer study.|<b>Methods & materials:</b> In total 214 cases (134 VS positive and 80 negative) with gadolinium-enhanced T1 and native T2 weighted MR images were acquired from 37 centres and 12 different MRI scanners. The intra- and extra meatal parts of the tumour were manually delineated by two observers under supervision of an experienced head and neck radiologist. Cases were divided into three non-overlapping sets (training, validation, and testing). A model was trained using 3D no-new-Unet deep learning segmentation method. In addition, an observer study was performed, in which the radiologist blinded to case information and delineation method compared model and human delineations.|<b>Results:</b> The model correctly detected VS in all positive cases and excluded the negative. Evaluation of the T1 model compared to the human delineation resulted in a Dice index 90.4&plusmn;13.0, Hausdorff distance 2.12&plusmn;9.32 mm, and mean surface-to-surface distance 0.49&plusmn;1.52 mm. Intra and extra meatal tumour parts had Dice indices of 77.5&plusmn;21.3 and 82.2&plusmn;28.0, respectively. The observer study showed that in 103 out of 111 cases (93%) the model was comparable to or better than human delineation.|<b>Conclusion:</b> The proposed model can accurately detect and delineate VS from MRI in a multi-centre, multi-vendor setting. As such, it is a robust tool well suited to the reality of clinical practise. The model performed comparably to human delineations in the observer study.},
}

@inproceedings{Brink:2021,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Brink, Wyger and Yousefi, Sahar and Bhatnagar, Prernna and Staring, Marius and Remis, Rob and Webb, Andrew},
title 	= {Numerical Body Model Inference for Personalized RF Exposure Prediction in Neuroimaging at 7T},
booktitle 	= {ISMRM},
address 	= {Vancouver, BC, Canada},
month 	= {May},
year 	= {2021},
  pdf =       {2021_a_ISMRM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Compliance with RF exposure limits in ultra-high field MRI is typically based on ``one-size-fits-all'' safety margins to account for the intersubject variability of local SAR. In this work we have developed a semantic segmentation method based on deep learning, which is able to generate a subject-specific bodymodel for personalized RF exposure prediction at 7T.},
}

@inproceedings{Tao:2020,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Tao, Qian and Romeijn, Stephan and Neve, Olaf and de Boer, Nick and Grootjans, Willem and Kruit, Mark C. and Lelieveldt, Boudewijn P.F. and Jansen, Jeroen and Hensen, Erik and Verbist, Berit and Staring, Marius},
title 	= {Deep-Learning-based Detection and Segmentation of Vestibular Schwannoma: A Multi-Center and Multi-Vendor MRI Study},
booktitle 	= {RSNA},
address 	= {Chicago, USA},
month 	= {November},
year 	= {2020},
  pdf =       {2020_a_RSNA.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>PURPOSE:</b> Accurate measurement of vestibular schwannoma (VS) is important for evaluation of VS progression and treatment planning. In clinical practice, linear measurements are manually performed from MRI. Manual measurement is time-consuming, subjective, and restricted to 2D planes. In this study, we aim to develop a deep learning convolutional neural network (CNN) model to automatically detect and segment VS in 3D from Gadolinium (Gd)-enhanced MRI.|<b>METHOD AND MATERIALS:</b> In total 124 patients with unilateral hearing loss referred to MRI exam were enrolled, including 84 VS-positive and 40 VS-negative cases. MRI data were acquired from 37 centers, by 12 different MRI scanners from 3 vendors. Typical image resolution was 0.35x0.35x1 mm, and field of view ranged from 130x130x24 mm to 270x270x188 mm. In 84 positive cases, VS was manually delineated by two observers, supervised by a senior radiologist. The 124 subjects were randomly divided into three non-overlapping sets: training set (N=72), validation set (N=18), and test set (N=34). We trained a 3D no-new-Unet CNN for both VS detection and segmentation. Training was performed on a NVIDIA Tesla V100 graphics processing unit with 16GB memory.|<b>RESULTS:</b> Applied to the test set, the CNN correctly detected VS in 24 subjects and excluded VS in 10 (sensitivity 100%, specificity 100%). We evaluated the Dice index, Hausdorff distance, and surface to surface (S2S) distance in two scenarios, namely, CNN vs. observer 1, and observer 1 vs. observer 2. No significant differences were found: Dice 0.91&plusmn;0.06 vs 0.92&plusmn;0.05 (p=0.5 by paired Wilcoxon test), Hausdorff 1.3&plusmn;1.5mm vs. 1.2&plusmn;1.0 mm (p=0.6), S2S 0.4&plusmn;0.3 mm vs. 0.4&plusmn;0.2 mm (p=0.9). The annotation time was 6.0&plusmn;3.3 min for the observer and 2.5&plusmn;2.8 min for the CNN model.|<b>CONCLUSION:</b> In a multi-center and multi-vendor setting, a CNN model can accurately detect and delineate VS in 3D from Gd-enhanced MRI, to faciliate diagnosis and measurement of VS in clinical practice.},
}

@inproceedings{Zhai:2020,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Zhai, Zhiwei and Ota, Hideki and Staring, Marius and Stolk, Jan and Sugimura, Koichiro and Takase, Kei and Stoel, Berend C.},
title 	= {Response to balloon pulmonary angioplasty in treated versus untreated pulmonary arteries in CTEPH patients},
booktitle 	= {European Congress of Radiology},
address 	= {Vienna, Austria},
month 	= {March},
year 	= {2020},
  pdf =       {2020_a_ECR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Purpose:</b> Balloon pulmonary angioplasty (BPA) is a treatment of obstructed pulmonary arteries (PAs), for patients with inoperable chronic thromboembolic pulmonary hypertension (CTEPH). Since the effect of BPA in untreated (i.e. unobstructed) PAs is unknown, we investigated the treatment response in treated and untreated PAs, by analyzing CT Pulmonary Angiography (CTPA).|<b>Methods and Materials:</b> We studied 22 consecutive CTEPH patients (20 female; age: 67 &plusmn; 14), who underwent CTPA and right-heart catheterization (RHC), pre- and post-BPA. In consensus, three experts selected treated artery segments based on the BPA locations and approximately 5 untreated artery segments at a similar level. Post-BPA CTPA scans were registered to pre-BPA scans, and local intravascular density changes were measured. The median density change in treated (MDC<sub>T</sub>) and untreated segments (MDC<sub>U</sub>) was calculated, based on manual selections. The difference between MDC<sub>U</sub> and MDC<sub>T</sub> was tested by paired T-test. The difference in density changes (&Delta;MDC) between treated and untreated PAs was calculated (MDC<sub>T</sub>-MDC<sub>U</sub>). Changes in RHC parameters included systolic, diastolic and mean pulmonary artery pressure (&Delta;sPAP, &Delta;dPAP and &Delta;mPAP) and in pulmonary vascular resistance (&Delta;PVR). The relation between hemodynamic changes and &Delta;MDC was studied with Spearman's correlation.|<b>Results:</b> MDC<sub>T</sub> (51 &plusmn; 85 HU) and MDC<sub>U</sub> (-23 &plusmn; 103 HU) were significantly different and in opposite direction (p=0.001). &Delta;MDC was significantly correlated with &Delta;dPAP (R=-0.55, p=0.008) and &Delta;PVR (R=-0.47, p=0.026), and marginally correlated with &Delta;mPAP (R=-0.4, p=0.068).|<b>Conclusion:</b> Perfusion in treated PAs increased, whereas perfusion in untreated PAs decreased. Not only improved perfusion in treated arteries, but also normalization in untreated arteries may play a significant role in improving hemodynamics by BPA.},
}

@inproceedings{Bayer:2019,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Bayer, S. and Zhai, Z. and Strumia, M. and Tong, X. and Gao, Y. and Staring, M. and Stoel, B.C. and Ostermeier, M. and Fahrig, R. and Nabavi, A. and Maier, A. and Ravikumar, N.},
title 	= {Local topology preservation for vascular centerline matching using a hybrid mixture model},
booktitle 	= {IEEE Nuclear Science Symposium and Medical Imaging Conference},
address 	= {Manchester, UK},
month 	= {October},
year 	= {2019},
  pdf =       {2019_a_NSSMIC.pdf},
  html =      {https://doi.org/10.1109/NSS/MIC42101.2019.9059857},
  arxiv =     {},
  code =      {},
  abstract =  {Non-rigid registration is essential for a wide range of clinical applications, such as intraoperative image-guidance and postoperative follow-up assessment, and longitudinal image analysis for disease diagnosis and monitoring. Vascular structures are a rich descriptor of the organ deformation, since it permeates through all organs within body. As vasculature differs in size, shape and topology, following surgical intervention/treatment or due to disease progression,  non-rigid vessel matching remains a challenging task. Recently, hybrid mixture models (HdMM) have been applied to tackle this challenge, and demonstrate significant improvements in terms of accuracy and robustness relative to the state-of-the-art. However, the smoothness constraint enforced on the deformation field with this approach only accounts for the global topology of the vasculature, resulting in a reduced capacity to accurately match localized changes to vascular structures, and preserve local topology. In this work, we proposed a modified version of HdMM by formulating an adaptive kernel, to enforce a local smoothness constraint on the deformation field, henceforth referred to as HdMMad. The proposed HdMMad framework is evaluated with cerebral and pulmonary vasculature, acquired retrospectively. The registration results for both data sets demonstrate that the proposed approach outperforms registration algorithms also designed to preserve local topology. Using HdMMad, around 80% of the initial registration error was reduced, for both data sets.},
}

@inproceedings{Yousefi:2019,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Yousefi, Sahar and Sokooti, Hessam and Hirschler, L. and van der Plas, M. and Petitclerc, L. and Staring, Marius and van Osch, Mathias J.P.},
title 	= {Reconstruction of Dynamic Perfusion and Angiography Images from Sub-sampled Hadamard Time-encoded ASL Data using Deep Convolutional Neural Networks},
journal 	= {ESMRMB},
volume 	= {32},
number 	= {1},
pages 	= {S96 - S97},
month 	= {October},
year 	= {2019},
  pdf =       {2019_a_ESMRMB.pdf},
  html =      {http://dx.doi.org/10.1007/s10334-019-00753-3},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Purpose/Introduction:</b> Arterial spin labeling (ASL) is a non-invasive technique for acquiring quantitative measures of cerebral blood flow (CBF). Hadamard time-encoded(te) pCASL allows time-efficient acquisition of dynamic ASL-data and when done with and without flow-crushing, 4D MRA and arterial input function measurements can be obtained. While improving quantification, this approach is also a factor two slower. In this study, we propose an end-to-end 3D convolutional neural network (CNN) in order to accelerate CBF quantification from sparse sampling (50%) of te-pCASL with and without flow crushers. For training and evaluation of the CNN, we propose a framework to simulate the te-PCASL signal.|<b>Subjects and Methods:</b> Fig. 1a shows the proposed framework for generating the training and validation data. The ASL signal is simulated by a tracer kinetic model of te-pCASL. This model is a function of arterial arrival time, tissue arrival time and blood flow, which were extracted from in vivo data and registered to BrainWeb scans. This study contains 1676 simulated subjects, each including crushed and non-crushed input data at 8 timepoints, and angiographic and perfusion output data at 7 timepoints. The proposed CNN, Fig. 1b, leverages design elements from DenseNet with loop connectivity patterns in a typical U-shape (~400K parameters). We leverage a Huber loss function for training the network, with weights based on the gradient magnitudes from Fig. 2a. In order to manage memory usage, we utilize patch-based training. The simulated dataset was divided into 1174 subjects for training, 167 for validation, and 335 for testing. For augmenting the training data, noise, flipping and &plusmn;13<sup>{\circ}</sup> rotation have been applied randomly. The network was trained for 30k iterations.|<b>Results:</b> Fig. 2b, shows the network's training loss for the perfusion and angiography separately and their combination. The average MSE for the perfusion and the angiography is 5.30&plusmn;0.22 and 5.02&plusmn;0.17. Fig. 3 shows the outputs of the network for some slices of perfusion/angiography at different timepoints. Due to the averaging property in the Huber loss function, the results suffer from over-smoothing. It takes an average of 0.12&plusmn;0.18s to reconstruct all perfusion and angiography scans from the sparsely-sampled crushed/noncrushed data (size 101<sup>3</sup>).|<b>Discussion/Conclusion:</b> This study demonstrates that CNNs are promising to reconstruct angiographic and perfusion images from sparsely sampled Hadamard ASL-data. A next step is the use of perceptual losses to improve sharpness of the results, as well as validation on in vivo data.},
}

@inproceedings{vandenEnde:2019,
  abbr =    {},
  bibtex_show = {true},
  author 	= {van den Ende, Roy P.J. and Kerkhof, Ellen M. and Rigter, L.S. and van Leerdam, M. and Peters, Femke P. and van Triest, B. and Staring, Marius and Marijnen, Corrie A.M. and van der Heide, Uulke A.},
title 	= {Feasibility of gold fiducial markers as a surrogate for GTV position in image-guided radiotherapy of rectal cancer},
booktitle 	= {American Association of Physicists in Medicine (AAPM)},
address 	= {San Antonio, TX, USA},
month 	= {July},
year 	= {2019},
  pdf =       {2019_a_AAPM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Purpose:</b> To evaluate the feasibility of fiducial markers as a surrogate for GTV position in image-guided radiotherapy of rectal cancer.|<b>Methods and Materials:</b> We analyzed 35 fiducials in 19 rectal cancer patients who received short course radiotherapy or long-course chemoradiotherapy (LC-CRT). Two MRI exams and daily pre- and post-irradiation CBCT scans were acquired in the first week of radiotherapy. Weekly CBCT scans were acquired thereafter for patients that received LC-CRT. Between the two MRI exams, the fiducial displacement relative to the center of gravity of the GTV (COG<sub>GTV</sub>) and the COG<sub>GTV</sub> displacement relative to bony anatomy was determined. Using the CBCT scans, inter- and intrafraction fiducial displacement relative to bony anatomy was determined.|<b>Results:</b> The systematic error of the fiducial displacement relative to the COG<sub>GTV</sub> was 2.8, 2.4 and 4.2 mm in the left-right (LR), anterior-posterior (AP) and craniocaudal (CC) direction. Large interfraction systematic errors of up to 8.0 and random errors up to 4.7 mm were found for COG<sub>GTV</sub> and fiducial displacements relative to bony anatomy, mostly in the AP and CC directions. For tumors located in the mid- and upper rectum these errors were 9.4 (systematic) and 5.6 mm (random) compared to 4.9 and 2.9 mm for tumors in the lower rectum. Systematic and random errors of the intrafraction fiducial displacement relative to bony anatomy were <2.1 mm in all directions.|<b>Conclusions:</b> Large interfraction errors of the COG<sub>GTV</sub> and the fiducials relative to bony anatomy were found. Therefore, despite the observed fiducial displacement relative to the COG<sub>GTV</sub>, the use of fiducials as a surrogate for GTV position reduces the required margins in the AP and CC direction for a GTV boost using image-guided radiotherapy of rectal cancer. This reduction may be larger in patients with tumors located in the mid- and upper rectum compared to the lower rectum.},
}

@inproceedings{Jagt:2019a,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Jagt, T. and Breedveld, S. and van Haveren, R. and Nout, R. and Astreinidou, E. and Staring, M. and Heijmen, B. and M. Hoogeman,},
title 	= {An automated replanning strategy for near real-time adaptive proton therapy},
booktitle 	= {Particle Therapy Co-operative Group},
address 	= {Manchester, UK},
month 	= {June},
year 	= {2019},
  pdf =       {2019_a_PTCOG.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Purpose:</b> To develop a method to automatically adapt treatment plans in near real-time to the anatomy-of-the-day for prostate and cervical cancer.|<b>Material / Methods:</b> Starting point is a prior plan optimized on the planning CT. First, spot positions (Bragg peaks) from the prior plan are restored by adjusting the energy of each pencil-beam to the water-equivalent path length in the daily CT. Subsequently, to compensate for deformations of target and OARs, pencil-beams are added followed by a pencil-beam weight optimization using the Reference-Point-Method. This method generates a Pareto optimal plan for the anatomy-of-the-day, with similar trade-offs to those in the prior plan. The method was evaluated using 8-10 daily CTs of 11 prostate cancer patients (88 CTs) and 3-4 daily CTs of 5 cervical cancer patients (19 CTs). Evaluation was done by comparing for each CT a full multi-criteria optimization without time constraints (benchmark) to the proposed method and to a forward dose calculation of the prior plan on each CT (no replanning).|<b>Results:</b> The figures show large dosimetric differences between no replanning and benchmark, while the differences between the proposed method and benchmark are substantially smaller. The use of replanning improved target coverage to clinically acceptable levels in 85/88 CTs and 19/19 CTs for prostate and cervix, respectively. All plans showed reduced OAR doses. Replanning took on average 2.9 and 3.6 minutes for prostate and cervix, respectively, using ~50% for dose computation.|<b>Conclusion:</b> The automation and realized replanning times make the proposed method an important step towards real-time adaptive proton therapy.},
}

@inproceedings{Jagt:2019b,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Jagt, Thyrza and Breedveld, Sebastiaan and van Haveren, Rens and Nout, Remi and Astreinidou, Eleftheria and Staring, Marius and Heijmen, Ben and Hoogeman, Mischa},
title 	= {Plan-library supported automated re-planning for online-adaptive IMPT of cervical cancer},
journal 	= {Radiotherapy and Oncology (ESTRO)},
volume 	= {133},
number 	= {Supplement 1},
pages 	= {S38 - S39},
month 	= {April},
year 	= {2019},
  pdf =       {2019_a_ESTROa.pdf},
  html =      {https://doi.org/10.1016/S0167-8140(19)30501-8},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Purpose/objective:</b> Intensity-modulated proton therapy (IMPT) is very sensitive to small daily density variations along the pencil beam paths and variations in target and OAR shapes. This makes IMPT for sites with large inter-fraction target deformations extra challenging, such as in the treatment of cervical cancer. Online replanning is an option to achieve adequate target dose in each fraction. This study evaluates a novel approach employing a pre-treatment established plan-library as prior information in automated online replanning for IMPT of cervical cancer.|<b>Material and Methods:</b> CT data of 5 cervical cancer patients was available, comprising of a full and empty-bladder CT and 3-4 repeat CTs. Prescribed dose for the primary tumor and pelvic ±para-aortic lymph nodes was 45 Gy. Pre-treatment plan-libraries were created to provide prior spot distributions for replanning on the repeat CTs. One consisted of two treatment plans based on the full and empty-bladder CT +8 mm margin and the other of one treatment plan encompassing all target deformation observed in the full and empty-bladder CT +10 mm margin, i.e. a large ITV. In case of the 2-plan-library the daily bladder volume was used to select the prior plan for replanning.<br>The reoptimization method starts with a spot-position (Bragg peak) restoration from the selected prior plan by adjusting the energy of each pencil beam to the water equivalent path length in the repeat CT. To further compensate for deformations, new spots are added. The reference point method (RPM) is then used to optimize the spot weights. The RPM has been automatically tuned on benchmark plans of 4 CTs (i.e. optimized from scratch without time constraints) and results in a reoptimized Pareto optimal plan for the new anatomy, with similar trade-offs as in the benchmark plan. Replanning was performed for each repeat CT using tight margins of 5/2 mm (primary tumor/nodes), only meant to account for intra-fraction motion. The prior and reoptimized plans were evaluated on the repeat CTs using the 5/2 mm-PTVs and compared to benchmark plans on the repeat CTs.|<b>Results:</b> Evaluating the prior plans on the repeat CTs without replanning resulted in V<sub>95%</sub><95% in most CTs, with values down to 50% (see Fig 1). For both plan-library approaches, reoptimization increased the number of repeat CTs with adequate coverage (PTV V<sub>95%</sub>=95% and V<sub>107%</sub>=2%) from 2/19 to 19/19 CTs. Fig 2 shows the differences between the reoptimized and benchmark plans on the repeat CTs using the ITV or 2-plan-library as prior. Median improvements are seen up to 4.5%-point for bladder V30Gy when using the 2-plan-library instead of the ITV plan, with outliers up to 13.8%-point. Reoptimization took 3.6 min on average.|<b>Conclusion:</b> With fully automated replanning, adequate target coverage was restored for all CTs, as well as decreased OAR doses. The use of a 2-plan-library yielded lower OAR doses than a single ITV prior plan. With an average time of 3.6 minutes, this method is an important step towards online-adaptive IMPT in cervical cancer.},
}


