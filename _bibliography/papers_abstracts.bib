

@inproceedings{Rao:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Beljaards, Laurens and van Osch, Matthias and Doneva, Mariya and Meineke, Jakob and Sch{\"u}lke, Christophe and Pezzotti, Nicola and de Weerdt, Elwin and Staring, Marius},
title 	= {Guided Multicontrast Reconstruction based on the Decomposition of Content and Style},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2024},
  pdf =       {2024_a_ISMRM.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {<b>Motivation: </b>Scans within an MR exam share redundant information due to the same underlying structures. One contrast can hence be used to guide the reconstruction of another, thereby requiring less measurements.<br><b>Goals: </b>Multimodal guided reconstruction to reduce scanning times.<br><b>Approach: </b>Our method exploits AI-based content/style decomposition in an iterative reconstruction algorithm. We explored this concept via numerical simulation and subsequently validated it on in vivo data.<br><b>Results: </b>Compared to a conventional compressed sensing baseline, our method showed consistent improvement in simulations and produced sharper reconstructions from undersampled in vivo data. By enforcing data consistency, it was also more reliable than blind image translation.<br><b>Impact: </b>In the clinic, this can potentially enable a reduced MR exam time for a given image quality or improve image quality given a scan time budget. The former can reduce strain on the patient, whereas the latter can improve diagnosis.},
}

@inproceedings{Mody:2024,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Mody, Prerak and Huiskes, Merle and Chaves de Plaza, Nicolas and Onderwater, Alice and Lamsma, Rense and Hildebrandt, Klaus and Hoekstra, Nienke and Astreinidou, Eleftheria and Staring, Marius and Dankers, Frank},
title 	= {Dose evaluation using existing plan parameters of auto-contouring in head-and-neck radiotherapy},
journal 	= {Radiotherapy and Oncology (ESTRO)},
month 	= {May},
year 	= {2024},
  pdf =       {2024_a_ESTRO.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Previous work on auto-contour dose evaluation has used both manual [1] and automated [2,3] techniques, however with small (~20) test patient cohorts. This is due to extensive manual effort required for additional contour refinement and treatment planning on the auto-contours. Moreover, automated planning techniques, if not already clinically implemented, are difficult to adopt. Our primary goal is to investigate the dosimetric effect of auto-contouring for proton radiotherapy using a large-scale cohort of patients. A secondary goal is to develop and evaluate a workflow that is both automated and uses existing plan parameters, hence enabling evaluation for a large patient cohort.},
}

@inproceedings{Goedmakers:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Goedmakers, C.M.W and Pereboom, L.M. and de Leeuw den Bouter, M.L. and Remis, R.F. and Staring, M. and Vleggeert-Lankamp, C.L.A.},
title 	= {Deep Learning on Preoperative Radiographs for Clinical Success Prediction after Surgery for Cervical Degenerative Disease},
journal 	= {Brain and Spine},
volume 	= {3},
pages 	= {101842},
year 	= {2023},
  pdf =       {2023_a_BandS.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {As populations age and the prevalence of cervical spine degeneration rises, the demand for computer-aided diagnostics and prognostics in neurosurgery rises. Not all patients benefit from surgical treatment and predicting who will remains challenging. Automating parts of the radiological image analysis process using Machine Learning could provide more accurate, consistent assessment with increased time efficiency, and potentially gain new disease insights. The purpose of this study was to identify which image features on cervical radiographs are important for the prediction of clinical success one year after surgery for cervical disc disease, by developing and validating a deep learning algorithm that predicts clinical success solely based on the radiograph.},
}

@inproceedings{Malimban:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Malimban, Justin and Ludwig, Felix and Lathouwers, Danny and Staring, Marius and Verhaegen, Frank and Brandenburg, Sytze},
title 	= {A simulation framework of the preclinical proton irradiation workflow},
booktitle 	= {Particle Therapy Co-operative Group},
address 	= {Madrid, Spain},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_PTCOG.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {The size of orthotopic tumors in small animals (typically a few mm) presents some challenges in preclinical proton dose delivery. For tumors situated deeper in the animal close to critical organs, determination of the actual dose distribution and conformity is challenging especially for Bragg peak irradiations. Therefore, it is important to optimize beam properties, verify CT HU-RSP calibration, and ensure the quality of dose distributions.<br>In this work, we present a simulation framework that (1) allows generation of realistic X-ray {\mu}-CBCT images, (2) facilitates CT HU calibration, and (3) performs proton dose calculations.<br>A {\mu}-CBCT model was developed using the fastCAT toolkit. Monte Carlo simulations were performed to generate the primary and scatter kernels and imaging dose calibration appropriate for {\mu}-CBCT scans. CTs were then generated for a mini Gammex phantom and the MOBY/ROBY digital rodent phantoms. The HU - SPR conversion is performed with the mini Gammex phantom. The resulting calibration parameters are then used to convert the CTs of the MOBY/ROBY phantoms to SPR maps. These are then used to calculate dose distributions in TOPAS for treatment plans created in matRad using realistic beams based on measured emittances and simulations of the beam transport with BDSIM. Since the composition of the MOBY/ROBY phantoms is known, a ground truth exists against which the accuracy of the calibration and dose distributions can be verified.<br>This framework is used to optimize the irradiation setup and assess the quality of small animal irradiations.},
}

@inproceedings{Rao:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Rao, Chinmay and Meineke, Jakob and Pezzotti, Nicola and Staring, Marius and van Osch, Matthias and Doneva, Mariya},
title 	= {Analysis of the Discretization Error vs. Estimation Time Tradeoff of MRF Dictionary Matching and the Advantage of the Neural Net-based Approach},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMa.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Traditional MR fingerprinting involves matching the acquired signal evolutions against a dictionary of expected tissue fingerprints to obtain thecorresponding tissue parameters. Since this dictionary is essentially a discrete representation of a physical model and the matching processamounts to brute-force search in a discretized parameter space, there arises a tradeoff between discretization error and parameter estimationtime. In this work, we investigate this tradeoff and show via numerical simulation how a neural net-based approach solves it. We additionallyconduct a phantom study using 1.5T and 3T data to demonstrate the consistency of neural net-based estimation with dictionary matching.},
}

@inproceedings{Dong:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Dong, Yiming and Koolstra, Kirsten and Beljaards, Laurens and Staring, Marius and van Osch, Matthias J.P. and Börnert, Peter},
title 	= {Deep Learning Based Self-Navigated Diffusion Weighted Multi-Shot EPI with Supervised Denoising},
journal 	= {International Society for Magnetic Resonance in Medicine},
month 	= {June},
year 	= {2023},
  pdf =       {2023_a_ISMRMb.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {Advanced diffusion weighted self-navigated multi-shot MRI can run at high scan efficiencies resulting in good image quality. However, the model-based image reconstruction used is rather time consuming. Deep learning-based reconstruction approaches could function as a faster alternative. Tailored network architectures with appropriately set physical model constraints can help to shorten reconstruction times, resulting in good image quality with reduced noise propagation.},
}

@inproceedings{Lu:2023,
  abbr =    {},
  bibtex_show = {true},
  author 	= {Lu, Huangling and Juffermans, Joe F. and Pezzotti, Nicola and Staring, Marius and Lamb, Hildo J.},
title 	= {Deep learning-based acceleration of Compressed SENSE Cardiac MR imaging - accelerating total scan-times and reducing the number of breath holds},
journal 	= {Society for Cardiovascular Magnetic Resonance},
month 	= {January},
year 	= {2023},
  pdf =       {2023_a_SCMR.pdf},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {With compressed sensing (CS) undersampled data points are used for MR image reconstruction to reduce acquisition times with preservation of SNR, but CS tends to simplify image content with higher levels of acceleration. Deep learning (DL) reconstruction methods could accelerate the acquisition process with preservation of high image quality by learning from high complexity images. In cardiac MR imaging high levels of acceleration allows multi-slice imaging during one breath-hold (BH) which could reduce scan-times significantly. We investigate the feasibility of a prospectively assessed DL-based reconstruction technique combined with different levels of acceleration using Compressed Sensing artificial intelligence framework in cardiac MR imaging.},
}

@inproceedings{,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}

@inproceedings{,
  abbr =    {},
  bibtex_show = {true},
  pdf =       {},
  html =      {},
  arxiv =     {},
  code =      {},
  abstract =  {},
}


