---
---

@string{aps = {American Physical Society,}}

@article{Mody:2024,
  abbr={PhIRO},
  bibtex_show={true},
  title={Large-scale dose evaluation of deep learning organ contours in head-and-neck radiotherapy by leveraging existing plans},
  author={Mody, Prerak and Huiskes, Merle and Chaves "de Plaza", Nicolas and Onderwater, Alice and Lamsma, Rense and Hildebrandt, Klaus and Hoekstra, Nienke and Astreinidou, Eleftheria and Staring, Marius and Dankers, Frank},
  journal={Physics and Imaging in Radiation Oncology},
  volume={30},
  pages={100572},
  month={April},
  year={2024},
  pdf={2024_j_PHIRO.pdf},
  html={https://doi.org/10.1016/j.phro.2024.100572},
  abstract={<b>Background and Purpose:</b> Retrospective dose evaluation for organ-at-risk auto-contours has previously used small cohorts due to additional manual effort required for treatment planning on auto-contours. We aimed to do this at large scale, by a) proposing and assessing an automated plan optimization workflow that used existing clinical plan parameters and b) using it for head-and-neck auto-contour dose evaluation.<br><b>Materials and Methods:</b> Our automated workflow emulated our clinic's treatment planning protocol and reused existing clinical plan optimization parameters. This workflow recreated the original clinical plan (POG) with manual contours (PMC) and evaluated the dose effect (POG - PMC) on 70 photon and 30 proton plans of head-and-neck patients. As a use-case, the same workflow (and parameters) created a plan using auto-contours (PAC) of eight head-and-neck organs-at-risk from a commercial tool and evaluated their dose effect (PMC - PAC).<br><b>Results:</b> For plan recreation (POG - PMC), our workflow had a median impact of 1.0% and 1.5% across dose metrics of auto-contours, for photon and proton respectively. Computer time of automated planning was 25% (photon) and 42% (proton) of manual planning time. For auto-contour evaluation (PMC - PAC), we noticed an impact of 2.0% and 2.6% for photon and proton radiotherapy. All evaluations had a median ΔNTCP (Normal Tissue Complication Probability) less than 0.3%.<br><b>Conclusions:</b> The plan replication capability of our automated program provides a blueprint for other clinics to perform auto-contour dose evaluation with large patient cohorts. Finally, despite geometric differences, auto-contours had a minimal median dose impact, hence inspiring confidence in their utility and facilitating their clinical adoption.}
}

@article{Stoel:2024,
  abbr={Nat. Rev. Rheumatol.},
  bibtex_show={true},
  title={Deep Learning in Rheumatologic Image Interpretation},
  author={Stoel, Berend C. and Staring, Marius and Reijnierse, Monique and van der Helm-van Mil, Annette H.M.},
  journal={Nature Reviews Rheumatology},
  volume={20},
  pages={182 -- 195},
  month={March},
  year={2024},
  pdf={2024_j_NRR.pdf},
  html={https://doi.org/10.1038/s41584-023-01074-5},
  abstract={Artificial intelligence techniques, specifically deep learning, have already affected daily life in a wide range of areas. Likewise, initial applications have been explored in rheumatology. Deep learning might not easily surpass the accuracy of classic techniques when performing classification or regression on low-dimensional numerical data. With images as input, however, deep learning has become so successful that it has already outperformed the majority of conventional image-processing techniques developed during the past 50 years. As with any new imaging technology, rheumatologists and radiologists need to consider adapting their arsenal of diagnostic, prognostic and monitoring tools, and even their clinical role and collaborations. This adaptation requires a basic understanding of the technical background of deep learning, to efficiently utilize its benefits but also to recognize its drawbacks and pitfalls, as blindly relying on deep learning might be at odds with its capabilities. To facilitate such an understanding, it is necessary to provide an overview of deep-learning techniques for automatic image analysis in detecting, quantifying, predicting and monitoring rheumatic diseases, and of currently published deep-learning applications in radiological imaging for rheumatology, with critical assessment of possible limitations, errors and confounders, and conceivable consequences for rheumatologists and radiologists in clinical practice.}
}

@article{Neve:2022,
  abbr =    {Radiol Artif Intell},
  bibtex_show = {true},
  author =  {Neve, Olaf and Chen, Yunjie and Tao, Qian and Romeijn, Stephan and de Boer, Nick and Grootjans, Willem and Kruit, Mark and Lelieveldt, Boudewijn and Jansen, Jeroen and Hensen, Erik and Verbist, Berit and Staring, Marius},
  title =   {Fully Automated 3D Vestibular Schwannoma Segmentation with and without Gadolinium Contrast: a multi-center, multi-vendor study},
  journal = {Radiology: Artificial Intelligence},
  volume =  {4},
  number =  {4},
  pages =   {e210300},
  year =    {2022},
  pdf =     {2022_j_RadAI.pdf},
  html =    {https://doi.org/10.1148/ryai.210300},
  abstract = {<b>Purpose:</b> To develop automated vestibular schwannoma measurements on contrast-enhanced T1- and T2-weighted MRI.<br><b>Material and methods:</b> MRI data from 214 patients in 37 different centers was retrospectively analyzed between 2020-2021. Patients with hearing loss (134 vestibular schwannoma positive [mean age ± SD, 54 ± 12 years; 64 men], 80 negative) were randomized to a training and validation set and an independent test set. A convolutional neural network (CNN) was trained using five-fold cross-validation for two models (T1 and T2). Quantitative analysis including Dice index, Hausdorff distance, surface-to-surface distance (S2S), and relative volume error were used to compare the computer and the human delineations. Furthermore, an observer study was performed in which two experienced physicians evaluated both delineations.<br><b>Results:</b> The T1-weighted model showed state-of-the-art performance with a mean S2S distance of less than 0.6 mm for the whole tumor and the intrameatal and extrameatal tumor parts. The whole tumor Dice index and Hausdorff distance were 0.92 and 2.1 mm in the independent test set. T2-weighted images had a mean S2S distance less than 0.6 mm for the whole tumor and the intrameatal and extrameatal tumor parts. Whole tumor Dice index and Hausdorff distance were 0.87 and 1.5 mm in the independent test set. The observer study indicated that the tool was comparable to human delineations in 85-92% of cases.<br><b>Conclusion:</b> The CNN model detected and delineated vestibular schwannomas accurately on contrast-enhanced T1 and T2-weighted MRI and distinguished the clinically relevant difference between intrameatal and extrameatal tumor parts.}
}
