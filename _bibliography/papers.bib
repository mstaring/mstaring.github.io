---
---

@string{aps = {American Physical Society,}}

@article{Shahzad:2015,
  abbr =     {},
  bibtex_show = {true},
  author = {Shahzad, Rahil and Dzyubachyk, Oleh and Staring, Marius and Kullberg, Joel and Johansson, Lars and Ahlstr{\"o}m, H{\r{a}}kan and Lelieveldt, Boudewijn P. F. and van der Geest, Rob J.},
  title = {Automated Extraction and Labelling of the Arterial Tree from Whole-Body MRA Data},
  journal = {Medical Image Analysis},
  volume = {24},
  number = {1},
  pages =    {28 -- 40},
  month = {August},
  year = {2015},
  pdf =      {2015_j_MedIA.pdf},
  html =     {http://dx.doi.org/10.1016/j.media.2015.05.008},
  arxiv =    {},
  code =     {},
  abstract = {In this work, we present a fully automated algorithm for extraction of the 3D arterial tree and labelling the tree segments from whole-body magnetic resonance angiography (WB-MRA) sequences. The algorithm developed consists of two core parts (i) 3D volume reconstruction from different stations with simultaneous correction of different types of intensity inhomogeneity, and (ii) Extraction of the arterial tree and subsequent labelling of the pruned extracted tree. Extraction of the arterial tree is performed using the probability map of the "contrast" class, which is obtained as one of the results of the inhomogeneity correction scheme. We demonstrate that such approach is more robust than using the difference between the pre- and post-contrast channels traditionally used for this purpose. Labelling the extracted tree is performed by using a combination of graph-based and atlas-based approaches. Validation of our method with respect to the extracted tree was performed on the arterial tree subdivided into 32 segments, 82.4% of which were completely detected, 11.7% partially detected, and 5.9% were missed on a cohort of 35 subjects. With respect to automated labelling accuracy of the 32 segments, various registration strategies were investigated on a training set consisting of 10 scans. Further analysis on the test set consisting of 25 data sets indicates that 69% of the vessel centerline tree in the head and neck region, 80% in the thorax and abdomen region, and 84% in the legs was accurately labelled to the correct vessel segment. These results indicate clinical potential of our approach in enabling fully automated and accurate analysis of the entire arterial tree. This is the first study that not only automatically extracts the WB-MRA arterial tree, but also labels the vessel tree segments.},
}

@article{Ninaber:2015,
  abbr =     {},
  bibtex_show = {true},
  pdf =      {2015_j_EJR.pdf},
  author =   {Ninaber, Maarten K. and Stolk, Jan and Smit, Jasper and Le Roy, Ernest J. and Kroft, Lucia J.M. and Bakker, M.E. and de Vries Bouwstra, Jeska K. and Schouffoer, Anna A. and Staring, Marius and Stoel, Berend C.},
  title =    {Lung Structure And Function Relation In Systemic Sclerosis: Application Of Lung Densitometry},
  journal =  {European Journal of Radiology},
  volume =   {84},
  number =   {5},
  pages =    {975 - 979},
  month =    {May},
  year =     {2015},
  html =     {http://dx.doi.org/10.1016/j.ejrad.2015.01.012},
  arxiv =    {},
  code =     {},
  abstract = {<b>Introduction.</b> Interstitial lung disease occurs frequently in patients with systemic sclerosis (SSc). Quantitative computed tomography (CT) densitometry using the percentile density method may provide a sensitive assessment of lung structure for monitoring parenchymal damage. Therefore, we aimed to evaluate the optimal percentile density score in SSc by quantitative CT densitometry, against pulmonary function.<br><b>Material and Methods.</b> We investigated 41 SSc patients by chest CT scan, spirometry and gas transfer tests. Lung volumes and the nth percentile density (between 1 and 99%) of the entire lungs were calculated from CT histograms. The nth percentile density is defined as the threshold value of densities expressed in Hounsfield units. A prerequisite for an optimal percentage was its correlation with baseline DLCO%predicted. Two patients showed distinct changes in lung function 2 years after baseline. We obtained CT scans from these patients and performed progression analysis.<br><b>Results.</b> Regression analysis for the relation between DLCO%predicted and the nth percentile density was optimal at 85% (Perc85). There was significant agreement between Perc85 and DLCO%predicted (R = -0.49, P = 0.001) and FVC%predicted (R = -0.64, P < 0.001). Two patients showed a marked change in Perc85 over a two year period, but the localisation of change differed clearly.<br><b>Conclusions.</b> We identified Perc85 as optimal lung density parameter, which correlated significantly with DLCO and FVC, confirming a lung parenchymal structure-function relation in SSc. This provides support for future studies to determine whether structural changes do precede lung function decline.},
}

@article{Stoel:2015,
  abbr =     {},
  bibtex_show = {true},
  author =   {Stoel, Berend C. and Marquering, Henk A. and Staring, Marius and Beenen, Ludo F. and Slump, Cornelis H. and Roos, Yvo B. and Majoie, Charles B.},
  title =    {Automated brain computed tomographic densitometry of early ischemic changes in acute stroke},
  journal =  {Journal of Medical Imaging},
  volume =   {2},
  number =   {1},
  pages =    {014004},
  month =    {March},
  year =     {2015},
  pdf =      {2015_j_JMI.pdf},
  html =     {http://dx.doi.org/10.1117/1.JMI.2.1.014004},
  arxiv =    {},
  code =     {},
  abstract = {The Alberta Stroke Program Early CT score (ASPECTS) scoring method is frequently used for quantifying early ischemic changes (EICs) in patients with acute ischemic stroke in clinical studies. Varying interobserver agreement has been reported, however, with limited agreement. Therefore, our goal was to develop and evaluate an automated brain densitometric method. It divides CT scans of the brain into ASPECTS regions using atlas-based segmentation. EICs are quantified by comparing the brain density between contralateral sides. This method was optimized and validated using CT data from 10 and 63 patients, respectively. The automated method was validated against manual ASPECTS, stroke severity at baseline and clinical outcome after 7 to 10 days (NIH Stroke Scale, NIHSS) and 3 months (modified Rankin Scale). Manual and automated ASPECTS showed similar and statistically significant correlations with baseline NIHSS (R=-0.399 and -0.277, respectively) and with follow-up mRS (R=-0.256 and -0.272), except for the follow-up NIHSS. Agreement between automated and consensus ASPECTS reading was similar to the interobserver agreement of manual ASPECTS (differences <1 point in 73% of cases). The automated ASPECTS method could, therefore, be used as a supplementary tool to assist manual scoring.},
}

@article{Rudyanto:2014,
  abbr =     {},
  bibtex_show = {true},
  author =   {Rudyanto, Rina D. and Kerkstra, Sjoerd and van Rikxoort, Eva M. and Fetita, Catalin and Brillet, Pierre-Yves and Lefevre, Christophe and Xue, Wenzhe and Zhu, Xiangjun and Liang, Jianming and {\"O}ks{\"u}z, Ilkay and {\"U}nay, Devrim and Kadipasaoglu, Kamuran and Est{\'e}par, Ra{\'u}l San Jos{\'e} and Ross, James C. and Washko, George R. and Prieto, Juan-Carlos and Hoyos, Marcela Hern{\'a}ndez and Orkisz, Maciej and Meine, Hans and H{\"u}llebrand, Markus and St{\"o}cker, Christina and Mir, Fernando Lopez and Naranjo, Valery and Villanueva, Eliseo and Staring, Marius and Xiao, Changyan and Stoel, Berend C. and Fabijanska, Anna and Smistad, Erik and Elster, Anne C. and Lindseth, Frank and Foruzan, Amir Hossein and Kiros, Ryan and Popuri, Karteek and Cobzas, Dana and Jimenez-Carretero, Daniel and Santos, Andres and Ledesma-Carbayo, Maria J. and Helmberger, Michael and Urschler, Martin and Pienn, Michael and Bosboom, Dennis G. H. and Campo, Arantza and Prokop, Mathias and de Jong, Pim A. and Ortiz-de-Solorzano, Carlos and Mu{\~n}oz-Barrutia, Arrate and van Ginneken, Bram},
  title =    {Comparing algorithms for automated vessel segmentation in Computed Tomography scans of the lung: The VESSEL12 study},
  journal =  {Medical Image Analysis},
  volume =   {18},
  number =   {7},
  pages =    {1217 - 1232},
  month =    {October},
  year =     {2014},
  pdf =      {2014_j_MedIA.pdf},
  html =     {http://dx.doi.org/10.1016/j.media.2014.07.003},
  arxiv =    {},
  code =     {},
  abstract = {The VESSEL12 (VESsel SEgmentation in the Lung) challenge objectively compares the performance of different algorithms to identify vessels in thoracic computed tomography (CT) scans. Vessel segmentation is fundamental in computer aided processing of data generated by 3D imaging modalities. As manual vessel segmentation is prohibitively time consuming, any real world application requires some form of automation. Several approaches exist for automated vessel segmentation, but judging their relative merits is difficult due to a lack of standardized evaluation. We present an annotated reference dataset containing 20 CT scans and propose nine categories to perform a comprehensive evaluation of vessel segmentation algorithms from both academia and industry. Twenty algorithms participated in the VESSEL12 challenge, held at International Symposium on Biomedical Imaging (ISBI) 2012. All results have been published at the VESSEL12 website http://vessel12.grand-challenge.org. The challenge remains ongoing and open to new participants. Our three contributions are: (1) an annotated reference dataset available online for evaluation of new algorithms; (2) a quantitative scoring system for objective comparison of algorithms; and (3) performance analysis of the strengths and weaknesses of the various vessel segmentation methods in the presence of various lung diseases.},
}

@article{Staring:2014,
  abbr =     {},
  bibtex_show = {true},
  author =   {Staring, Marius and Bakker, M.E. and Stolk, Jan and Shamonin, Denis P. and Reiber, Johan H.C. and Stoel, Berend C.},
  title =    {Towards Local Progression Estimation of Pulmonary Emphysema using CT},
  journal =  {Medical Physics},
  volume =   {41},
  number =   {2},
  pages =    {021905-1 - 021905-13},
  month =    {February},
  year =     {2014},
  pdf =      {2014_j_MP.pdf},
  html =     {http://dx.doi.org/10.1118/1.4851535},
  arxiv =    {},
  code =     {},
  abstract = {<b>Purpose:</b> Whole lung densitometry on chest CT images is an accepted method for measuring tissue destruction in patients with pulmonary emphysema in clinical trials. Progression measurement is required for evaluation of change in health condition and the effect of drug treatment. Information about the location of emphysema progression within the lung may be important for the correct interpretation of drug efficacy, or for determining a treatment plan. The purpose of this study is therefore to develop and validate methods that enable the local measurement of lung density changes, which requires proper modeling of the effect of respiration on density.<br><b>Methods:</b> Four methods, all based on registration of baseline and follow-up chest CT scans, are compared. The first naive method subtracts registered images. The second employs the so-called dry sponge model, where volume correction is performed using the determinant of the Jacobian of the transformation. The third and the fourth introduce a novel adaptation of the dry sponge model that circumvents its constant-mass assumption, which is shown to be invalid. The latter two methods require a third CT scan at a different inspiration level to estimate the patient-specific density-volume slope, where one method employs a global and the other a local slope. The methods were validated on CT scans of a phantom mimicking the lung, where mass and volume could be controlled. In addition, validation was performed on data of 21 patients with pulmonary emphysema.<br><b>Results:</b> The image registration method was optimized leaving a registration error below half the slice increment (median 1.0mm). The phantom study showed that the locally adapted slope model most accurately measured local progression. The systematic error in estimating progression, as measured on the phantom data, was below 2 gr/l for a 70 ml (6%) volume difference, and 5 gr/l for a 210 ml (19%) difference, if volume correction was applied. On the patient data an underlying linearity assumption relating lung volume change with density change was shown to hold (fit R<sup>2</sup> = 0.94), and globalized versions of the local models are consistent with global results (R<sup>2</sup> of 0.865 and 0.882 for the two adapted slope models, respectively).<br><b>Conclusions:</b> In conclusion, image matching and subsequent analysis of differences according to the proposed lung models i) has good local registration accuracy on patient data, ii) effectively eliminates a dependency on inspiration level at acquisition time, iii) accurately predicts progression in phantom data, and iv) is reasonably consistent with global results in patient data. It is therefore a potential future tool for assessing local emphysema progression in drug evaluation trials and in clinical practice.},
}

@article{Shamonin:2014,
  abbr =     {},
  bibtex_show = {true},
  author =   {Shamonin, Denis P and Bron, Esther E and Lelieveldt, Boudewijn P.F. and Smits, Marion and Klein, Stefan and Staring, Marius},
  title =    {Fast Parallel Image Registration on CPU and GPU for Diagnostic Classification of Alzheimer's Disease},
  journal =  {Frontiers in Neuroinformatics},
  volume =   {7},
  number =   {50},
  pages =    {1-15},
  month =    {January},
  year =     {2014},
  pdf =      {2014_j_FNI.pdf},
  html =     {http://dx.doi.org/10.3389/fninf.2013.00050},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {Nonrigid image registration is an important, but time-consuming task in medical image analysis. In typical neuroimaging studies, multiple image registrations are performed, i.e. for atlas-based segmentation or template construction. Faster image registration routines would therefore be beneficial.<br>In this paper we explore acceleration of the image registration package elastix by a combination of several techniques: i) parallelization on the CPU, to speed up the cost function derivative calculation; ii) parallelization on the GPU building on and extending the OpenCL framework from ITKv4, to speed up the Gaussian pyramid computation and the image resampling step; iii) exploitation of certain properties of the B-spline transformation model; iv) further software optimizations.<br>The accelerated registration tool is employed in a study on diagnostic classification of Alzheimer's disease and cognitively normal controls based on T1-weighted MRI. We selected 299 participants from the publicly available Alzheimer's Disease Neuroimaging Initiative database. Classification is performed with a support vector machine based on gray matter volumes as a marker for atrophy. We evaluated two types of strategies (voxel-wise and region-wise) that heavily rely on nonrigid image registration.<br>Parallelization and optimization resulted in an acceleration factor of 4-5x on an 8-core machine. Using OpenCL a speedup factor of {\sim}2 was realized for computation of the Gaussian pyramids, and 15-60 for the resampling step, for larger images. The voxel-wise and the region-wise classification methods had an area under the receiver operator characteristic curve of 88% and 90%, respectively, both for standard and accelerated registration.<br>We conclude that the image registration package elastix was substantially accelerated, with nearly identical results to the non-optimized version. The new functionality will become available in the next release of elastix as open source under the BSD license.},
}

@article{Baka:2014,
  abbr =     {},
  bibtex_show = {true},
  author =   {Baka, Nora and Kaptein, Bart L. and Giphart, J. Erik and Staring, Marius and de Bruijne, Marleen and Lelieveldt, Boudewijn P.F. and Valstar, Edward},
  title =    {Evaluation of automated statistical shape model based knee kinematics from biplane fluoroscopy},
  journal =  {Journal of Biomechanics},
  volume =   {47},
  number =   {1},
  pages =    {122 - 129},
  month =    {January},
  year =     {2014},
  pdf =      {2014_j_JBM.pdf},
  html =     {http://dx.doi.org/10.1016/j.jbiomech.2013.09.022},
  arxiv =    {},
  code =     {},
  abstract = {State-of-the-art fluoroscopic knee kinematic analysis methods require the patient-specific bone shapes segmented from CT or MRI. Substituting the patient-specific bone shapes with personalizable models, such as statistical shape models (SSM), could eliminate the CT/MRI acquisitions, and thereby decrease costs and radiation dose (when eliminating CT). SSM based kinematics, however, have not yet been evaluated on clinically relevant joint motion parameters.<br>Therefore, in this work the applicability of SSM-s for computing knee kinematics from biplane fluoroscopic sequences was explored. Kinematic precision with an edge based automated bone tracking method using SSM-s was evaluated on 6 cadaver and 10 in-vivo fluoroscopic sequences. The SSMs of the femur and the tibia-fibula were created using 61 training datasets. Kinematic precision was determined for medial-lateral tibial shift, anterior-posterior tibial drawer, joint distraction-contraction, flexion, tibial rotation and adduction. The relationship between kinematic precision and bone shape accuracy was also investigated.<br>The SSM based kinematics resulted in sub-millimeter (0.48-0.81 mm) and approximately one degree (0.69-0.99<sup>{\circ}</sup>) median precision on the cadaveric knees compared to bone-marker-based kinematics. The precision on the in-vivo datasets was comparable to the cadaveric sequences when evaluated with a semi-automatic reference method. These results are promising, though further work is necessary to reach the accuracy of CT-based kinematics. We also demonstrated that a better shape reconstruction accuracy does not automatically imply a better kinematic precision. This result suggests that the ability of accurately fitting the edges in the fluoroscopic sequences has a larger role in determining the kinematic precision than the overall 3D shape accuracy.},
}

@article{Mengler:2014,
  abbr =     {},
  bibtex_show = {true},
  author =   {Mengler, Luam and Khmelinskii, Artem and Diedenhofen, Michael and Po, Chrystelle and Staring, Marius and Lelieveldt, Boudewijn P.F. and Hoehn, Mathias},
  title =    {Brain maturation of the adolescent rat cortex and striatum: changes in volume and myelination},
  journal =  {NeuroImage},
  volume =   {84},
  number =   {1},
  pages =    {35-44},
  month =    {January},
  year =     {2014},
  pdf =      {2014_j_NI.pdf},
  html =     {http://dx.doi.org/10.1016/j.neuroimage.2013.08.034},
  arxiv =    {},
  code =     {},
  abstract = {Longitudinal studies on brain pathology and assessment of therapeutic strategies rely on a fully mature adult brain to exclude confounds of cerebral developmental changes. Thus, knowledge about onset of adulthood is indispensable for discrimination of developmental phase and adulthood. We have performed a high-resolution longitudinal MRI study at 11.7T of male Wistar rats between 21 days and six months of age, characterizing cerebral volume changes and tissue-specific myelination as a function of age. Cortical thickness reaches final value at 1 month, while volume increases of cortex, striatum and whole brain end only after two months. Myelin accretion is pronounced until the end of the third postnatal month. After this time, continuing myelination increases in cortex are still seen on histological analysis but are no longer reliably detectable with diffusion-weighted MRI due to parallel tissue restructuring processes. In conclusion, cerebral development continues over the first three months of age. This is of relevance for future studies on brain disease models which should not start before the end of month 3 to exclude serious confounds of continuing tissue development.},
}

@article{vantKlooster:2013,
  abbr =     {},
  bibtex_show = {true},
  author =   {van 't Klooster, Ronald and Staring, Marius and Klein, Stefan and Kwee, R.M. and Kooi, M.E. and Reiber, J.H.C and Lelieveldt, Boudewijn P.F. and van der Geest, Rob J.},
  title =    {Automated registration of multispectral MR vessel wall images of the carotid artery},
  journal =  {Medical Physics},
  volume =   {40},
  number =   {12},
  pages =    {121904-1 -- 121904-12},
  month =    {December},
  year =     {2013},
  pdf =      {2013_j_MP.pdf},
  html =     {http://dx.doi.org/10.1118/1.4829503},
  arxiv =    {},
  code =     {},
  abstract = {<b>Purpose:</b> Atherosclerosis is the primary cause of heart disease and stroke. The detailed assessment of atherosclerosis of the carotid artery requires high resolution imaging of the vessel wall using multiple MR sequences with different contrast weightings. These images allow manual or automated classification of plaque components inside the vessel wall. Automated classification requires all sequences to be in alignment, which is hampered by patient motion. In clinical practice correction of this motion is performed manually. Previous studies applied automated image registration to correct for motion using only non-deformable transformation models and did not perform a detailed quantitative validation. The purpose of this study is to develop an automated accurate 3D registration method, and to extensively validate this method on a large set of patient data. In addition, we quantified patient motion during scanning to investigate the need for correction.<br><b>Methods:</b> MR imaging studies (1.5T, dedicated carotid surface coil, Philips) from fifty-five TIA/stroke patients with ipsilateral <70% carotid artery stenosis were randomly selected from a larger cohort. Five MR pulse sequences were acquired around the carotid bifurcation, each containing nine transverse slices: T1W TFE, TOF, T2W TSE, and pre- and post-contrast T1W TSE. The images were manually segmented by delineating the lumen contour in each vessel wall sequence and were manually aligned by applying through-plane and in-plane translations to the images. To find the optimal automatic image registration method, different masks, choice of the fixed image, different types of the mutual information image similarity metric, and transformation models including 3D deformable transformation models, were evaluated. Evaluation of the automatic registration results was performed by comparing the lumen segmentations of the fixed image and moving image after registration.<br><b>Results:</b> The average required manual translation per image slice was 1.33 mm. Translations were larger as the patient was longer inside the scanner. Manual alignment took 187.5 seconds per patient resulting in a mean surface distance of 0.271 &pm; 0.127 mm. After minimal user interaction to generate the mask in the fixed image, the remaining sequences are automatically registered with a computation time of 52.0 seconds per patient. The optimal registration strategy used a circular mask with a diameter of 10 mm, a 3D B-spline transformation model with a control point spacing of 15 mm, mutual information as image similarity metric, and the pre-contrast T1W TSE as fixed image. A mean surface distance of 0.288 &pm; 0.128 mm was obtained with these settings, which is very close to the accuracy of the manual alignment procedure. The exact registration parameters and software were made publicly available.<br><b>Conclusions:</b> An automated registration method was developed and optimized, only needing two mouse clicks to mark the start and end point of the artery. Validation on a large group of patients showed that automated image registration has similar accuracy as the manual alignment procedure, substantially reducing the amount of user interactions needed, and is multiple times faster. In conclusion, we believe that the proposed automated method can replace the current manual procedure, thereby reducing the time to analyze the images.},
}

@article{Dzyubachyk:2013,
  abbr =     {},
  bibtex_show = {true},
  author =   {Dzyubachyk, Oleh and Blaas, Jorik and Botha, Charl P. and Staring, Marius and Reijnierse, Monique and Bloem, Johan L. and van der Geest, Rob J. and Lelieveldt, Boudewijn P.F.},
  title =    {Comparative Exploration of Whole-Body MR through Locally Rigid Transforms},
  journal =  {International Journal of Computer Assisted Radiology and Surgery},
  volume =   {8},
  number =   {4},
  pages =    {635 - 647},
  month =    {July},
  year =     {2013},
  pdf =      {2013_j_IJCARS.pdf},
  html =     {http://dx.doi.org/10.1007/s11548-013-0820-z},
  arxiv =    {},
  code =     {},
  abstract = {<i>Purpose</i> Whole-body MRI is seeing increasing use in the study and diagnosis of disease progression. In this, a central task is the visual assessment of the progressive changes that occur between two whole-body MRI datasets, taken at baseline and follow-up. Current radiological workflow for this consists in manual search of each organ of interest on both scans, usually on multiple data channels, for further visual comparison. Large size of datasets, significant posture differences, and changes in patient anatomy turn manual matching in an extremely labour-intensive task that requires from radiologists high concentration for long period of time. This strongly limits the productivity and increases risk of underdiagnosis.<br><i>Materials and Methods</i> We present a novel approach to the comparative visual analysis of whole-body MRI follow-up data. Our method is based on interactive derivation of locally rigid transforms from a pre-computed whole-body deformable registration. Using this approach, baseline and follow-up slices can be interactively matched with a single mouse-click in the anatomical region of interest. In addition to the synchronized side-by-side baseline and matched follow-up slices, we have integrated four techniques to further facilitate the visual comparison of the two datasets: the "deformation sphere", the color fusion view, the magic lens, and a set of uncertainty iso-contours around the current region of interest.<br><i>Results</i> We have applied our method to the study of cancerous bone lesions over time in patients with Kahler's disease. During these studies, the radiologist carefully visually examines a large number of anatomical sites for changes. Our interactive locally rigid matching approach was found helpful in localization of cancerous lesions and visual assessment of changes between different scans. Furthermore, each of the features integrated in our software was separately evaluated by the experts.<br><i>Conclusions</i> We demonstrated how our method significantly facilitates examination of whole-body MR datasets in follow-up studies by enabling the rapid interactive matching of regions of interest and by the explicit visualization of change.},
}

@article{Xiao:2013,
  abbr =     {},
  bibtex_show = {true},
  author =   {Xiao, Changyan and Staring, Marius and Wang, Yaonan and Shamonin, Denis P. and Stoel, Berend C.},
  title =    {A Multiscale Bi-Gaussian Filter for Adjacent Curvilinear Structures Detection With Application to Vasculature Images},
  journal =  {IEEE Transactions on Image Processing},
  volume =   {22},
  number =   {1},
  pages =    {174 - 188},
  month =    {January},
  year =     {2013},
  pdf =      {2013_j_TIP.pdf},
  html =     {http://dx.doi.org/10.1109/TIP.2012.2216277},
  arxiv =    {},
  code =     {},
  abstract = {The intensity or gray-level derivatives have been widely used in image segmentation and enhancement. Conventional derivative filters often suffer from an undesired merging of adjacent objects, due to their intrinsic usage of an inappropriately broad Gaussian kernel; as a result neighboring structures cannot be properly resolved. To avoid this problem, we propose to replace the low-level Gaussian kernel with a bi-Gaussian function, which allows independent selection of scales on foreground and background. By selecting a narrow neighborhood for the background relative to the foreground, the proposed method will reduce interference from adjacent objects, while preserving the ability of intra-region smoothing. Our idea is inspired by a comparative analysis of existing line filters, where several traditional methods including the vesselness, gradient flux and medialness models are integrated into a uniform framework. The comparison subsequently aids in understanding the principles of the different filtering kernels, which is also a contribution of the paper. Based on some axiomatic scale-space assumptions, the full representation of our bi-Gaussian kernel is deduced. The popular {\gamma}-normalization scheme for multi-scale integration is extended to the bi-Gaussian operators. Finally, combined with a parameter-free shape estimation scheme, a derivative filter is developed for the typical applications of curvilinear structure detection and vasculature image enhancement. It is verified in experiments using synthetic and real data that the proposed method outperforms several conventional filters in separating closely located objects as well as being robust to noise.},
}

@article{Murphy:2011,
  abbr =     {},
  bibtex_show = {true},
  author =   {Murphy, Keelin and van Ginneken, Bram and Reinhardt, Joseph M. and Kabus, Sven and Ding, Kai and Deng, Xiang and Cao, Kunlin and Du, Kaifang and Christensen, Gary E. and Garcia, Vincent and Vercauteren, Tom and Ayache, Nicholas and Commowick, Olivier and Malandain, Gregoire and Glocker, Ben and Paragios, Nikos and Navab, Nassir and Gorbunova, Vladlena and Sporring, Jon and de Bruijne, Marleen and Han, Xiao and Heinrich, Mattias P. and Schnabel, Julia A. and Jenkinson, Mark and Lorenz, Cristian and Modat, Marc and McClelland, Jamie R. and Ourselin, Sebastien and Muenzing, Sascha E.A. and Viergever, Max A. and De Nigris, Dante and Collins, D.L. and Arbel, Tal and Peroni, Marta and Li, Rui and Sharp, Gregory C. and Schmidt-Richberg, Alexander and Ehrhardt, Jan and Werner, Rene and Smeets, Dirk and Loeckx, Dirk and Song, Gang and Tustison, Nicholas and Avants, Brian and Gee, James C. and Staring, Marius and Klein, Stefan and Stoel, Berend C. and Urschler, Martin and Werlberger, Manuel and Vandemeulebroucke, Jef and Rit, Simon and Sarrut, David and Pluim, Josien P.W.},
  title =    {Evaluation of Registration Methods on Thoracic CT: The EMPIRE10 Challenge},
  journal =  {IEEE Transactions on Medical Imaging},
  volume =   {30},
  number =   {11},
  pages =    {1901 - 1920},
  month =    {November},
  year =     {2011},
  pdf =      {2011_j_TMI.pdf},
  html =     {http://dx.doi.org/10.1109/TMI.2011.2158349},
  arxiv =    {},
  code =     {},
  abstract = {EMPIRE10 (Evaluation of Methods for Pulmonary Image REgistration 2010) is a public platform for fair and meaningful comparison of registration algorithms which are applied to a database of intrapatient thoracic CT image pairs. Evaluation of nonrigid registration techniques is a nontrivial task. This is compounded by the fact that researchers typically test only on their own data, which varies widely. For this reason, reliable assessment and comparison of different registration algorithms has been virtually impossible in the past. In this work we present the results of the launch phase of EMPIRE10, which comprised the comprehensive evaluation and comparison of 20 individual algorithms from leading academic and industrial research groups. All algorithms are applied to the same set of 30 thoracic CT pairs. Algorithm settings and parameters are chosen by researchers expert in the configuration of their own method and the evaluation is independent, using the same criteria for all participants. All results are published on the EMPIRE10 website (<a href="http://empire10.isi.uu.nl">http://empire10.isi.uu.nl</a>). The challenge remains ongoing and open to new participants. Full results from 24 algorithms have been published at the time of writing. This paper details the organization of the challenge, the data and evaluation methods and the outcome of the initial launch with 20 algorithms. The gain in knowledge and future work are discussed.},
}

@article{Xiao:2011,
  abbr =     {},
  bibtex_show = {true},
  author =   {Xiao, Changyan and Staring, Marius and Shamonin, Denis P. and Reiber, Johan H.C. and Stolk, Jan and Stoel, Berend C.},
  title =    {A Strain Energy Filter for 3D Vessel Enhancement with Application to Pulmonary CT Images},
  journal =  {Medical Image Analysis},
  volume =   {15},
  number =   {1},
  pages =    {112 - 124},
  month =    {February},
  year =     {2011},
  pdf =      {2011_j_MedIAb.pdf},
  html =     {http://dx.doi.org/10.1016/j.media.2010.08.003},
  arxiv =    {},
  code =     {},
  abstract = {The traditional Hessian-related vessel filters often suffer from detecting complex structures like bifurcations due to an over-simplified cylindrical model. To solve this problem, we present a shape-tuned strain energy density function to measure vessel likelihood in 3D medical images. This method is initially inspired by established stress-strain principles in mechanics. By considering the Hessian matrix as a stress tensor, the three invariants from orthogonal tensor decomposition are used independently or combined to formulate distinctive functions for vascular shape discrimination, brightness contrast and structure strengthen measuring. Moreover, a mathematical description of Hessian eigenvalues for general vessel shapes is obtained, based on an intensity continuity assumption, and a relative Hessian strength term is presented to ensure the dominance of second-order derivatives as well as suppress undesired step edges. Finally, we adopt the multi-scale scheme to find an optimal solution through scale space. The proposed method is validated in experiments with a digital phantom and non-contrast-enhanced pulmonary CT data. It is shown that our model performed more effectively in enhancing vessel bifurcations and preserving details, compared to three existing filters.},
}

@article{Murphy:2011,
  abbr =     {},
  bibtex_show = {true},
  author =   {Murphy, Keelin and van Ginneken, Bram and Klein, Stefan and Staring, Marius and Viergever, Max A. and Pluim, Josien P.W.},
  title =    {Semi-Automatic Construction of Reference Standards for Evaluation of Image Registration},
  journal =  {Medical Image Analysis},
  volume =   {15},
  number =   {1},
  pages =    {71 - 84},
  month =    {February},
  year =     {2011},
  pdf =      {2011_j_MedIAa.pdf},
  html =     {http://dx.doi.org/10.1016/j.media.2010.07.005},
  arxiv =    {},
  code =     {},
  abstract = {Quantitative evaluation of image registration algorithms is a difficult and under-addressed issue due to the lack of a reference standard in most registration problems. In this work a method is presented whereby detailed reference standard data may be constructed in an efficient semi-automatic fashion. A well-distributed set of <i>n</i> landmarks is detected fully automatically in one scan of a pair to be registered. Using a custom-designed interface, observers define corresponding anatomic locations in the second scan for a specified subset of <i>s</i> of these landmarks. The remaining <i>n - s</i> landmarks are matched fully automatically by a thin-plate-spline based system using the <i>s</i> manual landmark correspondences to model the relationship between the scans. The method is applied to 47 pairs of temporal thoracic CT scans, three pairs of brain MR scans and five thoracic CT datasets with synthetic deformations. Interobserver differences are used to demonstrate the accuracy of the matched points. The utility of the reference standard data as a tool in evaluating registration is shown by the comparison of six sets of registration results on the 47 pairs of thoracic CT data.},
}

@article{Isgum:2010,
  abbr =     {},
  bibtex_show = {true},
  author =   {I{\v{s}}gum, Ivana and Rutten, Annemarieke and Prokop, Mathias and Staring, Marius and Klein, Stefan and Pluim, Josien P.W. and Viergever, Max A. and van Ginneken, Bram},
  title =    {Automated aortic calcium scoring on low-dose chest computed tomography},
  journal =  {Medical Physics},
  volume =   {37},
  number =   {2},
  pages =    {714 - 723},
  month =    {February},
  year =     {2010},
  pdf =      {2010_j_MP.pdf},
  html =     {http://link.aip.org/link/doi/10.1118/1.3284211},
  arxiv =    {},
  code =     {},
  abstract = {Thoracic computed tomography (CT) scans provide information about cardiovascular risk status. These scans are non-ECG-synchronized, thus precise quantification of coronary calcifications is difficult. Aortic calcium scoring is less sensitive to cardiac motion, so it is an alternative to coronary calcium scoring as an indicator of cardiovascular risk. We developed and evaluated a computer-aided system for automatic detection and quantification of aortic calcifications in low-dose non-contrast-enhanced chest CT. A computer-aided system for automatic detection and quantification of aortic calcifications was trained and tested on scans from participants of a lung cancer screening trial. A total of 433 low-dose, non-ECG-synchronized, non-contrast enhanced 16-detector row examinations of the chest were randomly divided into 340 training and 93 test data sets. A first observer manually identified aortic calcifications on training and test scans. A second observer did the same on the test scans only. First, a multi-atlas-based segmentation method was developed to delineate the aorta. Subsequently, the training data was used to train the system based on statistical pattern recognition theory to automatically identify calcifications in the aortic wall. Calcium volume scores for computer system and first observer and for the two observers were compared using descriptive statistics and Spearman rank correlation coefficients. The computer system correctly detected on average 768 mm<sup>3</sup> out of 871 mm<sup>3</sup> calcified plaque volume in the aorta with an average 61 mm<sup>3</sup> of false positive volume per scan. Spearman rank correlation coefficient was {\rho}=0.97 between system and first observer compared to {\rho}=0.99 between the two observers. Automatic calcium scoring in the aorta appears feasible with good correlation between manual and automatic scoring.},
}

@article{KleinStaring:2010,
  abbr =     {},
  bibtex_show = {true},
  author =   {Klein, Stefan and Staring, Marius and Murphy, Keelin and Viergever, Max A. and Pluim, Josien P.W.},
  title =    {elastix: a toolbox for intensity-based medical image registration},
  journal =  {IEEE Transactions on Medical Imaging},
  volume =   {29},
  number =   {1},
  pages =    {196 -- 205},
  month =    {January},
  year =     {2010},
  pdf =      {2010_j_TMI.pdf},
  html =     {http://dx.doi.org/10.1109/TMI.2009.2035616},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {Medical image registration is an important task in medical image processing. It refers to the process of aligning data sets, possibly from different modalities (e.g., magnetic resonance (MR) and computed tomography (CT)), different time points (e.g., follow-up scans), and/or different subjects (in case of population studies). A large number of methods for image registration are described in the literature. Unfortunately, there is not one method that works for all applications. We have therefore developed <code>elastix</code>, a publicly available computer program for intensity-based medical image registration. The software consists of a collection of algorithms that are commonly used to solve medical image registration problems. The modular design of <code>elastix</code> allows the user to quickly configure, test, and compare different registration methods for a specific application. The command-line interface enables automated processing of large numbers of data sets, by means of scripting. The usage of <code>elastix</code> for comparing different registration methods is illustrated with three example experiments, in which individual components of the registration method are varied.},
}

@article{vanRikxoort:2010,
  abbr =     {},
  bibtex_show = {true},
  author =   {van Rikxoort, Eva M. and I{\v{s}}gum, Ivana and Arzhaeva, Yulia and Staring, Marius and Klein, Stefan and Viergever, Max A. and Pluim, Josien P.W. and van Ginneken, Bram},
  title =    {Adaptive Local Multi-Atlas Segmentation: Application to the Heart and the Caudate Nucleus},
  journal =  {Medical Image Analysis},
  volume =   {14},
  number =   {1},
  pages =    {39 -- 49},
  month =    {February},
  year =     {2010},
  pdf =      {2010_j_MedIA.pdf},
  html =     {http://dx.doi.org/10.1016%2fj.media.2009.10.001},
  arxiv =    {},
  code =     {},
  abstract = {Atlas-based segmentation is a powerful generic technique for automatic delineation of structures in volumetric images. Several studies have shown that multi atlas segmentation methods outperform schemes that use only a single atlas, but running multiple registrations on volumetric data is time-consuming. Moreover, for many scans or regions within scans, a large number of atlases may not be required to achieve good segmentation performance and may even deteriorate the results. It would therefore be worthwhile to include the decision which and how many atlases to use for a particular target scan in the segmentation process. To this end, we propose two generally applicable multi atlas segmentation methods, AMAS and ALMAS. AMAS automatically selects the most appropriate atlases for a target image and automatically stops registering atlases when no further improvement is expected. ALMAS takes this concept one step further by locally deciding how many and which atlases are needed to segment a target image. The methods employ a computationally cheap atlas selection strategy, an automatic stopping criterion, and a technique to locally inspect registration results and determine how much improvement can be expected from further registrations.<br>AMAS and ALMAS were applied to segmentation of the heart in computed tomography scans of the chest and compared to a conventional multi atlas method (MAS). The results show that ALMAS achieves the same performance as MAS at a much lower computational cost. When the available segmentation time is fixed, both AMAS and ALMAS perform significantly better than MAS. In addition, AMAS was applied to an on-line segmentation challenge for delineation of the caudate nucleus in brain MRI scans where it achieved the best score of all results submitted to date.},
}

@article{Staring:2009,
  abbr =     {},
  bibtex_show = {true},
  author =   {Staring, Marius and van der Heide, Uulke A. and Klein, Stefan and Viergever, Max A. and Pluim, Josien P.W.},
  title =    {Registration of Cervical MRI Using Multifeature Mutual Information},
  journal =  {IEEE Transactions on Medical Imaging},
  volume =   {28},
  number =   {9},
  pages =    {1412 - 1421},
  month =    {September},
  year =     {2009},
  pdf =      {2009_j_TMIb.pdf},
  html =     {http://dx.doi.org/10.1109/TMI.2009.2016560},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {Radiation therapy for cervical cancer can benefit from image registration in several ways, for example by studying the motion of organs, or by (partially) automating the delineation of the target volume and other structures of interest. In this paper, the registration of cervical data is addressed using mutual information (MI) of not only image intensity, but also features that describe local image structure. Three aspects of the registration are addressed to make this approach feasible. Firstly, instead of relying on a histogram-based estimation of mutual information, which poses problems for a larger number of features, a graph-based implementation of {\alpha}-mutual information ({\alpha}-MI) is employed. Secondly, the analytical derivative of {\alpha}-MI is derived. This makes it possible to use a stochastic gradient descent method to solve the registration problem, which is substantially faster than non-derivative-based methods. Thirdly, the feature space is reduced by means of a principal component analysis, which also decreases the registration time. The proposed technique is compared to a standard approach, based on the mutual information of image intensity only. Experiments are performed on 93 T2-weighted MR clinical data sets acquired from 19 patients with cervical cancer. Several characteristics of the proposed algorithm are studied on a subset of 19 image pairs (one pair per patient). On the remaining data (36 image pairs, one or two pairs per patient) the median overlap is shown to improve significantly compared to standard MI from 0.85 to 0.86 for the clinical target volume (CTV, <i>p</i> = 2 10<sup>-2</sup>), from 0.75 to 0.81 for the bladder (<i>p</i> = 8 10<sup>-6</sup>) and from 0.76 to 0.77 for the rectum (<i>p</i> = 2 10<sup>-4</sup>). The registration error is improved at important tissue interfaces, such as that of the bladder with the CTV, and the interface of the rectum with the uterus and cervix.},
}

@article{Isgum:2009,
  abbr =     {},
  bibtex_show = {true},
  author =   {I{\v{s}}gum, Ivana and Staring, Marius and Rutten, Annemarieke and Prokop, Mathias and Viergever, Max A. and van Ginneken, Bram},
  title =    {Multi-Atlas-Based Segmentation With Local Decision Fusion - Application to Cardiac and Aortic Segmentation in CT Scans},
  journal =  {IEEE Transactions on Medical Imaging},
  volume =   {28},
  number =   {7},
  pages =    {1000 - 1010},
  month =    {July},
  year =     {2009},
  pdf =      {2009_j_TMIa.pdf},
  html =     {http://dx.doi.org/10.1109/TMI.2008.2011480},
  arxiv =    {},
  code =     {},
  abstract = {A novel atlas-based segmentation approach based on the combination of multiple registrations is presented. Multiple atlases are registered to a target image. To obtain a segmentation of the target, labels of the atlas images are propagated to it. The propagated labels are combined by spatially varying decision fusion weights. These weights are derived from local assessment of the registration success.  Furthermore, an atlas selection procedure is proposed that is equivalent to sequential forward selection from  statistical pattern recognition theory. The proposed method is compared to three existing atlas-based segmentation approaches, namely (1) single atlas-based segmentation, (2) average-shape atlas-based segmentation, and (3) multi-atlas-based segmentation with averaging as decision fusion. These methods were tested on the segmentation of the heart and the aorta in computed tomography scans of the thorax. The results show that the proposed method outperforms other methods and yields results very close to those of an independent human observer. Moreover, the additional atlas selection step led to a faster segmentation at a comparable performance.},
}

@article{Klein:2009,
  abbr =     {},
  bibtex_show = {true},
  author =   {Klein, Stefan and Pluim, Josien P.W. and Staring, Marius and Viergever, Max A.},
  title =    {Adaptive Stochastic Gradient Descent Optimisation for Image Registration},
  journal =  {International Journal of Computer Vision},
  volume =   {81},
  number =   {3},
  pages =    {227 - 239},
  month =    {March},
  year =     {2009},
  pdf =      {2009_j_IJCV.pdf},
  html =     {http://dx.doi.org/10.1007/s11263-008-0168-y},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {We present a stochastic gradient descent optimisation method for image registration with adaptive step size prediction. The method is based on the theoretical work by Plakhov and Cruz (2004). Our main methodological contribution is the derivation of an image-driven mechanism to select proper values for the most important free parameters of the method. The selection mechanism employs general characteristics of the cost functions that commonly occur in intensity-based image registration. Also, the theoretical convergence conditions of the optimisation method are taken into account. The proposed adaptive stochastic gradient descent (ASGD) method is compared to a standard, non-adaptive Robbins-Monro (RM) algorithm. Both ASGD and RM employ a stochastic subsampling technique to accelerate the optimisation process. Registration experiments were performed on 3D CT and MR data of the head, lungs, and prostate, using various similarity measures and transformation models. The results indicate that ASGD is robust to these variations in the registration framework and is less sensitive to the settings of the user-defined parameters than RM. The main disadvantage of RM is the need for a predetermined step size function. The ASGD method provides a solution for that issue.},
}

@article{Staring:2009,
  abbr =     {},
  bibtex_show = {true},
  author =   {Staring, Marius and Pluim, Josien P.W. and de Hoop, Bartjan and Klein, Stefan and van Ginneken, Bram and Gietema, Hester and Nossent, George and Schaefer-Prokop, Cornelia and van de Vorst, Saskia and Prokop, Mathias},
  title =    {Image Subtraction Facilitates Assessment of Volume and Density Change in Ground-Glass Opacities in Chest CT},
  journal =  {Investigative Radiology},
  volume =   {44},
  number =   {2},
  pages =    {61 - 66},
  month =    {February},
  year =     {2009},
  pdf =      {2009_j_IR.pdf},
  html =     {http://dx.doi.org/10.1097/RLI.0b013e318197fcb7},
  arxiv =    {},
  code =     {},
  abstract = {<b>Objectives</b>: To study the impact of image subtraction of registered images on the detection of change in pulmonary ground-glass nodules identified on chest CT.<br><b>Materials and Methods</b>: A cohort of 33 individuals (25 men, 8 women; age range 51 to 75 years) with 37 focal ground-glass opacities (GGO) were recruited from a lung cancer screening trial. For every participant, one to three follow-up scans were available (total number of pairs, 84). Pairs of scans of the same nodule were registered nonrigidly, and then subtracted to enhance differences in size and density. Four observers rated size and density change of the GGO between pairs of scans by visual comparison alone and with additional availability of a subtraction image and indicated their confidence. An independent experienced chest radiologist served as an arbiter having all reader data, clinical data and follow-up examinations available. Nodule pairs for which the arbiter could not establish definite progression, regression, or stability were excluded from further evaluation. This left 59 and 58 pairs for evaluation of size and density change, respectively. Weighted kappa statistics were used to assess inter-observer agreement and agreement with the arbiter. Statistical significance was tested with a kappa z-test.<br><b>Results</b>: When the subtraction image was available, the average inter-observer improved from 0.52 to 0.66 for size change and from 0.47 to 0.57 for density change. Average agreement with the arbiter improved from 0.61 to 0.76 for size change and from 0.53 to 0.64 for density change. The effect was more pronounced when observer confidence without the subtraction image was low: agreement improved from 0.26 to 0.57 and from 0.19 to 0.47 in those cases.<br><b>Conclusions</b>: Image subtraction improves the evaluation of subtle changes in pulmonary ground-glass opacities and decreases inter-observer variability.},
}

@article{Klein:2008,
  abbr =     {},
  bibtex_show = {true},
  author =   {Klein, Stefan and van der Heide, Uulke A. and Lips, Irene M. and van Vulpen, Marco and Staring, Marius and Pluim, Josien P.W.},
  title =    {Automatic Segmentation of the Prostate in 3D MR Images by Atlas Matching using Localised Mutual Information},
  journal =  {Medical Physics},
  volume =   {35},
  number =   {4},
  pages =    {1407 - 1417},
  month =    {April},
  year =     {2008},
  pdf =      {2008_j_MP.pdf},
  html =     {http://link.aip.org/link/doi/10.1118/1.2842076},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {An automatic method for delineating the prostate (including the seminal vesicles) in 3D magnetic resonance (MR) scans is presented. The method is based on nonrigid registration of a set of prelabelled atlas images. Each atlas image is nonrigidly registered with the target patient image. Subsequently, the deformed atlas label images are fused to yield a single segmentation of the patient image. The proposed method is evaluated on 50 clinical scans, which were manually segmented by three experts. The Dice similarity coefficient (DSC) is used to quantify the overlap between the automatic and manual segmentations. We investigate the impact of several factors on the performance of the segmentation method. For the registration, two similarity measures are compared: mutual information and a localised version of mutual information. The latter turns out to be superior (median diff. DSC = 0.02, p < 0.01 with a paired two-sided Wilcoxon test) and comes at no added computational cost, thanks to the use of a novel stochastic optimisation scheme. For the atlas fusion step we consider a majority voting rule and the ''simultaneous truth and performance level estimation'' (STAPLE) algorithm, both with and without a preceding atlas selection stage. The differences between the various fusion methods appear to be small and mostly not statistically significant (p > 0.05). To assess the influence of the atlas composition, two atlas sets are compared. The first set consists of 38 scans of healthy volunteers. The second set is constructed by a leave-one-out approach using the 50 clinical scans that are used for evaluation. The second atlas set gives substantially better performance (diff. DSC = 0.04, p < 0.01), stressing the importance of a careful atlas definition. With the best settings, a median DSC of around 0.85 is achieved, which is close to the median interobserver DSC of 0.87. The segmentation quality is especially good at the prostate-rectum interface, where the segmentation error remains below 1mm in 50% of the cases and below 1.5mm in 75% of the cases.},
}

@article{Staring:2007a,
  abbr =     {},
  bibtex_show = {true},
  author =   {Staring, Marius and Klein, Stefan and Pluim, Josien P.W.},
  title =    {Nonrigid Registration with Tissue-Dependent Filtering of the Deformation Field},
  journal =  {Physics in Medicine and Biology},
  volume =   {52},
  number =   {23},
  pages =    {6879 - 6892},
  month =    {December},
  year =     {2007},
  pdf =      {2007_j_PMB.pdf},
  html =     {http://dx.doi.org/10.1088/0031-9155/52/23/007},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {In present-day medical practice it is often necessary to nonrigidly align image data. Current registration algorithms do not generally take the characteristics of tissue into account. Consequently, rigid tissue, such as bone, can be deformed elastically, growth of tumours may be concealed, and contrast-enhanced structures may be reduced in volume.<br>We propose a method to locally adapt the deformation field at structures that must be kept rigid, using a tissue-dependent filtering technique. This adaptive filtering of the deformation field results in locally linear transformations without scaling or shearing. The degree of filtering is related to tissue stiffness: more filtering is applied at stiff tissue locations, less at parts of the image containing nonrigid tissue. The tissue-dependent filter is incorporated in a commonly used registration algorithm, using mutual information as a similarity measure and cubic B-splines to model the deformation field. The new registration algorithm is compared with this popular method.<br>Evaluation of the proposed tissue-dependent filtering is performed on 3D CT data of the thorax and on 2D Digital Subtraction Angiography (DSA) images. The results show that tissue-dependent filtering of the deformation field leads to improved registration results: tumour volumes and vessel widths are preserved rather than affected.},
}

@article{Klein:2007,
  abbr =     {},
  bibtex_show = {true},
  author =   {Klein, Stefan and Staring, Marius and Pluim, Josien P.W.},
  title =    {Evaluation of Optimization Methods for Nonrigid Medical Image Registration using Mutual Information and B-splines},
  journal =  {IEEE Transactions on Image Processing},
  volume =   {16},
  number =   {12},
  pages =    {2879 - 2890},
  month =    {December},
  year =     {2007},
  pdf =      {2007_j_TIP.pdf},
  html =     {http://dx.doi.org/10.1109/TIP.2007.909412},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {A popular technique for nonrigid registration of medical images is based on the maximization of their mutual information, in combination with a deformation field parameterized by cubic B-splines. The coordinate mapping that relates the two images is found using an iterative optimization procedure. This work compares the performance of eight optimization methods: gradient descent (with two different step size selection algorithms), quasi-Newton, nonlinear conjugate gradient, Kiefer-Wolfowitz, simultaneous perturbation, Robbins-Monro, and evolution strategy. Special attention is paid to computation time reduction by using fewer voxels to calculate the cost function and its derivatives. The optimization methods are tested on manually deformed CT images of the heart, on follow-up CT chest scans, and on MR scans of the prostate acquired using a BFFE, T1, and T2 protocol. Registration accuracy is assessed by computing the overlap of segmented edges. Precision and convergence properties are studied by comparing deformation fields. The results show that the Robbins-Monro method is the best choice in most applications. With this approach, the computation time per iteration can be lowered approximately 500 times without affecting the rate of convergence by using a small subset of the image, randomly selected in every iteration, to compute the derivative of the mutual information. From the other methods the quasi-Newton and the nonlinear conjugate gradient method achieve a slightly higher precision, at the price of larger computation times.},
}

@article{Staring:2007b,
  abbr =     {},
  bibtex_show = {true},
  author =   {Staring, Marius and Klein, Stefan and Pluim, Josien P.W.},
  title =    {A Rigidity Penalty Term for Nonrigid Registration},
  journal =  {Medical Physics},
  volume =   {34},
  number =   {11},
  pages =    {4098 - 4108},
  month =    {November},
  year =     {2007},
  pdf =      {2007_j_MP.pdf},
  html =     {http://dx.doi.org/10.1118/1.2776236},
  arxiv =    {},
  code =     {https://github.com/SuperElastix/elastix},
  abstract = {Medical images that are to be registered for clinical application often contain both structures that deform and ones that remain rigid. Nonrigid registration algorithms that do not model properties of different tissue types may result in deformations of rigid structures. In this article a local rigidity penalty term is proposed which is included in the registration function in order to penalize the deformation of rigid objects. This term can be used for any representation of the deformation field capable of modelling locally rigid transformations. By using a B-spline representation of the deformation field, a fast algorithm can be devised. The proposed method is compared with an unconstrained nonrigid registration algorithm. It is evaluated on clinical three-dimensional CT follow-up data of the thorax and on two-dimensional DSA image sequences. The results show that nonrigid registration using the proposed rigidity penalty term is capable of nonrigidly aligning images, while keeping user-defined structures locally rigid.},
}

